{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist 3368 - Week 10: Word Context Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By Jo Guldi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From Word Vectors to Word Context Vectors\n",
    "\n",
    "In previous notebooks, you've used word count vectors to compare the words most distinctive of companies and time periods, and to measure the abstract \"distance\" between different entities.\n",
    "\n",
    "In our reading, we've learned that many scholars applied word vectors to understanding intellectual history. Word vectors can help you to understand the changing profile of every word -- how its \"context\" was different in 1920 than in 1980.  For example, the word \"gay\" meant \"happy\" in 1920, but by 1990 it had come to mean \"homosexual.\"  Word context is the study of the changing words that surrounded \"gay\" in both instances.\n",
    "\n",
    "Wordcount vectors can get you to changing word context. To perform such an investigation, you need to structure the data so that there is one vector for each word in every period of time.  This is called a “word context vector”. \n",
    "\n",
    "In this week's notebook, we'll make word context vectors for some words in Congress. We'll go through the following steps:\n",
    "* First, we'll organize the data so that we have a dataframe of one word per row, where another column gives the sentence in which the word appears in Congress and the date.\n",
    "* Then, we'll \"groupby\" keyword and period, so that we have an index for each keyword and period (for instance, \"woman-1985\") and a \"context\" column with every word next to which \"woman\" appears in the year 1985.\n",
    "* Next, we'll use the word vector tools you already know -- SKLEARN's Countvectorizer(), .fit_transform -- to make vectors from this data.\n",
    "* We'll use a measurement tool you already know -- cosine distance -- to compare context vectors for \"woman\" from 1985 to 1995 and 2005\n",
    "* We'll use a comparison tool you already know -- vector subtraction -- to create a \"gender difference vectors\" whose low scores show words more likely to show up in the context of \"woman\" and whose high scores show words more likely to show up in the context of \"man\"\n",
    "* Later in the notebook, we'll return to a 'word embedding' software package that uses high-dimensional math and hidden layers to make whip-fast vectors.\n",
    "\n",
    "#### Word Vectors vs. Word Embeddings \n",
    "\n",
    "Wordcount vectors are just what we’ve looked at: a simple count of words, with one integer per every word.  Wordcount embeddings are similar. But they typically add one more row of data or more per document.  That might mean that there’s a count of how many nouns, verbs, or adjectives there are per document. That might mean that there’s a count of bigrams, trigrams, fourgrams, or more – or multi-word phrases, plus or minus a word, called a “skipgram.”  These “hidden layers” in word embedding models mean an even richer model of which documents are like other documents. Because they factor in grammar and sentence structure as well as lexicon, they produce models that are very good at matching rhetorical style in text, and getting at the nuances of grammatical meaning. That is to say, they’re good at noticing when you mean “apple” the fruit (which you might eat or make into pie) or “apple” the computer (which you might turn on or off).  \n",
    "\n",
    "Functionally, you use word embeddings just the way you use wordcount vectors. You can measure the distance between them, just like we did in our notebook this week.  You can subtract them, just as we did, to get a litmus test of what’s different between two periods of time, or which words are used to signify masculinity and femininity.  \n",
    "\n",
    "*In the first half of this notebook,* we'll stick with \"word vectors,\" not embeddings.  We'll word context vectors 'by hand' -- i.e., using onyl SKLEARN's CountVectorizer() and .fit_transform + cosine distance and subtraction.  Doing it this way is slower than loading some other packages that have been built specifically for working with large-scale wordcount vectors, where the code is packaged with high-dimensional math designed to make the comparisons run faster. We're doing it this way, however, so that you can really see for yourself how a word vector is built and what's inside it at every moment.   When we structure the data, build the vectors, subtract and measure the distance between vectors, we'll be able to inspect what's in the vector at every turn. You'd be able to do the math yourself if you looked more carefully.\n",
    "\n",
    "*In the second half of the code,* however, we'll use the GENSIM package of word embeddings to work on a larger-scale sample of debates. We'll use GENSIM's pre-built tools to do analysis comparative to what you did with cosine distance and vector subtraction:\n",
    "\n",
    "     wv.vocab - which allows you to inspect the words in a vector \n",
    "     wv.most_similar() - which allows you to call up vectors from your dataset that are most similar to a given word\n",
    "\n",
    "#### Skill Building for Historical Analysis\n",
    "\n",
    "By the end of this notebook, you'll know how to replicate most of the fancy work with vectors in the reading.  You'll be able to:\n",
    "* use word context vectors to analyze the intellectual history of concept words like \"freedom,\" \"gay\", or \"woman,\" detecting how their context changed from moment to moment\n",
    "* visualize changes to word concepts as a dendrogram\n",
    "* use GENSIM's \"most_similar()\" to generate a list of the words most similar to any concept (for instance \"freedom\") at different moments over time\n",
    "* visualize changes to the context of an individual word over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.spatial.distance\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines load some data from Congress. Don't worry too much about the commands within this block; we're more interested in the transformations we'll apply to the data after it's loaded.  If you're curious, the lines below download two separate dataframes --  \"speeches\" and \"descriptions\" -- and then merge them  so that we now have one database of speeches with the date on which they were spoken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "6qCg0mXrtOD1",
    "outputId": "4ecca950-9419-4b8d-96fc-aa5fbb1426f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_111.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_100.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_101.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_102.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_103.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_104.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_105.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_106.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_107.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_108.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_109.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_110.txt...\n",
      "Reading /scratch/group/oit_research_data/stanford_congress/hein-bound/descr_111.txt...\n"
     ]
    }
   ],
   "source": [
    "all_speech_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/speeches_*.txt')\n",
    "CONGRESS_MIN_THRESHOLD = 100\n",
    "CONGRESS_MAX_THRESHOLD = 115\n",
    "\n",
    "speech_files = []\n",
    "\n",
    "for fn in all_speech_files:\n",
    "    number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "    if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "        speech_files.append(fn)\n",
    "\n",
    "speech_files.sort()\n",
    "        \n",
    "def parse_one(fn):\n",
    "    print(f'Reading {fn}...')\n",
    "    return pd.read_csv(fn, sep='|', encoding=\"ISO-8859-1\", error_bad_lines=False, warn_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
    "\n",
    "speeches_df = pd.concat((parse_one(fn) for fn in speech_files))\n",
    "speeches_df.dropna(how='any', inplace=True)\n",
    "\n",
    "all_description_files = glob.glob('/scratch/group/oit_research_data/stanford_congress/hein-bound/descr_*.txt')\n",
    "                                  \n",
    "description_files = []\n",
    "\n",
    "for fn in all_description_files:\n",
    "    number = int(fn.rsplit('_', 1)[-1].split('.')[0])\n",
    "    if CONGRESS_MIN_THRESHOLD <= number <= CONGRESS_MAX_THRESHOLD:\n",
    "        description_files.append(fn)\n",
    "        description_files.sort()\n",
    "        \n",
    "description_df = pd.concat((parse_one(fn) for fn in description_files))\n",
    "\n",
    "all_data = pd.merge(speeches_df, description_df, on = 'speech_id')\n",
    "all_data.fillna(0, inplace=True)\n",
    "all_data = all_data.drop(['chamber', 'speech_id', 'number_within_file', 'speaker', 'first_name'], 1)\n",
    "all_data = all_data.drop(['last_name', 'state', 'gender', 'line_start', 'line_end', 'file', 'char_count', 'word_count'], 1)\n",
    "all_data['date']=pd.to_datetime(all_data['date'],format='%Y%m%d')\n",
    "all_data['year'] = pd.to_datetime(all_data['date']).dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['5yrperiod'] = np.floor(all_data['year'] / 5) * 5 # round each year to the nearest 5 -- by dividing by 5 and \"flooring\" to the lowest integer\n",
    "all_data = all_data.drop(['date', 'year'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "atQkz5HhtOFo",
    "outputId": "cff96380-af39-4402-a9c2-a5c97c547fc5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech</th>\n",
       "      <th>5yrperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Representativeselect to the 100th Congress. th...</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Chair would also like to state that Repres...</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quor closes that 426 Represe have answered...</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Clerk credentials regular in for received ...</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The next order of business is the election of ...</td>\n",
       "      <td>1985.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              speech  5yrperiod\n",
       "0  Representativeselect to the 100th Congress. th...     1985.0\n",
       "1  The Chair would also like to state that Repres...     1985.0\n",
       "2  The quor closes that 426 Represe have answered...     1985.0\n",
       "3  The Clerk credentials regular in for received ...     1985.0\n",
       "4  The next order of business is the election of ...     1985.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, the first pass, we're going to do some memory-intensive work on the computer by creating word context vectors 'by hand' -- i.e., using onyl SKLEARN's CountVectorizer() and .fit_transform + cosine distance and subtraction.  \n",
    "\n",
    "Doing it this way is slower than loading some other packages that have been built specifically for working with large-scale wordcount vectors, where the code is packaged with high-dimensional math designed to make the comparisons run faster.\n",
    "\n",
    "We're doing it this way, however, so that you can really see for yourself how a word vector is built and what's inside it at every moment.   \n",
    "\n",
    "When we structure the data, build the vectors, subtract and measure the distance between vectors, we'll be able to inspect what's in the vector at every turn. You'd be able to do the math yourself if you looked more carefully.\n",
    "\n",
    "Later in the notebook, we'll return to a 'word embedding' software package that uses high-dimensional math and hidden layers to make whip-fast vectors.\n",
    "\n",
    "However, as we're doing old-fashioned vectors by hand, it'll go best if we \"downsample\" the data, taking a random sample of 5000 sentences spoken in Congress between 1985-2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some downsamples so we don't break the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_l = all_data.sample(500000)\n",
    "sample_m = sample_l.sample(50000)\n",
    "sample = sample_m.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make a word context vector dataframe.\n",
    "\n",
    "First, we'll break up the data so that we have one row per every sentence.\n",
    "\n",
    "Then, we'll break up the data so that we have one row per every word -- and a column with the 'sentence' where the word was originally found.\n",
    "\n",
    "This will tell us about the context of the word.\n",
    "\n",
    "We'll retain information about the '5yrperiod' when the word was originally from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break data into sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a handy script for breaking up strings into sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "\n",
    "def make_sentences(text):\n",
    "    preprocessed_text = []\n",
    "    for line in text:\n",
    "        lower_case = line.lower()\n",
    "        sentences = sent_tokenize(lower_case)\n",
    "        tokenized_sentences = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "        preprocessed_text += tokenized_sentences\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the make_sentences function to the 'speech' column (this might take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = make_sentences(sample['speech']).copy()\n",
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>5yrperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I object</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I yield to the gentleman from California</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madam Speaker</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rise today to honor the outgoing 2006 Board...</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that vote will occur tomorrow morning</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We may be able to work on an agreement to wor...</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We will certainly work with all colleagues to...</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have asked the Republican leader to speak f...</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104103 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  5yrperiod\n",
       "0   The Chair again informs the Senator from Calif...     2000.0\n",
       "0                                            I object     2000.0\n",
       "0            I yield to the gentleman from California     2005.0\n",
       "0                                       Madam Speaker     2005.0\n",
       "0    I rise today to honor the outgoing 2006 Board...     2005.0\n",
       "..                                                ...        ...\n",
       "0               that vote will occur tomorrow morning     2005.0\n",
       "0    We may be able to work on an agreement to wor...     2005.0\n",
       "0    We will certainly work with all colleagues to...     2005.0\n",
       "0    I have asked the Republican leader to speak f...     2005.0\n",
       "0         I have something I have to do off the floor     2005.0\n",
       "\n",
       "[104103 rows x 2 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_sentences = pd.concat([pd.DataFrame({'sentence': speech, '5yrperiod': row['5yrperiod']}, index=[0]) \n",
    "           for _, row in sample.iterrows() \n",
    "           for speech in row['speech'].split('.') if speech != ''])\n",
    "word_context_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break sentences into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some code for breaking up sentences into words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an 'index' column with \n",
    "    \n",
    "        np.arange(len(index_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>5yrperiod</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I object</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I yield to the gentleman from California</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Madam Speaker</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rise today to honor the outgoing 2006 Board...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>that vote will occur tomorrow morning</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>104098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We may be able to work on an agreement to wor...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>104099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We will certainly work with all colleagues to...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have asked the Republican leader to speak f...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>104101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>104102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  5yrperiod   index\n",
       "0   The Chair again informs the Senator from Calif...     2000.0       0\n",
       "0                                            I object     2000.0       1\n",
       "0            I yield to the gentleman from California     2005.0       2\n",
       "0                                       Madam Speaker     2005.0       3\n",
       "0    I rise today to honor the outgoing 2006 Board...     2005.0       4\n",
       "..                                                ...        ...     ...\n",
       "0               that vote will occur tomorrow morning     2005.0  104098\n",
       "0    We may be able to work on an agreement to wor...     2005.0  104099\n",
       "0    We will certainly work with all colleagues to...     2005.0  104100\n",
       "0    I have asked the Republican leader to speak f...     2005.0  104101\n",
       "0         I have something I have to do off the floor     2005.0  104102\n",
       "\n",
       "[104103 rows x 3 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_context = word_context_sentences.copy()\n",
    "index_context['index'] = np.arange(len(index_context)) # create an 'index' column\n",
    "index_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use str.split() and \n",
    "\n",
    "    .explode()\n",
    "\n",
    "to create a dataframe with one word per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Chair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>informs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007998</th>\n",
       "      <td>104102</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007999</th>\n",
       "      <td>104102</td>\n",
       "      <td>do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008000</th>\n",
       "      <td>104102</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008001</th>\n",
       "      <td>104102</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008002</th>\n",
       "      <td>104102</td>\n",
       "      <td>floor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  keyword\n",
       "0             0      The\n",
       "1             0    Chair\n",
       "2             0    again\n",
       "3             0  informs\n",
       "4             0      the\n",
       "...         ...      ...\n",
       "1007998  104102       to\n",
       "1007999  104102       do\n",
       "1008000  104102      off\n",
       "1008001  104102      the\n",
       "1008002  104102    floor\n",
       "\n",
       "[1008003 rows x 2 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_per_row = index_context.set_index('index')\n",
    "word_per_row =pd.concat([word_per_row['sentence'].str.split(' ').explode()],axis=1).reset_index() #explode the data \n",
    "word_per_row = word_per_row.rename({'sentence' : 'keyword'}, axis = 1) # rename the column \"sentence\" to \"keyword\"\n",
    "word_per_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two dataframes to create a well-annotated dataframe of every word and its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>sentence</th>\n",
       "      <th>5yrperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chair</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>again</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>informs</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007998</th>\n",
       "      <td>to</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007999</th>\n",
       "      <td>do</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008000</th>\n",
       "      <td>off</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008001</th>\n",
       "      <td>the</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008002</th>\n",
       "      <td>floor</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword                                           sentence  5yrperiod\n",
       "0            The  The Chair again informs the Senator from Calif...     2000.0\n",
       "1          Chair  The Chair again informs the Senator from Calif...     2000.0\n",
       "2          again  The Chair again informs the Senator from Calif...     2000.0\n",
       "3        informs  The Chair again informs the Senator from Calif...     2000.0\n",
       "4            the  The Chair again informs the Senator from Calif...     2000.0\n",
       "...          ...                                                ...        ...\n",
       "1007998       to        I have something I have to do off the floor     2005.0\n",
       "1007999       do        I have something I have to do off the floor     2005.0\n",
       "1008000      off        I have something I have to do off the floor     2005.0\n",
       "1008001      the        I have something I have to do off the floor     2005.0\n",
       "1008002    floor        I have something I have to do off the floor     2005.0\n",
       "\n",
       "[1008003 rows x 3 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_words = pd.merge(word_per_row, index_context, on=\"index\") # merge the two df's\n",
    "word_context_words = word_context_words.drop('index', 1) # get rid of the index column because we don't need it any more\n",
    "word_context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>sentence</th>\n",
       "      <th>5yrperiod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chair</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>again</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>informs</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007998</th>\n",
       "      <td>to</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007999</th>\n",
       "      <td>do</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008000</th>\n",
       "      <td>off</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008001</th>\n",
       "      <td>the</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008002</th>\n",
       "      <td>floor</td>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword                                           sentence  5yrperiod\n",
       "0            The  The Chair again informs the Senator from Calif...     2000.0\n",
       "1          Chair  The Chair again informs the Senator from Calif...     2000.0\n",
       "2          again  The Chair again informs the Senator from Calif...     2000.0\n",
       "3        informs  The Chair again informs the Senator from Calif...     2000.0\n",
       "4            the  The Chair again informs the Senator from Calif...     2000.0\n",
       "...          ...                                                ...        ...\n",
       "1007998       to        I have something I have to do off the floor     2005.0\n",
       "1007999       do        I have something I have to do off the floor     2005.0\n",
       "1008000      off        I have something I have to do off the floor     2005.0\n",
       "1008001      the        I have something I have to do off the floor     2005.0\n",
       "1008002    floor        I have something I have to do off the floor     2005.0\n",
       "\n",
       "[1008003 rows x 3 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_words['keyword'] = word_context_words['keyword'].str.strip() # strip the whitespace\n",
    "word_context_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use \n",
    "\n",
    "    .size()\n",
    "    \n",
    "with .groupby() to get the word counts per time.  We can also call\n",
    "\n",
    "    .to_frame()\n",
    "\n",
    "to tell pandas what to name the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th>5yrperiod</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\"></th>\n",
       "      <th>1985.0</th>\n",
       "      <td>10972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990.0</th>\n",
       "      <td>21075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995.0</th>\n",
       "      <td>21227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000.0</th>\n",
       "      <td>19087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005.0</th>\n",
       "      <td>20392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§</th>\n",
       "      <th>2000.0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§114</th>\n",
       "      <th>1995.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§16(f)(3)</th>\n",
       "      <th>2000.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§441(b)</th>\n",
       "      <th>1995.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§441b</th>\n",
       "      <th>1995.0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77508 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count\n",
       "keyword   5yrperiod       \n",
       "          1985.0     10972\n",
       "          1990.0     21075\n",
       "          1995.0     21227\n",
       "          2000.0     19087\n",
       "          2005.0     20392\n",
       "...                    ...\n",
       "§         2000.0         4\n",
       "§114      1995.0         2\n",
       "§16(f)(3) 2000.0         1\n",
       "§441(b)   1995.0         1\n",
       "§441b     1995.0         3\n",
       "\n",
       "[77508 rows x 1 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_per_period = word_context_words.groupby(['keyword', '5yrperiod']).size().to_frame('count')\n",
    "words_per_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Groupby Word and Period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new data structure where we group by keyword AND period.\n",
    "\n",
    "If we organize our data this way, we will preserve information about the context for how each word was spoken about, across all companies, in 1994, 2011, etc.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, we could groupby('keyword', '5yrperiod'). However, later on, we're going to want to call vectors of data by an index that references both word and period. So it's better if we just create a new column for the data called 'wpord-period,' and groupby() that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word-period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>The-2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>Chair-2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>again-2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>informs-2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Chair again informs the Senator from Calif...</td>\n",
       "      <td>the-2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007998</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>to-2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007999</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>do-2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008000</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>off-2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008001</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>the-2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008002</th>\n",
       "      <td>I have something I have to do off the floor</td>\n",
       "      <td>floor-2005.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1008003 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence     word-period\n",
       "0        The Chair again informs the Senator from Calif...      The-2000.0\n",
       "1        The Chair again informs the Senator from Calif...    Chair-2000.0\n",
       "2        The Chair again informs the Senator from Calif...    again-2000.0\n",
       "3        The Chair again informs the Senator from Calif...  informs-2000.0\n",
       "4        The Chair again informs the Senator from Calif...      the-2000.0\n",
       "...                                                    ...             ...\n",
       "1007998        I have something I have to do off the floor       to-2005.0\n",
       "1007999        I have something I have to do off the floor       do-2005.0\n",
       "1008000        I have something I have to do off the floor      off-2005.0\n",
       "1008001        I have something I have to do off the floor      the-2005.0\n",
       "1008002        I have something I have to do off the floor    floor-2005.0\n",
       "\n",
       "[1008003 rows x 2 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_word_period = word_context_words.copy()\n",
    "word_context_word_period['word-period'] = word_context_word_period['keyword'] + \"-\" + word_context_word_period['5yrperiod'].astype(str)\n",
    "word_context_word_period = word_context_word_period.drop(['5yrperiod', 'keyword'], 1)\n",
    "word_context_word_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_grouped = word_context_word_period.groupby(['word-period']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word-period</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>!--1995.0</th>\n",
       "      <td>It would be of greal - benefit to the future ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!-1995.0</th>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!imit-1990.0</th>\n",
       "      <td>this Member successfully pushed in the author...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!ine-1995.0</th>\n",
       "      <td>will continue to ensure a growing and efficie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"$12-1990.0</th>\n",
       "      <td>strike out \"$12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§-2000.0</th>\n",
       "      <td>§ 16(e)) containing the requirement that cour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§114-1995.0</th>\n",
       "      <td>Day casts serious doubt on §11410(c)(1)s requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§16(f)(3)-2000.0</th>\n",
       "      <td>§16(f)(3) intervention by interested parties ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§441(b)-1995.0</th>\n",
       "      <td>and instead looked to the particular characte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>§441b-1995.0</th>\n",
       "      <td>Court recognized that §441b took account of th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77508 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           sentence\n",
       "word-period                                                        \n",
       "!--1995.0          It would be of greal - benefit to the future ...\n",
       "!-1995.0                                                          !\n",
       "!imit-1990.0       this Member successfully pushed in the author...\n",
       "!ine-1995.0        will continue to ensure a growing and efficie...\n",
       "\"$12-1990.0                                         strike out \"$12\n",
       "...                                                             ...\n",
       "§-2000.0           § 16(e)) containing the requirement that cour...\n",
       "§114-1995.0        Day casts serious doubt on §11410(c)(1)s requ...\n",
       "§16(f)(3)-2000.0   §16(f)(3) intervention by interested parties ...\n",
       "§441(b)-1995.0     and instead looked to the particular characte...\n",
       "§441b-1995.0      Court recognized that §441b took account of th...\n",
       "\n",
       "[77508 rows x 1 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this new output, the 'context' column has all the words from all the sentences that contain the 'keyword' of that row in a given period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word-period</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chairwoman-2005.0</th>\n",
       "      <td>I wish to take a second to thank Chairwoman M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chairwoman-2010.0</th>\n",
       "      <td>I want to recognize the work of Chairwoman CL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-1985.0</th>\n",
       "      <td>I also want to commend Congressman FRANK who ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-1990.0</th>\n",
       "      <td>Congresswoman NANCY JOHNSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-1995.0</th>\n",
       "      <td>Congresswoman Congresswoman Congresswoman JAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-2000.0</th>\n",
       "      <td>Congresswoman EDDIE BERNICE JOHNSON Congressw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-2005.0</th>\n",
       "      <td>FY2010 Energy and Water Development and Relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Congresswoman-2010.0</th>\n",
       "      <td>Congresswoman CLARKE including Congressman LA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Councilwoman-1990.0</th>\n",
       "      <td>Councilwoman Clarks strong belief In educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assemblywoman-1985.0</th>\n",
       "      <td>And as she rose to the precedent setting rank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chairwoman-1995.0</th>\n",
       "      <td>and it asks the President to sign off on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chairwoman-2005.0</th>\n",
       "      <td>I have recently had conversations with the ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>councilwoman-1990.0</th>\n",
       "      <td>councilwoman at large in the Philadelphia Cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-1985.0</th>\n",
       "      <td>I would inform the gentlewoman from Nebraska ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-1990.0</th>\n",
       "      <td>I yield 1 minute to the distinguished gentlew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-1995.0</th>\n",
       "      <td>and the gentlewoman from Hawaii the gentlewom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-2000.0</th>\n",
       "      <td>I commend the gentlewoman from California and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-2005.0</th>\n",
       "      <td>I would like to yield 3 minutes to the gentle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewoman-2010.0</th>\n",
       "      <td>I want to acknowledge the extraordinary work ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewomans-1995.0</th>\n",
       "      <td>I said I was going to accept the gentlewomans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewomans-2005.0</th>\n",
       "      <td>So I would hope we would oppose the gentlewom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gentlewomans-2010.0</th>\n",
       "      <td>though I am not opposed to the gentlewomans a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jentlewoman-1995.0</th>\n",
       "      <td>I want to applaud the jentlewoman from New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tlewoman-2000.0</th>\n",
       "      <td>the gent Alabama tlewoman from California eac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-1985.0</th>\n",
       "      <td>And surely in this category we would also fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-1990.0</th>\n",
       "      <td>If we extended Medicaid coverage to all pregn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-1995.0</th>\n",
       "      <td>It is so flexible that a working woman who wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-2000.0</th>\n",
       "      <td>Laci and Conners story is only one of many in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-2005.0</th>\n",
       "      <td>Sergeant Hester sounds like an absolutely fab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman-2010.0</th>\n",
       "      <td>As a young woman woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman?-I-2000.0</th>\n",
       "      <td>When they ask mewhat is my government doing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womancomports-1995.0</th>\n",
       "      <td>I believe that the traditional family structu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womans-1995.0</th>\n",
       "      <td>That landmark decision recognized a womans fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>womans-2000.0</th>\n",
       "      <td>Opponents of the Unborn Victims of Violence A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               sentence\n",
       "word-period                                                            \n",
       "Chairwoman-2005.0      I wish to take a second to thank Chairwoman M...\n",
       "Chairwoman-2010.0      I want to recognize the work of Chairwoman CL...\n",
       "Congresswoman-1985.0   I also want to commend Congressman FRANK who ...\n",
       "Congresswoman-1990.0                        Congresswoman NANCY JOHNSON\n",
       "Congresswoman-1995.0   Congresswoman Congresswoman Congresswoman JAN...\n",
       "Congresswoman-2000.0   Congresswoman EDDIE BERNICE JOHNSON Congressw...\n",
       "Congresswoman-2005.0   FY2010 Energy and Water Development and Relat...\n",
       "Congresswoman-2010.0   Congresswoman CLARKE including Congressman LA...\n",
       "Councilwoman-1990.0    Councilwoman Clarks strong belief In educatio...\n",
       "assemblywoman-1985.0   And as she rose to the precedent setting rank...\n",
       "chairwoman-1995.0      and it asks the President to sign off on the ...\n",
       "chairwoman-2005.0      I have recently had conversations with the ch...\n",
       "councilwoman-1990.0    councilwoman at large in the Philadelphia Cit...\n",
       "gentlewoman-1985.0     I would inform the gentlewoman from Nebraska ...\n",
       "gentlewoman-1990.0     I yield 1 minute to the distinguished gentlew...\n",
       "gentlewoman-1995.0     and the gentlewoman from Hawaii the gentlewom...\n",
       "gentlewoman-2000.0     I commend the gentlewoman from California and...\n",
       "gentlewoman-2005.0     I would like to yield 3 minutes to the gentle...\n",
       "gentlewoman-2010.0     I want to acknowledge the extraordinary work ...\n",
       "gentlewomans-1995.0    I said I was going to accept the gentlewomans...\n",
       "gentlewomans-2005.0    So I would hope we would oppose the gentlewom...\n",
       "gentlewomans-2010.0    though I am not opposed to the gentlewomans a...\n",
       "jentlewoman-1995.0      I want to applaud the jentlewoman from New York\n",
       "tlewoman-2000.0        the gent Alabama tlewoman from California eac...\n",
       "woman-1985.0           And surely in this category we would also fin...\n",
       "woman-1990.0           If we extended Medicaid coverage to all pregn...\n",
       "woman-1995.0           It is so flexible that a working woman who wo...\n",
       "woman-2000.0           Laci and Conners story is only one of many in...\n",
       "woman-2005.0           Sergeant Hester sounds like an absolutely fab...\n",
       "woman-2010.0                                     As a young woman woman\n",
       "woman?-I-2000.0        When they ask mewhat is my government doing t...\n",
       "womancomports-1995.0   I believe that the traditional family structu...\n",
       "womans-1995.0          That landmark decision recognized a womans fu...\n",
       "womans-2000.0          Opponents of the Unborn Victims of Violence A..."
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_context_grouped.filter(like = 'woman', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to see how 'woman' changed its meaning in Congress from 1985 to 2005."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Word Context Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=10000, lowercase=True, ngram_range=(1, 1), analyzer = \"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we feed the vectorizer the column 'sentence' because we want to model the CONTEXT in which each keyword appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized = vectorizer.fit_transform(word_context_grouped['sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the vectors as a dataframe where every column is a word and every row a period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_words = np.array(vectorizer.get_feature_names())\n",
    "context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_period = list(word_context_grouped.axes[0].to_numpy())\n",
    "word_period[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_dataframe = pd.DataFrame(vectorized.todense(), # the matrix we saw above is turned into a dataframe\n",
    "                                 columns=context_words,\n",
    "                                 index = word_period\n",
    "                                 )\n",
    "vectors_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = vectorized.todense()\n",
    "matr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking measurements of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our last exercise, we measured how different individual words were from each other.\n",
    "\n",
    "Let's do it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_1985_vector = vectors_dataframe.filter(regex = ('^woman-1985'), axis=0) # the caret (^) means 'begins with'\n",
    "woman_1985_vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_1990_vector = vectors_dataframe.filter(regex = '^woman-1990', axis=0)\n",
    "woman_1995_vector = vectors_dataframe.filter(regex = '^woman-1995', axis=0)\n",
    "woman_2000_vector = vectors_dataframe.filter(regex = '^woman-2000', axis=0)\n",
    "woman_2005_vector = vectors_dataframe.filter(regex = '^woman-2005', axis=0)\n",
    "woman_1990_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors_dataframe is nice to use because its rows and columns are nicely labeled.  It's easy to call exactly the keyword-period combination you want.  \n",
    "\n",
    "You can use the rows directly pulled from vectors_dataframe as the basis for calculating cosine distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.spatial.distance.cosine(woman_1985_vector, woman_1990_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.spatial.distance.cosine(woman_1985_vector, woman_1995_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.spatial.distance.cosine(woman_1985_vector, woman_2000_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.spatial.distance.cosine(woman_1985_vector, woman_2005_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtracting vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we called the rows of vectors_dataframe directly to calculate cosine distances.  \n",
    "\n",
    "We can use these same vectors to execute a subtraction -- with a bit of reformatting.\n",
    "\n",
    "First, we \"transmute\" them from a horizontal row of values to a vertical row of values with \n",
    "\n",
    "    .T\n",
    "\n",
    "\n",
    "Next, we call the columns with the values by name, e.g.: \n",
    "\n",
    "    ['woman-1985.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = woman_1995_vector.T['woman-1995.0'] - woman_1985_vector.T['woman-1985.0']\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We \"sort\" the values from small to big using:\n",
    "\n",
    "    .sort_values()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: use \n",
    "    \n",
    "    .dropna() \n",
    "    \n",
    "to get rid of NaN's (not a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff.dropna().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the words that changed the most in the context of 'woman' between 1985 and 1995."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare words used for 'man' and 'woman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a vector that contains all the references to women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = ['woman','women','\\bshe','\\bher','\\bhers','girl']\n",
    "woman_vector = vectors_dataframe.loc[[x for x in vectors_dataframe.index for word in pattern if word in x]]\n",
    "\n",
    "woman_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the data we want, all right. But it'd be more useful as a matrix where all the columns are added together. \n",
    "\n",
    "That's easy to do with \n",
    "\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_vector = woman_vector.sum()\n",
    "woman_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now let's look for men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern2 = ['\\bhe\\b','\\bhim','\\bhis','\\bman\\b','\\bmen\\b','boy\\b','boys']\n",
    "man_vector = vectors_dataframe.loc[[x for x in vectors_dataframe.index for word in pattern2 if word in x]]\n",
    "man_vector = man_vector.sum()\n",
    "man_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_diff_vector = man_vector - woman_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_diff_vector.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of gender_diff_vector.sort_values() is predictive of the words most likely to refer to women (the negatives) and the words most likely to indicate men (the higher positives.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point in the code, we're shifting from word vectors made with SKLEARN to word \"embeddings\" made with the GENSIM package.\n",
    "\n",
    "GENSIM uses higher-level math to condense the matrices, meaning that we'll be able to deal with more information than the downsized sample above. Word embeddings like GENSIM also typically have a \"hidden layer\" of modeling which includes information about word order and part-of-speech, designed to make the word vectors more accurate models of the way that words are used in sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resample the data and create data structure (again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a larger sample than we did last time. We'll need to break it into sentences and words again, and group by the features of the data that we care about -- keyword and period -- again.\n",
    "\n",
    "Because you've seen the instructions above, we'll skip them below and just give the code.\n",
    "\n",
    "NOTE: the lines below may take a while. Splitting sentences and words can be intensive on a dataset of this scale. If it's not working for you, try sample_m or sample where you see sample_l in the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_m = make_sentences(sample_l['speech']).copy() # <---- switch out sample_l to sample_s or sample_m here\n",
    "word_context_sentences_m = pd.concat([pd.DataFrame({'sentence': speech, '5yrperiod': row['5yrperiod']}, index=[0]) \n",
    "           for _, row in sample.iterrows() \n",
    "           for speech in row['speech'].split('.') if speech != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_m[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to model a larger set of data in Congress from 1985 to 2005 with the help of GENSIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break sentences into words (for later use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the code for breaking up sentences into words. We'll need words_per_period later in the code. You've seen the detailed code before, so here's the quick version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_context2 = word_context_sentences_m.copy()\n",
    "index_context2['index'] = np.arange(len(index_context2)) # create an 'index' column\n",
    "word_per_row2 = index_context2.set_index('index')\n",
    "word_per_row2 =pd.concat([word_per_row2['sentence'].str.split(' ').explode()],axis=1).reset_index() #explode the data \n",
    "word_per_row2 = word_per_row2.rename({'sentence' : 'keyword'}, axis = 1) # rename the column \"sentence\" to \"keyword\"\n",
    "word_context_words2 = pd.merge(word_per_row2, index_context2, on=\"index\") # merge the two df's\n",
    "word_context_words2 = word_context_words2.drop('index', 1) # get rid of the index column because we don't need it any more\n",
    "word_context_words2['keyword'] = word_context_words2['keyword'].str.strip() # strip the whitespace\n",
    "words_per_period2 = word_context_words2.groupby(['keyword', '5yrperiod']).size().to_frame('count')\n",
    "words_per_period2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up GENSIM\n",
    "\n",
    "The first step is to \"train\" the GENSIM model with the function `gensim.models.Word2Vec()`. This function has a couple dozen parameters, some of which are more important than others.\n",
    "\n",
    "Here are a few major ones. Only two are MANDATORY: these are marked with an asterisk:\n",
    "\n",
    "1. `sentences*`: This is where you provide your data. It must be in a format of iterable of iterables.\n",
    "2. `sg`: Your choice of training algorithm. There are two standard ways of training W2V vectors -- 'skipgram' and 'CBOW'. If you enter 1 here the skip-gram is applied; otherwise, the default is CBOW.\n",
    "3. `size*`: This is the length of your resulting word vectors. If you have a large corpus (>few billion tokens) you can go up to 100-300 dimensions. Generally word vectors with more dimensions give better results.\n",
    "4. `window`: This is the window of context words you are training on. In other words, how many words come before and after your given word. A good number is 4 here but this can vary depending on what you are interested in. For instance, if you are more interested in embeddings that embody semantic meaning, smaller window sizes work better. \n",
    "5. `alpha`: The learning rate of your model. If you are interested in machine learning experimentation with your vectors you may experiment with this parameter.\n",
    "6. `seed` (int): This is the random seed for your random initialization. All deep learning models initialize the weights with random floats before training. This is a useful field if you want to replicate your experiments because giving this a seed will initialize 'randomly' deterministically.\n",
    "7. `min_count`: This is the minimum frequency threshold. If a given word appears with lower frequency than provided it will be ignored. This is here because words with very low frequency are hard to train.\n",
    "8. `iter`: This is the number of iterations(entire run) over the corpus, also known as epochs. Usually anything between 1-10 is ok. The trade offs are that if you have higher iterations, it will take longer to train and the model may overfit on your dataset. However, longer training will allow your vectors to perform better on tasks relevant to your dataset.\n",
    "\n",
    "Most of these settings will not concern us. As you'll see below, we are only going to use four arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model = gensim.models.Word2Vec(\n",
    "    sentences = sentences_m,\n",
    "    min_count = 2, # remove words stated only once\n",
    "    size = 100) # size of neuralnet layers; default is 100; higher for larger corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save our model in case we want to use it again in a later session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.save('congress_model')\n",
    "# hansard_model = gensim.models.Word2Vec.load('hansard_model') # to load a saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can load a model in the same way (remember this from our topic model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model = gensim.models.Word2Vec.load('congress_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `wv.index2word` allows us to see the words in our model (but careful! congress_model.wv.vocab will print out every word in the corpus -- a very long list!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.index2word[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model itself is -- like the SKLEARN CountVectors model -- a matrix of vectors. Every row corresponds to the counts for one word. We can call the entire matrix or call up one row at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the fourth row of the model, represented as a word and as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = congress_model.wv.index2word[3]\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.vectors[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting Word Context with the GENSIM model, one word at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GENSIM model has all sorts of tools built in for navigating and inspecting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the word context vector for any individual word by using:\n",
    "\n",
    "    model.wv['word']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the words with the highest counts in the context vector for 'man'. In other words, these are words that appear most commonly around 'man' in our sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_vector = congress_model.wv['man']\n",
    "congress_model.wv.similar_by_vector(man_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_vector = congress_model.wv['woman']\n",
    "congress_model.wv.similar_by_vector(woman_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_vector = congress_model.wv['individual']\n",
    "congress_model.wv.similar_by_vector(individual_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soldier_vector = congress_model.wv['soldier']\n",
    "congress_model.wv.similar_by_vector(soldier_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance and Similarity with Vectors in GENSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity is cosine similarity -- it's 1 minus cosine distance.  You've used cosine distance before -- you're a whiz with cosine distance already. \n",
    "\n",
    "With similarity, the higher the number, the more alike two terms are in the context in which they are used. \n",
    "\n",
    "When we used cosine distance before, we were doing it one vector at a time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.similarity('women', 'men')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What other words have similar context vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the beauty of the GENSIM package is that it has pre-run all the word vectors for you. So it can call up the most similar word context vectors to the word context vector of any word, using the command, 'most_similar()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the GENSIM documentation: \"This method computes cosine similarity between a simple mean of the projection weight vectors of the given words and the vectors for each word in the model.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.most_similar(\"women\", topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. So, according to our model, women are like men and individuals and soldiers; they're also like students and parents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting vector similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we get carried away, remember that these results come from a *different* mode of analysis than the CONTEXT VECTOR above.  The results here don't indicate that the words \"individuals\" or \"soldiers\" regularly occur in sentneces with the word \"women.\"  \n",
    "\n",
    "Instead, the model indicates that \"individuals\" and \"soldiers\" are often talked about with the same words that men and women are talked about.  They have employers, wages, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the word context vectors that are most similar to 'men'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.most_similar(\"men\", topn = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that men are spoken about almost in entirely the same context as women. But if women are spoken about in the same context as children, men are spoken about slightly more often in the same context as their homes. (what you see may vary with a different sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**: everything the model knows it knows from our corpus. What we're learning are assumptions *immanent* to the corpus.  These aren't FACTS about women or men -- these are data about how women and men were spoken about in Congress, 1985-2005.\n",
    "\n",
    "Both `word2vec` and our model have limitations.\n",
    "\n",
    "Additionally, our training set is selective and small (just a subset of some debates about the environment). Therefore, our analogies can return some wild cards. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.most_similar(\"america\", topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. America is spoken about like freedom, like Iraq, and like the world. It's in a downturn, and when we speak of America, we speak of the same contexts in which we invoke democracy, drugs, and the interests of different peoples, especially workers. (what you see may vary with a different sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try your own hand at interpreting these outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.most_similar(\"iraq\", topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret these similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress_model.wv.most_similar(\"britain\", topn = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the similarities\n",
    "\n",
    "You'll recall that in Sarah Connell's blog entry, researchers produced a \"dendrogram\" of words related to other words, which we learned was created on the basis of cosine distance scores between word vectors.\n",
    "\n",
    "This dendrogram was used to compare the meaning of \"freedom\" in the seventeenth century (when the word was nearest in meaning to \"friendship\") to the meaning of \"freedom\" in the eighteenth century (when the word became associated with nations and patriotism).\n",
    "\n",
    "Let's see if we can make a dendrogram of words for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \n",
    "\n",
    "    linkage()\n",
    "    \n",
    "command performs hierarchical clustering -- in other words, it takes the Euclidean similarity score between any two vectors, and then ranks them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['dream', 'bombing', 'warfare', 'racism', 'prosperity', 'wealth', 'happiness', 'today', 'tomorrow', 'past', 'present', 'future', 'america', 'france', 'britain', 'iraq', 'china', 'democratic', 'dictator', 'totalitarian', 'democracy', 'welfare', 'socialism', 'communism', 'russia', 'congress', 'debate', 'hearing', 'protest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: if you get an error because any of the words above aren't in your sample corpus, edit the list and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_vectors = congress_model.wv[keywords]\n",
    "keyword_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "links = linkage(keyword_vectors, method='complete', metric='seuclidean')\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ranking gives us a read of which vectors are closest to which vectors.  We can visualize it using matplotlib and the \"dendrogram\" command from SKLEARN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "l = links\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.ylabel('word')\n",
    "plt.xlabel('distance')\n",
    "\n",
    "dendrogram(\n",
    "    l,\n",
    "    leaf_rotation=0,  # rotates the x axis labels\n",
    "    leaf_font_size=16,  # font size for the x axis labels\n",
    "    orientation='left',\n",
    "    leaf_label_func=lambda v: str(keywords[v])\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a little tweaking, you can create a list of only those vectors for the words most of interest to you, using GENSIM to visualize their similarity to each other in the corpus.\n",
    "\n",
    "You could even -- like Connell's blog entry indicates -- create a separate dendrogram for 1985 and another for 2005, to see how these terms have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtracting Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll recall that we've used vector subtraction before.  Subtracting the context for \"woman\" from the context for \"man\" produces a vector of high scores for the words that only appear around \"man\" but not woman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = congress_model.wv['man'] - congress_model.wv['woman']\n",
    "congress_model.wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = congress_model.wv['woman'] - congress_model.wv['man']\n",
    "congress_model.wv.similar_by_vector(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Abstract Relatedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The four words making up the analogy can be understood as points in space where each word represents a single point. These points represent words' relationships with one-another.\n",
    "\n",
    "Let's borrow more of Sinykin's code to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "def display_pca_scatterplot(model, words=None, sample=0):\n",
    "    if words == None:\n",
    "        if sample > 0:\n",
    "            words = np.random.choice(list(model.wv.vocab.keys()), sample)\n",
    "        else:\n",
    "            words = [ word for word in model.wv.vocab ]\n",
    "        \n",
    "    word_vectors = np.array([model[w] for w in words])\n",
    "\n",
    "    twodim = PCA().fit_transform(word_vectors)[:,:2]\n",
    "    \n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(twodim[:,0], twodim[:,1], edgecolors='k', c='r')\n",
    "    for word, (x,y) in zip(words, twodim):\n",
    "        plt.text(x+0.05, y+0.05, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_pca_scatterplot(congress_model.wv, keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truth be told, I don't love this visualization; it's visualizing abstract relationships that show the conceptual distance between different entities in the model. I present it to you as a cute toy, not as an approved visualization that i'd like to see in your work. \n",
    "\n",
    "Please use PCA analysis with care; it's almost impossible to get back to what it actually *means* -- at least without pairing it with other visualizations and measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Time with GENSIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might recall that there's a lot of data that we're not using, for instance, the 5yrperiod field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we make use of it?  How about a for loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodnames = sample_m['5yrperiod'].unique().tolist()\n",
    "periodnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might take a while, since we're creating 6 different gensim models. Fortunately, we're saving all of them, so if you want to go back and run this for a different word later, you can just load the old data rather than running the whole thing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_context = [] # create an empty dummy variable\n",
    "\n",
    "for period1 in periodnames:\n",
    "    period_data = sample_m[sample_m['5yrperiod'] == period1] # select one period at a time\n",
    "    print('mining ', period1)\n",
    "    sentences = make_sentences(sample_m['speech']).copy() # break data into sentences for that period only \n",
    "    ####### tweak here after the first run to use the old data without generating it again\n",
    "     period_model = gensim.models.Word2Vec( # make a gensim model for that data\n",
    "        sentences = sentences,\n",
    "        min_count = 2, \n",
    "        size = 100)  \n",
    "    period_model.save('model-' + str(period1)) # save the model with the name of the period\n",
    "    #period_model = gensim.models.Word2Vec.load('model-' + str(period1)) # to load a saved model\n",
    "    ###########\n",
    "    women_context_period = period_model.wv.most_similar(\"woman\", topn = 1000) # extract the context of how women were talked about in that period\n",
    "    women_context.append(women_context_period) # save the context of how women were talked about for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should be a list of context vectors for each period, which we can use to show how the context of 'woman' was changing from period to period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_context[0][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_context[5][0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can grab just the names this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item[0] for item in women_context[1]][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can grab just the numbers for any given year (in this case, the second period -- 1990 -- [1]) this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item[1] for item in women_context[1]][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's annotate the data with how many times women were referred to over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we made a nice dataframe of how many times each word appears over a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_per_period2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_per_year = words_per_period2[words_per_period2['keyword'=='woman']]\n",
    "keyword_per_year[keyword_per_year['5yrperiod'=='1985']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a flattened list of all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for i in range(5):\n",
    "    words = [item[0] for item in women_context[i]][:10]\n",
    "    all_words.append(words)\n",
    "\n",
    "all_words2 = []\n",
    "for list in all_words:\n",
    "    for word in list:\n",
    "        all_words2.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linspace\n",
    "colors = [ cm.jet(x) for x in linspace(.5, 2, 50) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dots and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# change the figure's size here\n",
    "plt.figure(figsize=(5,5), dpi = 200)\n",
    "\n",
    "# plt.annotate only plots one label per iteration, so we have to use a for loop \n",
    "for i in range(len(periodnames)):    # cycle through the period names\n",
    "    \n",
    "    xx = periodnames[i]        # on the x axis, plot the period name\n",
    "    yyy = keyword_per_year[i]  # how many times was the keyword used that year?\n",
    "\n",
    "    # for each period, one big black dot\n",
    "    \n",
    "    plt.scatter(                                           # plot dots\n",
    "            xx, #x axis\n",
    "            yyy, # y axis\n",
    "            linewidth=1, \n",
    "            color = 'black',\n",
    "            s = 10, # dot size\n",
    "            alpha=0.2)  # dot transparency\n",
    "\n",
    "                     \n",
    "                     \n",
    "    for j in range(10):     # cycle through the first ten words (you can change this variable)\n",
    "        \n",
    "        yy = [item[1] for item in women_context[i]][j]         # on the y axis, plot the distance -- how closely the word is related to the keyword\n",
    "        txt = [item[0] for item in women_context[i]][j]        # grab the name of each collocated word\n",
    "        colorindex = all_words2.index(txt)                     # this command keeps all dots for the same word the same color\n",
    "        \n",
    "        plt.scatter(                                           # plot dots\n",
    "            xx, #x axis\n",
    "            yy, # y axis\n",
    "            linewidth=1, \n",
    "            color = colors[colorindex],\n",
    "            s = 3, # dot size\n",
    "            alpha=0.8)  # dot transparency\n",
    "\n",
    "                                                                # make a label for each word\n",
    "        plt.annotate(\n",
    "                txt,\n",
    "                (xx, yy),   \n",
    "                size = 5,\n",
    "                color = 'black', \n",
    "                alpha=0.8 # i've made the fonts transparent as well.  you could play with color and size if you wanted to. \n",
    "            )\n",
    "\n",
    "# Code to help with overlapping labels -- may take a minute to run\n",
    "adjust_text(texts, force_points=0.2, force_text=0.2,\n",
    "            expand_points=(1, 1), expand_text=(1, 1),\n",
    "            arrowprops=dict(arrowstyle=\"-\", color='black', lw=0.5))\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Add titles\n",
    "plt.title(\"Word Context Change for 'WOMAN'a Over Time in Congress\", fontsize=20, fontweight=0, color='Red')\n",
    "plt.xlabel(\"period\")\n",
    "plt.ylabel(\"similarity of word\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we make a dendrogram of a long list of interesting words and their contextual similarity. \n",
    "\n",
    "We also use a list of periods to create separate GENSIM models for each period.\n",
    "\n",
    "You will put these together to create a dendrogram for 1985 and another dendrogram for 1995 and 2005. \n",
    "\n",
    "#### Coding exercise\n",
    "   * Create a list of keywords that you think would be particularly relevant for Congress during this time -- something that might demonstrate historical change in ideas.\n",
    "        * Using the code above, create a GENSIM model for 1985, 1995, and 2005\n",
    "        * Using the code above, create an array of vectors for your words for each time period\n",
    "        * Using the code above, draw a dendrogram of keyword relatedness for the three time periods.\n",
    "    \n",
    "#### Interpretation exercise    \n",
    "   * Write an interpretive paragraph of at least half a page examining what this dendrogram suggests about change over time.  If there's not enough material in your first experiment, tweak the keyword list and try again -- until you have something to say about history.\n",
    "\n",
    "\n",
    "Turn in your work on Canvas. Do not turn in an ipynb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
