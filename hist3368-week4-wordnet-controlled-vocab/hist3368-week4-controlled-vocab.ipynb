{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week4-wordnet-controlled-vocab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 Assignment: Working With a Controlled Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by tutorials by Paige McKenzie - https://p-mckenzie.github.io/2018/01/11/Jane-Austen/\n",
    "William Scott - https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of this notebook, we'll be working with a 'controlled vocabulary,' which is to say, expert-defined words that help to limit our pursuit of wordcount to words that share a certain semantic valence.  Controlled Vocabularies have been used in digital history to examine the history of words used by Victorian people to describe the way that strangers walked down the street, and to show that novelists in the nineteenth century described the urban landscape with increasing detail.  \n",
    "\n",
    "First, we'll download some novels by Jane Austen to try our vocabulary on.  Then, we'll talk about how to clean the text using stemming and lemmatization.  \n",
    "\n",
    "Next, we'll use a controlled vocabulary to limit the count to words that are interesting to us.  Then, we'll expand that controlled vocabulary using the 'hyponym' feature of the WordNet package, which consults with dictionaries of the English language organized by linguists at Princeton.  \n",
    "\n",
    "Finally, we'll visualize our findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download some Jane Austen Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, numpy, re, matplotlib# , num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/group/history/hist_3368-jguldi\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download some data\n",
    "\n",
    "with open('senseandsensibility.txt', 'r') as myfile:\n",
    "    sas_data = myfile.read().split('\\n\\n\"I suppose you know, ma\\'am, that Mr. Ferrars is married\"\\n\\nIt _was_ Edward\\n\\n\"Everything in such respectable condition\"\\n\\n ')[1].split('THE END')[0].strip()\n",
    "\n",
    "with open('emma.txt', 'r') as myfile:\n",
    "    emma_data = myfile.read().split('CHAPTER I')[1].split('FINIS')[0].strip()\n",
    "\n",
    "with open('prideandprejudice.txt', 'r') as myfile:\n",
    "    pap_data = myfile.read().split('CHAPTER I')[1].split('End of the Project Gutenberg EBook of Pride and Prejudice, by Jane Austen')[0].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your data matches what you think it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *\\n\\n\\n\\n\\nCHAPTER I\\n\\n\\nThe family of Dashwood had long been settled in Sussex. Their estate\\nwas large, and their residence was at Norland Park, in the centre of\\ntheir property, where, for many generations, they had lived in so\\nrespectable a manner as to engage the general good opinion of their\\nsurrounding acquaintance. The late owner of this estate was a single\\nman, who lived to a very advanced age, and who for many years of his\\nlife, had a constant companion and housekeeper in his sister. But her\\ndeath, which happened ten years before his own, produced a great\\nalteration in his home; for to supply her loss, he invited and\\nreceived into his house the family of his nephew Mr. Henry Dashwood,\\nthe legal inheritor of the Norland estate, and the person to whom he\\nintended to bequeath it. In the society of his nephew and niece, and\\ntheir children, the old Gentleman's days were comfortably spent. His\\nattachment to them all increased. The constant attention of Mr. and\\nMrs. Henry Dashwood to his wishes, which proceeded not merely from\\ninterest, but from goodness of heart, gave him every degree of solid\\ncomfort which his age could receive; and the cheerfulness of the\\nchildren added a relish to his existence.\\n\\nBy a former marriage, Mr. Henry Dashwood had one son: by his present\\nlady, three daughters. The son, a steady respectable young man, was\\namply provided for by the fortune of his mother, which had been large,\\nand half of which devolved on him on his coming of age. By his own\\nmarriage, likewise, which happened soon afterwards, he added to his\\nwealth. To him therefore the succession to the Norland estate was not\\nso really important as to his sisters; for their fortune, independent\\nof what might arise to them from their father's inheriting that\\nproperty, could be but small. Their mother had nothing, and their\\nfather only seven thousand pounds in his own disposal; for the\\nremaining moiety of his first wife's fortune was also secured to her\\nchild, an\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing only first 2000 characters.\n",
    "sas_data[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "Isn't it getting tired, retyping the same command for each novel? Let's throw them all into one data set so we can loop through them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *\\n\\n\\n\\n\\nCHAPTER I\\n\\n\\nThe family of Dashwood had long been settled in Sussex. Their estate\\nwas large, and their residence was at Norland Park, in the centre of\\ntheir property, where, for many generations, they had lived in so\\nrespectable a manner as to engage the general good opinion of their\\nsurrounding acquaintance. The late owner of this estate was a single\\nman, who lived to a very advanced age, and who for many years of his\\nlife, had a constant companion and housekeeper in his sister. But her\\ndeath, which happened ten years before his own, produced a great\\nalteration in his home; for to supply her loss, he invited and\\nreceived into his house the family of his nephew Mr. Henry Dashwood,\\nthe legal inheritor of the Norland estate, and the person to whom he\\nintended to bequeath it. In the society of his nephew and niece, and\\ntheir children, the old Gentleman's days were comfortably spent. His\\nattachment to them all increased. The constant attention of Mr. and\\nMrs. Henry Dashwood to his wishes, which proceeded not merely from\\ninterest, but from goodness of heart, gave him every degree of solid\\ncomfort which his age could receive; and the cheerfulness of the\\nchildren added a relish to his existence.\\n\\nBy a former marriage, Mr. Henry Dashwood had one son: by his present\\nlady, three daughters. The son, a steady respectable young man, was\\namply provided for by the fortune of his mother, which had been large,\\nand half of which devolved on him on his coming of age. By his own\\nmarriage, likewise, which happened soon afterwards, he added to his\\nwealth. To him therefore the succession to the Norland estate was not\\nso really important as to his sisters; for their fortune, independent\\nof what might arise to them from their father's inheriting that\\nproperty, could be but small. Their mother had nothing, and their\\nfather only seven thousand pounds in his own disposal; for the\\nremaining moiety of his first wife's fortune was also secured to her\\nchild, an\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = [sas_data, emma_data, pap_data]\n",
    "data[0][:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still appear to be some errors where spaces have been replaced by \"\\n\".  We'll get rid of those in a second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *     CHAPTER I   The family of Dashwood had long been settled in Sussex. Their estate was large, and their residence was at Norland Park, in the centre of their property, where, for many generations, they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance. The late owner of this estate was a single man, who lived to a very advanced age, and who for many years of his life, had a constant companion and housekeeper in his sister. But her death, which happened ten years before his own, produced a great alteration in his home; for to supply her loss, he invited and received into his house the family of his nephew Mr. Henry Dashwood, the legal inheritor of the Norland estate, and the person to whom he intended to bequeath it. In the society of his nephew and niece, and their children, the old Gentleman's days were comfortably spent. His attachment to them all increased. The constant attention of Mr. and Mrs. Henry Dashwood to his wishes, which proceeded not merely from interest, but from goodness of heart, gave him every degree of solid comfort which his age could receive; and the cheerfulness of the children added a relish to his existence.  By a former marriage, Mr. Henry Dashwood had one son: by his present lady, three daughters. The son, a steady respectable young man, was amply provided for by the fortune of his mother, which had been large, and half of which devolved on him on his coming of age. By his own marriage, likewise, which happened soon afterwards, he added to his wealth. To him therefore the succession to the Norland estate was not so really important as to his sisters; for their fortune, independent of what might arise to them from their father's inheriting that property, could be but small. Their mother had nothing, and their father only seven thousand pounds in his own disposal; for the remaining moiety of his first wife's fortune was also secured to her child, an\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\n', ' ')\n",
    "data[0][:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the text into words and print the first word of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*', '*', '*', '*', '*', 'CHAPTER', 'I', 'The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex.', 'Their', 'estate', 'was']\n",
      "['Emma', 'Woodhouse,', 'handsome,', 'clever,', 'and', 'rich,', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition,', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best']\n",
      "['.', 'It', 'is', 'a', 'truth', 'universally', 'acknowledged,', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune,', 'must', 'be', 'in']\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "    print(words[:20]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's lowercase the text and get rid of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # data[i] is the current novel\n",
    "    data[i] = data[i].lower() # force to lowercase\n",
    "    data[i] = re.sub('[\\\",.;:?([)\\]_*]', '', data[i]) # remove punctuation and special characters with regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of removing suffices, like \"ed\" or \"ing\".\n",
    "\n",
    "We will use another standard NLTK package, PorterStemmer, to do the stemming.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " 'i',\n",
       " 'the',\n",
       " 'famili',\n",
       " 'of',\n",
       " 'dashwood',\n",
       " 'had',\n",
       " 'long',\n",
       " 'been',\n",
       " 'settl',\n",
       " 'in',\n",
       " 'sussex',\n",
       " 'their',\n",
       " 'estat',\n",
       " 'wa',\n",
       " 'larg',\n",
       " 'and',\n",
       " 'their',\n",
       " 'resid',\n",
       " 'wa']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "st = PorterStemmer()\n",
    "\n",
    "stemmed_list = []\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "    for word in words:\n",
    "        stemmed = st.stem(word)\n",
    "        stemmed_list.append(stemmed)\n",
    "        \n",
    "stemmed_list[:20] # i have changed this so you print just the first words\n",
    "# printing all the words is actually way more computer intensive than it may seem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, \"universal\" becomes \"univers\" (which means that \"universally\" will be counted with \"universal\" and \"universe\") and \"single\" becomes \"singl\" (which means it would be counted with \"singled\").  But \"acknowledged\" has been left as it is.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick up another term -- lemmatization -- which is extremely memory intensive, but far more accurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aardwolf'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "wn.morphy('aardwolves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " 'i',\n",
       " 'family',\n",
       " 'have',\n",
       " 'long',\n",
       " 'be',\n",
       " 'settle',\n",
       " 'in',\n",
       " 'sussex',\n",
       " 'estate',\n",
       " 'wa',\n",
       " 'large',\n",
       " 'residence',\n",
       " 'wa',\n",
       " 'at',\n",
       " 'park',\n",
       " 'in',\n",
       " 'centre',\n",
       " 'property',\n",
       " 'many']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_list = []\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "    for word in words:\n",
    "        lemma = wn.morphy(word)\n",
    "        if not lemma:\n",
    "            # word is not a valid english word so skip it\n",
    "            continue\n",
    "        lemma_list.append(lemma)\n",
    "\n",
    "lemma_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is often a more useful approach than stemming because it leverages an understanding of the word itself to convert the word back to its root word. \"Acknowledged\"  becomes \"acknowledge,\" and \"daughters\" becomes \"daughter.\"  \n",
    "\n",
    "Note some important oddities -- words such as \"that\" are replaced by \"None,\" so if we count lemmas to graph them we will want to eliminate this noise.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming and lemmatization are important because they matter for how we count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 4214), ('the', 4191), ('of', 3692), ('and', 3543), ('her', 2598), ('a', 2161), ('i', 2014), ('in', 1992), ('wa', 1896), ('it', 1896), ('she', 1629), ('be', 1501), ('that', 1403), ('for', 1282), ('not', 1281), ('as', 1247), ('you', 1239), ('he', 1125), ('hi', 1048), ('had', 1032), ('with', 1010), ('have', 920), ('but', 862), ('at', 848), ('is', 780), ('by', 761), ('mr', 758), ('on', 703), ('all', 674), ('so', 661), ('him', 649), ('my', 638), ('elinor', 614), ('which', 600), ('could', 588), ('no', 570), ('from', 554), ('would', 527), ('veri', 525), ('they', 524), ('their', 506), ('mariann', 486), ('them', 484), ('been', 454), ('were', 451), ('what', 443), ('thi', 442), ('me', 429), ('more', 414), ('ani', 409), ('your', 407), ('said', 393), ('everi', 388), ('will', 385), ('such', 373), ('than', 372), ('do', 368), ('or', 360), ('an', 347), ('one', 333), ('when', 317), ('must', 305), ('if', 303), ('much', 301), ('onli', 299), ('own', 284), ('know', 282), ('who', 276), ('time', 264), ('sister', 262), ('herself', 257), ('dashwood', 255), ('did', 250), ('other', 249), ('think', 249), ('are', 247), ('am', 246), ('now', 241), ('miss', 241), ('how', 240), ('should', 240), ('there', 236), ('we', 229), ('see', 225), ('some', 222), ('ha', 222), ('though', 220), ('might', 218), ('say', 214), ('can', 212), ('thing', 211), ('well', 210), ('after', 207), ('edward', 207), ('mother', 205), ('befor', 201), ('jen', 200), ('never', 197), ('day', 185), ('noth', 182)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "count = Counter(stemmed_list)\n",
    "print(count.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words and N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the word counts look like now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 4092), ('to', 4090), ('of', 3573), ('and', 3419), ('her', 2522), ('a', 2048), ('i', 1948), ('in', 1937), ('was', 1848), ('it', 1701)]\n",
      "[('and', 107), ('to', 102), ('a', 92), ('of', 90), ('the', 81), ('her', 61), ('i', 49), ('you', 48), ('it', 45), ('in', 43)]\n",
      "[('you', 31), ('of', 29), ('to', 22), ('a', 21), ('the', 18), ('and', 17), ('i', 17), ('that', 15), ('it', 14), ('is', 14)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "    count = Counter(words)\n",
    "    print(count.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to look for multi-word phrases instead of individual words.  For example, if we're researching the living spaces of Jane Austen's England, we definitely want to know whether she refers to \"dining rooms\" or \"bed-rooms\" (which our punctuation clean-up might have turned into separate words, depending on what we did)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['chapter', 'i', 'the']),\n",
       " WordList(['i', 'the', 'family']),\n",
       " WordList(['the', 'family', 'of']),\n",
       " WordList(['family', 'of', 'dashwood']),\n",
       " WordList(['of', 'dashwood', 'had']),\n",
       " WordList(['dashwood', 'had', 'long']),\n",
       " WordList(['had', 'long', 'been']),\n",
       " WordList(['long', 'been', 'settled']),\n",
       " WordList(['been', 'settled', 'in']),\n",
       " WordList(['settled', 'in', 'sussex']),\n",
       " WordList(['in', 'sussex', 'their']),\n",
       " WordList(['sussex', 'their', 'estate']),\n",
       " WordList(['their', 'estate', 'wa']),\n",
       " WordList(['estate', 'wa', 'large']),\n",
       " WordList(['wa', 'large', 'and']),\n",
       " WordList(['large', 'and', 'their']),\n",
       " WordList(['and', 'their', 'residence']),\n",
       " WordList(['their', 'residence', 'wa']),\n",
       " WordList(['emma', 'woodhouse', 'handsome']),\n",
       " WordList(['woodhouse', 'handsome', 'clever'])]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "three_grams_list = []\n",
    "\n",
    "for novel in data:\n",
    "    # Get the first 20 words of the novel.\n",
    "    words = novel.split(maxsplit=20)\n",
    "    \n",
    "    # Delete the last entry of the list as it contains the rest of the novel's text.\n",
    "    del words[-1]\n",
    "    \n",
    "    # Lemmatize\n",
    "    lemmatized_words = []\n",
    "    for word in words:\n",
    "        lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    # Join the lemmatized words back into text.\n",
    "    text = ' '.join(lemmatized_words)\n",
    "    \n",
    "    # Collect the n-grams and extend it to our list of n grams\n",
    "    three_grams = TextBlob(text).ngrams(n=3)\n",
    "    three_grams_list.extend(three_grams)\n",
    "\n",
    "three_grams_list[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to be', 436), ('of the', 431), ('in the', 359), ('it was', 281), ('of her', 277), ('to the', 242), ('mrs jennings', 237), ('to her', 231), ('i am', 224), ('she was', 209)]\n",
      "[('” “', 29), ('miss taylor', 23), ('mr knightley', 13), ('of her', 12), ('mr weston', 12), ('of the', 10), ('to have', 9), ('it was', 9), ('her father', 9), ('she had', 9)]\n",
      "[('my dear', 8), ('that he', 6), ('mr bennet', 6), ('you must', 5), ('of them', 5), ('it is', 4), ('do not', 4), ('how can', 4), ('will be', 4), ('of the', 3)]\n"
     ]
    }
   ],
   "source": [
    "for novel in data:\n",
    "    bigrams = TextBlob(novel).ngrams(n=2)\n",
    "    bigram_counter = Counter()\n",
    "    for bigram in bigrams:\n",
    "        # Join the bigram into a string as it is a WordList object.\n",
    "        bigram_text = ' '.join(bigram)\n",
    "        # Update the count.\n",
    "        bigram_counter.update([bigram_text])\n",
    "\n",
    "    print(bigram_counter.most_common(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the for loop outputs three lists of ten -- the top ten bigrams for each novel.  The output is a 'dictionary' type.  What if you wanted it as a simple list of bigrams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'i the',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in',\n",
       " 'in sussex',\n",
       " 'sussex their',\n",
       " 'their estate',\n",
       " 'estate was',\n",
       " 'was large',\n",
       " 'large and',\n",
       " 'and their',\n",
       " 'their residence',\n",
       " 'residence was',\n",
       " 'was at']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_as_text = []\n",
    "\n",
    "for novel in data:\n",
    "    bigrams = TextBlob(novel).ngrams(n=2)\n",
    "    for bigram in bigrams:\n",
    "        bigram_text = ' '.join(bigram)\n",
    "        bigrams_as_text.append(bigram_text)\n",
    "\n",
    "bigrams_as_text[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the bigrams in one list, we can also count the overall top bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to be', 448),\n",
       " ('of the', 444),\n",
       " ('in the', 369),\n",
       " ('of her', 291),\n",
       " ('it was', 290),\n",
       " ('to the', 244),\n",
       " ('mrs jennings', 237),\n",
       " ('to her', 234),\n",
       " ('i am', 234),\n",
       " ('she was', 213),\n",
       " ('of his', 209),\n",
       " ('i have', 203),\n",
       " ('it is', 194),\n",
       " ('she had', 193),\n",
       " ('could not', 167),\n",
       " ('on the', 161),\n",
       " ('have been', 161),\n",
       " ('in a', 161),\n",
       " ('and the', 160),\n",
       " ('at the', 160)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_count = Counter(bigrams_as_text)\n",
    "top_twenty_bigrams = bigram_count.most_common(20)\n",
    "top_twenty_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only want the bigrams that include the word \"she\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('she was', 213),\n",
       " ('she had', 193),\n",
       " ('that she', 122),\n",
       " ('as she', 116),\n",
       " ('she could', 108)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "she_bigrams = []\n",
    "\n",
    "for bigram in bigrams_as_text:\n",
    "    if \"she\" in bigram: # notice the space after she.  It\n",
    "        she_bigrams.append(bigram)\n",
    "        \n",
    "Counter(she_bigrams).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the above code won't work for 'he,' because it will pick up other words that contain 'he.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 444),\n",
       " ('in the', 369),\n",
       " ('of her', 291),\n",
       " ('to the', 244),\n",
       " ('to her', 234)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigrams_as_text:\n",
    "    if \"he\" in bigram: # notice the space after she.  It\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "Counter(he_bigrams).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to use \"regular expressions,\" which are ways of coding the details of language.  You can communicate to the computer about such needs as detecting the beginning or end of a word by using two backslashes (an \"escape\" to tell the computer not to take the next letter literally) and \"b\" for \"boundary.\"  If you tell the computer to find a \"boundary\" in this way, it will look for both spaces and for the end of strings.\n",
    "\n",
    "Notice how I use two \"\\\\\\b\"'s below to tell the computer to look for the word \"he\" but not \"her\" or \"the.\" Python use the 're' package to detect regular expressions, and the .compile() and .match() commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"\\\\bhe\\\\b\") #  notice the .compile() and the \"escapes\"+b to signify \"word boundary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he was', 126),\n",
       " ('he had', 113),\n",
       " ('he is', 75),\n",
       " ('he has', 49),\n",
       " ('he did', 37)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigrams_as_text:\n",
    "    if pattern.match(bigram): # notice the use of .match()\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "Counter(he_bigrams).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlled Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for what scholars call a \"controlled vocabulary\" -- a list of words that we know to be meaningful. For right now, let's pretend that we're researching the buildings, landscape, and furniture of nineteenth-century England.  I'm curious about what kinds of spaces are described in Austen, and I'd like to begin by counting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "controlled_vocab = [\n",
    "    \"garden\",\n",
    "    \"room\", \n",
    "    \"estate\",\n",
    "    \"manor\", \n",
    "    \"hedge\", \n",
    "    \"residence\",\n",
    "    \"park\",\n",
    "    \"lane\",\n",
    "    \"chair\",\n",
    "    \"sofa\",\n",
    "    \"settee\",\n",
    "    \"bed\",\n",
    "    \"bedroom\",\n",
    "    \"chaise\",\n",
    "    \"table\",\n",
    "    \"rug\",\n",
    "    \"carpet\",\n",
    "    \"candelabra\",\n",
    "    \"shed\",\n",
    "    \"cottage\",\n",
    "    \"fence\",\n",
    "    \"turret\",\n",
    "    \"castle\",\n",
    "    \"palace\",\n",
    "    \"hut\",\n",
    "    \"dwelling\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'estate': 19,\n",
       "         'residence': 7,\n",
       "         'park': 51,\n",
       "         'dwelling': 6,\n",
       "         'room': 97,\n",
       "         'cottage': 56,\n",
       "         'garden': 11,\n",
       "         'shed': 3,\n",
       "         'table': 23,\n",
       "         'manor': 1,\n",
       "         'chair': 9,\n",
       "         'bed': 25,\n",
       "         'lane': 3,\n",
       "         'chaise': 6,\n",
       "         'rug': 1,\n",
       "         'bedroom': 1,\n",
       "         'sofa': 1})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_words = []\n",
    "\n",
    "\n",
    "words = data[0].split()\n",
    "\n",
    "for w in words:\n",
    "    if w in controlled_vocab:\n",
    "        controlled_words.append(w)\n",
    "\n",
    "Counter(controlled_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not a very good return.  It also occurs to me that I might not be thinking clearly about all the kinds of furniture, buildings, and other structures that might make up the Georgian landscape.  Fortunately, linguists have compiled many dictionaries that can help us to navigate the semantic universe with greater position.  One of these dictionaries is \"Wordnet,\" the fruit of a long-term research undertaking at Princeton. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expanded Controlled Vocabulary with Wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'get_synsets' command in Wordnet unlocks the thesaurus/dictionary in its full potential.  We won't go into the full power of the \"synsets,\" but suffice it to say that Wordnet knows that a \"house\" when used as a noun can mean a \"firm,\" a \"sign of the zodiac,\" a \"family,\" or a \"theater.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('house.n.01'), Synset('firm.n.01'), Synset('house.n.03'), Synset('house.n.04'), Synset('house.n.05'), Synset('house.n.06'), Synset('house.n.07'), Synset('sign_of_the_zodiac.n.01'), Synset('house.n.09'), Synset('family.n.01'), Synset('theater.n.01'), Synset('house.n.12')]\n"
     ]
    }
   ],
   "source": [
    "from textblob import Word\n",
    "\n",
    "from textblob.wordnet import NOUN\n",
    "\n",
    "w1 = Word(\"house\")\n",
    "w1.synsets\n",
    "syns = w1.get_synsets(pos=NOUN)\n",
    "print(syns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, wordnet knows that the word \"building\" can refer to different kinds of construction (as a noun), but it can also be a verb form used with many different senses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('building.n.01'),\n",
       " Synset('construction.n.01'),\n",
       " Synset('construction.n.07'),\n",
       " Synset('building.n.04'),\n",
       " Synset('construct.v.01'),\n",
       " Synset('build_up.v.02'),\n",
       " Synset('build.v.03'),\n",
       " Synset('build.v.04'),\n",
       " Synset('build.v.05'),\n",
       " Synset('build.v.06'),\n",
       " Synset('build.v.07'),\n",
       " Synset('build.v.08'),\n",
       " Synset('build_up.v.04'),\n",
       " Synset('build.v.10')]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('building')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *hyponym* is a word that is a more specific version of another word.  So if we want to know the many different types of houses in the dictionary, we can use wordnet's .hyponyms() command to navigate these lists, and we can generate another controlled vocabulary from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('beach_house.n.01'),\n",
       " Synset('boarding_house.n.01'),\n",
       " Synset('bungalow.n.01'),\n",
       " Synset('cabin.n.02'),\n",
       " Synset('chalet.n.01'),\n",
       " Synset('chapterhouse.n.02'),\n",
       " Synset('country_house.n.01'),\n",
       " Synset('detached_house.n.01'),\n",
       " Synset('dollhouse.n.01'),\n",
       " Synset('duplex_house.n.01'),\n",
       " Synset('farmhouse.n.01'),\n",
       " Synset('gatehouse.n.01'),\n",
       " Synset('guesthouse.n.01'),\n",
       " Synset('hacienda.n.02'),\n",
       " Synset('lodge.n.04'),\n",
       " Synset('lodging_house.n.01'),\n",
       " Synset('maisonette.n.02'),\n",
       " Synset('mansion.n.02'),\n",
       " Synset('ranch_house.n.01'),\n",
       " Synset('residence.n.02'),\n",
       " Synset('row_house.n.01'),\n",
       " Synset('safe_house.n.01'),\n",
       " Synset('saltbox.n.01'),\n",
       " Synset('sod_house.n.01'),\n",
       " Synset('solar_house.n.01'),\n",
       " Synset('tract_house.n.01'),\n",
       " Synset('villa.n.02')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synlist = wn.synset('house.n.01').hyponyms()\n",
    "synlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet's 'lemmas()' function gives us access to the base lemma associated with any of these categories.  Let's use the 'append' function and the 'lemmas' function to create a vocabulary list stripped of the Wordnet apparatus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beach_house', 'boarding_house', 'boardinghouse', 'bungalow', 'cottage', 'cabin', 'chalet', 'chapterhouse', 'fraternity_house', 'frat_house', 'country_house', 'detached_house', 'single_dwelling', 'dollhouse', \"doll's_house\", 'duplex_house', 'duplex', 'semidetached_house', 'farmhouse', 'gatehouse', 'guesthouse', 'hacienda', 'lodge', 'hunting_lodge', 'lodging_house', 'rooming_house', 'maisonette', 'maisonnette', 'mansion', 'mansion_house', 'manse', 'hall', 'residence', 'ranch_house', 'residence', 'row_house', 'town_house', 'safe_house', 'saltbox', 'sod_house', 'soddy', 'adobe_house', 'solar_house', 'tract_house', 'villa']\n"
     ]
    }
   ],
   "source": [
    "new_vocab = []\n",
    "\n",
    "for syn in synlist:\n",
    "    for lemma in syn.lemmas():\n",
    "        new_vocab.append(str(lemma.name()))\n",
    "        \n",
    "print(new_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bear in mind: we don't have to stop here.  We can keep drilling down within each of these catergories to get an even finer-grain list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('beach_house.n.01.beach_house')]\n",
      "[Lemma('boarding_house.n.01.boarding_house'), Lemma('boarding_house.n.01.boardinghouse')]\n",
      "[Lemma('bungalow.n.01.bungalow'), Lemma('bungalow.n.01.cottage')]\n",
      "[Lemma('cabin.n.02.cabin')]\n",
      "[Lemma('chalet.n.01.chalet')]\n",
      "[Lemma('chapterhouse.n.02.chapterhouse'), Lemma('chapterhouse.n.02.fraternity_house'), Lemma('chapterhouse.n.02.frat_house')]\n",
      "[Lemma('country_house.n.01.country_house')]\n",
      "[Lemma('detached_house.n.01.detached_house'), Lemma('detached_house.n.01.single_dwelling')]\n",
      "[Lemma('dollhouse.n.01.dollhouse'), Lemma('dollhouse.n.01.doll's_house')]\n",
      "[Lemma('duplex_house.n.01.duplex_house'), Lemma('duplex_house.n.01.duplex'), Lemma('duplex_house.n.01.semidetached_house')]\n",
      "[Lemma('farmhouse.n.01.farmhouse')]\n",
      "[Lemma('gatehouse.n.01.gatehouse')]\n",
      "[Lemma('guesthouse.n.01.guesthouse')]\n",
      "[Lemma('hacienda.n.02.hacienda')]\n",
      "[Lemma('lodge.n.04.lodge'), Lemma('lodge.n.04.hunting_lodge')]\n",
      "[Lemma('lodging_house.n.01.lodging_house'), Lemma('lodging_house.n.01.rooming_house')]\n",
      "[Lemma('maisonette.n.02.maisonette'), Lemma('maisonette.n.02.maisonnette')]\n",
      "[Lemma('mansion.n.02.mansion'), Lemma('mansion.n.02.mansion_house'), Lemma('mansion.n.02.manse'), Lemma('mansion.n.02.hall'), Lemma('mansion.n.02.residence')]\n",
      "[Lemma('ranch_house.n.01.ranch_house')]\n",
      "[Lemma('residence.n.02.residence')]\n",
      "[Lemma('row_house.n.01.row_house'), Lemma('row_house.n.01.town_house')]\n",
      "[Lemma('safe_house.n.01.safe_house')]\n",
      "[Lemma('saltbox.n.01.saltbox')]\n",
      "[Lemma('sod_house.n.01.sod_house'), Lemma('sod_house.n.01.soddy'), Lemma('sod_house.n.01.adobe_house')]\n",
      "[Lemma('solar_house.n.01.solar_house')]\n",
      "[Lemma('tract_house.n.01.tract_house')]\n",
      "[Lemma('villa.n.02.villa')]\n"
     ]
    }
   ],
   "source": [
    "for syn in synlist:\n",
    "    print(syn.lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bed_and_breakfast.n.01'), Synset('log_cabin.n.01'), Synset('chateau.n.01'), Synset('dacha.n.01'), Synset('shooting_lodge.n.01'), Synset('summer_house.n.01'), Synset('villa.n.03'), Synset('villa.n.04'), Synset('lodge.n.03'), Synset('flophouse.n.01'), Synset('manor.n.01'), Synset('palace.n.01'), Synset('stately_home.n.01'), Synset('court.n.09'), Synset('deanery.n.01'), Synset('manse.n.02'), Synset('palace.n.04'), Synset('parsonage.n.01'), Synset('religious_residence.n.01'), Synset('brownstone.n.02'), Synset('terraced_house.n.01')]\n"
     ]
    }
   ],
   "source": [
    "finer_syns = []\n",
    "\n",
    "for syn in synlist:\n",
    "    hypo = syn.hyponyms()\n",
    "    for h in hypo:\n",
    "        finer_syns.append(h)\n",
    " #   print(syn.hyponyms())\n",
    "  \n",
    "print(finer_syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bed_and_breakfast',\n",
       " 'bed-and-breakfast',\n",
       " 'log_cabin',\n",
       " 'chateau',\n",
       " 'dacha',\n",
       " 'shooting_lodge',\n",
       " 'shooting_box',\n",
       " 'summer_house',\n",
       " 'villa',\n",
       " 'villa',\n",
       " 'lodge',\n",
       " 'flophouse',\n",
       " 'dosshouse',\n",
       " 'manor',\n",
       " 'manor_house',\n",
       " 'palace',\n",
       " 'castle',\n",
       " 'stately_home',\n",
       " 'court',\n",
       " 'deanery',\n",
       " 'manse',\n",
       " 'palace',\n",
       " 'parsonage',\n",
       " 'vicarage',\n",
       " 'rectory',\n",
       " 'religious_residence',\n",
       " 'cloister',\n",
       " 'brownstone',\n",
       " 'terraced_house']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab_finer = []\n",
    "\n",
    "for syn in finer_syns:\n",
    "    for subsyn in syn.lemmas():\n",
    "        w = subsyn.name()\n",
    "        new_vocab_finer.append(str(w))\n",
    "            \n",
    "\n",
    "\n",
    "new_vocab_finer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['garden',\n",
       " 'room',\n",
       " 'estate',\n",
       " 'manor',\n",
       " 'hedge',\n",
       " 'residence',\n",
       " 'park',\n",
       " 'lane',\n",
       " 'chair',\n",
       " 'sofa',\n",
       " 'settee',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " 'chaise',\n",
       " 'table',\n",
       " 'rug',\n",
       " 'carpet',\n",
       " 'candelabra',\n",
       " 'shed',\n",
       " 'cottage',\n",
       " 'fence',\n",
       " 'turret',\n",
       " 'castle',\n",
       " 'palace',\n",
       " 'hut',\n",
       " 'dwelling',\n",
       " 'bed_and_breakfast',\n",
       " 'bed-and-breakfast',\n",
       " 'log_cabin',\n",
       " 'chateau',\n",
       " 'dacha',\n",
       " 'shooting_lodge',\n",
       " 'shooting_box',\n",
       " 'summer_house',\n",
       " 'villa',\n",
       " 'villa',\n",
       " 'lodge',\n",
       " 'flophouse',\n",
       " 'dosshouse',\n",
       " 'manor',\n",
       " 'manor_house',\n",
       " 'palace',\n",
       " 'castle',\n",
       " 'stately_home',\n",
       " 'court',\n",
       " 'deanery',\n",
       " 'manse',\n",
       " 'palace',\n",
       " 'parsonage',\n",
       " 'vicarage',\n",
       " 'rectory',\n",
       " 'religious_residence',\n",
       " 'cloister',\n",
       " 'brownstone',\n",
       " 'terraced_house',\n",
       " 'beach_house',\n",
       " 'boarding_house',\n",
       " 'boardinghouse',\n",
       " 'bungalow',\n",
       " 'cottage',\n",
       " 'cabin',\n",
       " 'chalet',\n",
       " 'chapterhouse',\n",
       " 'fraternity_house',\n",
       " 'frat_house',\n",
       " 'country_house',\n",
       " 'detached_house',\n",
       " 'single_dwelling',\n",
       " 'dollhouse',\n",
       " \"doll's_house\",\n",
       " 'duplex_house',\n",
       " 'duplex',\n",
       " 'semidetached_house',\n",
       " 'farmhouse',\n",
       " 'gatehouse',\n",
       " 'guesthouse',\n",
       " 'hacienda',\n",
       " 'lodge',\n",
       " 'hunting_lodge',\n",
       " 'lodging_house',\n",
       " 'rooming_house',\n",
       " 'maisonette',\n",
       " 'maisonnette',\n",
       " 'mansion',\n",
       " 'mansion_house',\n",
       " 'manse',\n",
       " 'hall',\n",
       " 'residence',\n",
       " 'ranch_house',\n",
       " 'residence',\n",
       " 'row_house',\n",
       " 'town_house',\n",
       " 'safe_house',\n",
       " 'saltbox',\n",
       " 'sod_house',\n",
       " 'soddy',\n",
       " 'adobe_house',\n",
       " 'solar_house',\n",
       " 'tract_house',\n",
       " 'villa']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_vocab+=new_vocab_finer\n",
    "controlled_vocab+=new_vocab\n",
    "controlled_vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's great, but if we look for  phrases like \"road_construction\" in our list of Jane Austen words, we'll run into trouble -- because we've already cleaned the text of Jane Austen so that there are no underscores or hyphens.\n",
    "\n",
    "Because of this, we need to produce a clean list from controlled_vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adobe house',\n",
       " 'beach house',\n",
       " 'bed',\n",
       " 'bed and breakfast',\n",
       " 'bedroom',\n",
       " 'boarding house',\n",
       " 'boardinghouse',\n",
       " 'brownstone',\n",
       " 'bungalow',\n",
       " 'cabin',\n",
       " 'candelabra',\n",
       " 'carpet',\n",
       " 'castle',\n",
       " 'chair',\n",
       " 'chaise',\n",
       " 'chalet',\n",
       " 'chapterhouse',\n",
       " 'chateau',\n",
       " 'cloister',\n",
       " 'cottage',\n",
       " 'country house',\n",
       " 'court',\n",
       " 'dacha',\n",
       " 'deanery',\n",
       " 'detached house',\n",
       " \"doll's house\",\n",
       " 'dollhouse',\n",
       " 'dosshouse',\n",
       " 'duplex',\n",
       " 'duplex house',\n",
       " 'dwelling',\n",
       " 'estate',\n",
       " 'farmhouse',\n",
       " 'fence',\n",
       " 'flophouse',\n",
       " 'frat house',\n",
       " 'fraternity house',\n",
       " 'garden',\n",
       " 'gatehouse',\n",
       " 'guesthouse',\n",
       " 'hacienda',\n",
       " 'hall',\n",
       " 'hedge',\n",
       " 'hunting lodge',\n",
       " 'hut',\n",
       " 'lane',\n",
       " 'lodge',\n",
       " 'lodging house',\n",
       " 'log cabin',\n",
       " 'maisonette',\n",
       " 'maisonnette',\n",
       " 'manor',\n",
       " 'manor house',\n",
       " 'manse',\n",
       " 'mansion',\n",
       " 'mansion house',\n",
       " 'palace',\n",
       " 'park',\n",
       " 'parsonage',\n",
       " 'ranch house',\n",
       " 'rectory',\n",
       " 'religious residence',\n",
       " 'residence',\n",
       " 'room',\n",
       " 'rooming house',\n",
       " 'row house',\n",
       " 'rug',\n",
       " 'safe house',\n",
       " 'saltbox',\n",
       " 'semidetached house',\n",
       " 'settee',\n",
       " 'shed',\n",
       " 'shooting box',\n",
       " 'shooting lodge',\n",
       " 'single dwelling',\n",
       " 'sod house',\n",
       " 'soddy',\n",
       " 'sofa',\n",
       " 'solar house',\n",
       " 'stately home',\n",
       " 'summer house',\n",
       " 'table',\n",
       " 'terraced house',\n",
       " 'town house',\n",
       " 'tract house',\n",
       " 'turret',\n",
       " 'vicarage',\n",
       " 'villa'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_controlled_vocab = []\n",
    "for w in controlled_vocab:\n",
    "    cleaned = w.replace(\"_\", \" \").replace(\"-\", \" \") # remove hyphens or underscores\n",
    "    cleaned_controlled_vocab.append(cleaned)\n",
    "\n",
    "import numpy as np\n",
    "cleaned_controlled_vocab = set(cleaned_controlled_vocab) # get only unique values\n",
    "cleaned_controlled_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's run a \"for\" loop similar to those we've seen before to search for the words in cleaned_controlled_vocab that also appear in Jane Austen novels.  As you'll recall, we have a master list of Austen words called \"words.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'chapterhouse': 2358,\n",
       "         'residence': 2011,\n",
       "         'dwelling': 4310,\n",
       "         'cabin': 5933,\n",
       "         'chair': 4040,\n",
       "         'maisonnette': 6093,\n",
       "         'maisonette': 6410,\n",
       "         'shooting box': 3886,\n",
       "         'hacienda': 4049,\n",
       "         'cloister': 2691,\n",
       "         'log cabin': 5935,\n",
       "         'hunting lodge': 3888,\n",
       "         'shooting lodge': 3887,\n",
       "         'mansion': 5140,\n",
       "         'rooming house': 4242,\n",
       "         'single dwelling': 4320,\n",
       "         'boarding house': 6195,\n",
       "         'semidetached house': 5348,\n",
       "         'religious residence': 2102,\n",
       "         'vicarage': 4018,\n",
       "         'boardinghouse': 6195,\n",
       "         'fraternity house': 6802,\n",
       "         'chaise': 4742,\n",
       "         'lodging house': 4149,\n",
       "         'mansion house': 5400,\n",
       "         'villa': 4020,\n",
       "         'sofa': 6259,\n",
       "         'estate': 2929,\n",
       "         'candelabra': 6015,\n",
       "         'bed and breakfast': 8356,\n",
       "         'frat house': 3143,\n",
       "         'stately home': 3401,\n",
       "         'gatehouse': 3148,\n",
       "         'chateau': 2903,\n",
       "         'park': 2099,\n",
       "         'parsonage': 3433,\n",
       "         'solar house': 2944,\n",
       "         'sod house': 894,\n",
       "         'soddy': 642,\n",
       "         'lane': 2394,\n",
       "         'tract house': 2319,\n",
       "         'palace': 2050,\n",
       "         'beach house': 3646,\n",
       "         'manse': 2499,\n",
       "         'bungalow': 2075,\n",
       "         'dacha': 2048,\n",
       "         'ranch house': 2658,\n",
       "         'castle': 3270,\n",
       "         'manor': 3484,\n",
       "         'carpet': 2048,\n",
       "         'manor house': 3744,\n",
       "         'adobe house': 3910,\n",
       "         'terraced house': 2308,\n",
       "         'table': 2119,\n",
       "         'hall': 2700,\n",
       "         'farmhouse': 2384,\n",
       "         'safe house': 2320,\n",
       "         'garden': 2059,\n",
       "         'chalet': 2077,\n",
       "         'deanery': 2389,\n",
       "         'detached house': 3400,\n",
       "         'cottage': 2123,\n",
       "         'saltbox': 2051,\n",
       "         'brownstone': 5389,\n",
       "         'town house': 4704,\n",
       "         'rectory': 4439,\n",
       "         'hedge': 1093,\n",
       "         'shed': 2681,\n",
       "         'flophouse': 265,\n",
       "         'dosshouse': 582,\n",
       "         'row house': 261,\n",
       "         'guesthouse': 266,\n",
       "         'country house': 299,\n",
       "         'dollhouse': 584,\n",
       "         'duplex house': 371,\n",
       "         'summer house': 693,\n",
       "         \"doll's house\": 584,\n",
       "         'bed': 1305,\n",
       "         'bedroom': 1405,\n",
       "         'duplex': 111,\n",
       "         'court': 78,\n",
       "         'settee': 32,\n",
       "         'room': 97,\n",
       "         'fence': 3,\n",
       "         'rug': 1,\n",
       "         'lodge': 2})"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_words = []\n",
    "\n",
    "for w in words:\n",
    "    for v in cleaned_controlled_vocab: \n",
    "        if w in v:\n",
    "            controlled_words.append(v)\n",
    "\n",
    "Counter(controlled_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, I'm not sure that's right.  There aren't so many hacienda's or log cabin's in Jane Austen.  What might have gone wrong?  Perhaps it's a regular expressions problem again -- the computer is looking for \"chapter\" and finds \"chapterhouse.\"  How can we tweak the code above to be more accurate?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer involves the difference between \"if a in b\" and \"if a==b\".  \n",
    "\n",
    "The former searches for cases where a is \"in\" b.  The latter searches for cases where a is an exact match for b.\n",
    "\n",
    "*Notice that we can get even more control over matches -- by looking for word boundaries before and after a and b -- by using \"regular expression\" or \"regex\" language with the .compile() and .match() commands above.  In future iterations of exercises, you may want to learn more about this in order to gain total control over pattern matching with language; you can find an introduction to the \"re\" package for regex here: https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'estate': 19,\n",
       "         'residence': 7,\n",
       "         'park': 51,\n",
       "         'dwelling': 6,\n",
       "         'room': 97,\n",
       "         'cottage': 56,\n",
       "         'garden': 11,\n",
       "         'shed': 3,\n",
       "         'court': 4,\n",
       "         'table': 23,\n",
       "         'manor': 1,\n",
       "         'mansion': 1,\n",
       "         'chair': 9,\n",
       "         'bed': 25,\n",
       "         'lane': 3,\n",
       "         'chaise': 6,\n",
       "         'rug': 1,\n",
       "         'bedroom': 1,\n",
       "         'rectory': 2,\n",
       "         'parsonage': 9,\n",
       "         'sofa': 1,\n",
       "         'hall': 1})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_words2 = []\n",
    "\n",
    "for w in words:\n",
    "    for v in cleaned_controlled_vocab: \n",
    "        if w == v: # notice what I changed in this line\n",
    "            controlled_words2.append(v)\n",
    "\n",
    "Counter(controlled_words2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I'm only counting words that *exactly match* my controlled vocab.  \n",
    "\n",
    "Again, I could also use regular expressions and the commands .compile() and .match() (see bigrams section above) to tailor exactly what is being looked for, depending on whether I'm looking for exact matches of one string within another or exact matches of one string and another string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'estate': 19,\n",
       "         'residence': 7,\n",
       "         'park': 51,\n",
       "         'single dwelling': 8,\n",
       "         'dwelling': 6,\n",
       "         'room': 97,\n",
       "         'cottage': 56,\n",
       "         'garden': 11,\n",
       "         'shed': 3,\n",
       "         'country house': 32,\n",
       "         'court': 4,\n",
       "         'table': 23,\n",
       "         'summer house': 3,\n",
       "         'manor': 1,\n",
       "         'manor house': 1,\n",
       "         'safe house': 9,\n",
       "         'mansion': 1,\n",
       "         'mansion house': 1,\n",
       "         'chair': 9,\n",
       "         'town house': 82,\n",
       "         'bed and breakfast': 25,\n",
       "         'bed': 25,\n",
       "         'lane': 3,\n",
       "         'chaise': 6,\n",
       "         'rug': 1,\n",
       "         'bedroom': 1,\n",
       "         'lodging house': 2,\n",
       "         'rectory': 2,\n",
       "         'parsonage': 9,\n",
       "         'tract house': 1,\n",
       "         'sofa': 1,\n",
       "         'hall': 1})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlled_words3 = []\n",
    "\n",
    "for w in words:\n",
    "    for v in cleaned_controlled_vocab: \n",
    "        pattern = re.compile(r'\\b%s\\b' % w, re.I) # notice what I changed in this line\n",
    "        if pattern.match(v): # notice what I changed in this line\n",
    "            controlled_words3.append(v)\n",
    "\n",
    "Counter(controlled_words3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlled_words3 is giving us output where any *complete words* found in Jane Austen are also found in a controlled_vocab string.  Thus \"town house\" appears because \"house\" is found in Jane Austen.  But this output is also probably inaccurate: \"safe house\" doesn't sound like a circa 1820 term that Austen would have included in her novels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All I'm doing here is demonstrating the various different outputs you can get from similar searches, using \"in\", \"==\", and regex pattern matching.  You could keep tweaking the code, but so far, the best results are from our second example, controlled_words2, where we used the exact match operator, \"==\", to match single words in Jane Austen against exact entries in the controlled_vocab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's only one problem with the solution thus far.  The variable *words* contains strings that are one-word long, but we're matching it with cleaned_controlled_vocab -- which includes such two-word phrases as \"terraced house.\" \n",
    "\n",
    "Those two-word phrases aren't getting accurately matched. We could fix this by searching the variable \"bigrams_as_text\" for the cleaned_controlled_vocab.  In fact, this is exactly what you'll be doing in one part of the exercise that follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To be turned in on Canvas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First, let's have you get some more terminology of houses or furniture to add to cleaned_controlled_vocab.  Up at the top of this exercise, where you import the 'synsets' -- lists of related words -- from Wordnet, we looked at how to load multiple synsets that contain the word 'building.'  We only took the hyponyms from the first synset -- house.n.01.  But you could take the hyponyms from another synset.  Alternatively, you could look for synsets that contain the word 'furniture' or 'garden.'  What you choose is up to you, but try playing with Wordnet a little.  Once you have a synset that you like, run it through the code that follows so that you have a new 'cleaned_controlled_vocab' that you can use to search Jane Austen.\n",
    "\n",
    "2) Next, find the bigrams (two-word phrases) in Jane Austen that contain any of these lemmas or phrases in 'cleaned_controlled_vocab'.  Sort the phrases by descending frequency, and paste the top twenty into Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Write an interpretive paragraph of at least five sentences making some observations about the built landscape of England at the time of Jane Austen.  Offset phrases and words found in the text with quotation marks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help where help is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're finding yourself confused about the code and how to follow directions at this point, bear in mind that we're moving very quickly through the introduction to Python. You might need to slow down and revisit some of the \"optional\" notebooks that we mentioned in Weeks 1-2.  Here they are again:\n",
    "\n",
    "- lists : https://github.com/laurenfklein/emory-qtm340/blob/master/notebooks/lists.ipynb\n",
    "- for loops : https://problemsolvingwithpython.com/09-Loops/09.01-For-Loops/\n",
    "- expressions and strings :  https://github.com/laurenfklein/emory-qtm340/blob/master/notebooks/expressions-and-strings.ipynb\n",
    "- dictionaries, sets, tuples: https://github.com/laurenfklein/emory-qtm340/blob/master/notebooks/dictionaries-sets-tuples.ipynb\n",
    "- counting things: https://github.com/laurenfklein/emory-qtm340/blob/master/notebooks/counting.ipynb\n",
    "\n",
    "Remember that SMU expects you to be spending around 6 hours every week on your homework for this class.  Don't be afraid to keep tweaking the code until it works -- or reaching out on Slack if you need encouragement from others.  \n",
    "\n",
    "Also, please bear in mind that everyone who learns how to code ultimately does so through a lot of trial and error.  Try typing in code and running it. When you run into trouble, you can google your problems and find stack overflow results or blog entries that match your problem and suggest solutions.  The more you try, the faster you will master code.  \n",
    "\n",
    "Don't give up!  Keep trying things until you feel like you're getting it! \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
