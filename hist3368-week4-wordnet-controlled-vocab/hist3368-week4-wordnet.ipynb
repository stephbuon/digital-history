{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week4-wordnet-controlled-vocab/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Mini Wordnet Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the ways to build a compelling case for studying cultural difference and historical change is to examine a \"controlled vocabulary\" -- or a list of words that are semantically related.\n",
    "\n",
    "We can use a dictionary or a thesaurus to generate a list of words that are related.  For instance, searching for the following words would give us a good set of vocabulary for studying the discourse of nonsense:\n",
    "\n",
    "    buncombe\n",
    "    horsefeathers\n",
    "    applesauce\n",
    "    hooey\n",
    "    phooey\n",
    "    fiddle-faddle\n",
    "    \n",
    "If we searched the parliamentary debates for the debates where speakers use these words, we have a good change of finding the debates where parliamentarians are expressing a lack of respect for each other. We can go from that set of debates to a study of the most contentious topics in parliament.\n",
    "\n",
    "We can use the **WordNet** package like a thesaurus to look up synonyms for words and to generate a list of semantically related words.  \n",
    "\n",
    "We'll learn the following commands:\n",
    "   * **Word()** -- tell Wordnet to look up a new word.\n",
    "   * **.synsets** or **.get_synsets()** -- which look up files of semantically related words in which a given word appears. Once I have the name of these files, I can navigate to the individual words that are synonyms for my word.\n",
    "   * We navigate to the individual words inside the Synset files by using the commands **.lemmas()** and **.name().**\n",
    "   * **.hyponyms()** tells WordNet to look up the particularized synsets that are hierarchically inferior to a given word. For example, .hyponyms('cutlery') would give me the synsets for 'fork,' 'spoon,' and 'knife.'\n",
    "   \n",
    "In this notebook, we'll learn to apply these commands to generate a rich list of semantically-related words that the analyst might use for searching text. We'll learn how to format the results for future text mining.  And we'll start thinking about which words are useful. \n",
    "\n",
    "In a future notebook, we'll learn how to search historical texts with these rich lists of words.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating Wordnet's Synsets to find Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to Wordnet are the files of related words, called **synsets**.  Synsets are named with the part of speech of the word -- typically a noun or a verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "from nltk.corpus import wordnet as wn\n",
    "from textblob.wordnet import NOUN, VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look up the files in which the word 'house' appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('house.n.01'),\n",
       " Synset('firm.n.01'),\n",
       " Synset('house.n.03'),\n",
       " Synset('house.n.04'),\n",
       " Synset('house.n.05'),\n",
       " Synset('house.n.06'),\n",
       " Synset('house.n.07'),\n",
       " Synset('sign_of_the_zodiac.n.01'),\n",
       " Synset('house.n.09'),\n",
       " Synset('family.n.01'),\n",
       " Synset('theater.n.01'),\n",
       " Synset('house.n.12'),\n",
       " Synset('house.v.01'),\n",
       " Synset('house.v.02')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('house')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that Wordnet knows that the word \"house\" can refer to a \"sign of the zodiac.\" It knows that sometimes when we refer to a \"house\" we refer to business firms, other of which refer to dwellings, signs of the zodiac, families, or theaters.  In general, these usages are listed in order from the most prevalent to the least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, wordnet knows that the word \"building\" can refer to different kinds of construction (as a noun), but it can also be a verb form used with many different senses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('building.n.01'),\n",
       " Synset('construction.n.01'),\n",
       " Synset('construction.n.07'),\n",
       " Synset('building.n.04'),\n",
       " Synset('construct.v.01'),\n",
       " Synset('build_up.v.02'),\n",
       " Synset('build.v.03'),\n",
       " Synset('build.v.04'),\n",
       " Synset('build.v.05'),\n",
       " Synset('build.v.06'),\n",
       " Synset('build.v.07'),\n",
       " Synset('build.v.08'),\n",
       " Synset('build_up.v.04'),\n",
       " Synset('build.v.10')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('building')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can navigate a list of synsets like a list, with square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('house.n.01')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysynsets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('firm.n.01')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysynsets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Part of Speech (POS) to navigate synsets\n",
    "\n",
    "Notice that some of the synsets have an 'n', meaning that they are synonyms for 'house' as a noun, as in \"a shelter.\"\n",
    "\n",
    "Others have a 'v', meaning that they are synonyms for 'house' as a verb, as in, 'to provide shelter.'\n",
    "\n",
    "To navigate synsets we'll use the Textblob command\n",
    "\n",
    "    Word()\n",
    "    \n",
    "to create a 'textblob' type data item from the word 'house.' We will use this textblob to get more information about 'house' and its uses in various parts of speech.\n",
    "\n",
    "We can use the command \n",
    "\n",
    "    .get_synsets() \n",
    "    \n",
    "which takes the argument **'pos'** to tell WordNet that we're only interested in the nouns.\n",
    "\n",
    "Let's set pos to NOUN when we search for the synsets for 'house':\n",
    "\n",
    "    .get_synsets(pos=NOUN)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textblob.blob.Word"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('house.n.01'), Synset('firm.n.01'), Synset('house.n.03'), Synset('house.n.04'), Synset('house.n.05'), Synset('house.n.06'), Synset('house.n.07'), Synset('sign_of_the_zodiac.n.01'), Synset('house.n.09'), Synset('family.n.01'), Synset('theater.n.01'), Synset('house.n.12')]\n"
     ]
    }
   ],
   "source": [
    "w1 = Word('house')\n",
    "mysynsets = w1.get_synsets(pos=NOUN)\n",
    "print(mysynsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('house.v.01'), Synset('house.v.02')]\n"
     ]
    }
   ],
   "source": [
    "w1 = Word('house')\n",
    "mysynsets2 = w1.get_synsets(pos=VERB)\n",
    "print(mysynsets2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting the individual words from the synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We navigate to the individual words inside the Synset files by using the commands **.lemmas()** and **.name().**\n",
    "\n",
    "Notice that\n",
    "\n",
    "    .lemmas()\n",
    "\n",
    "is invoking the 'lemmas' of each word in the file. We encountered the concept of the 'lemma' root of each word in our module on lemmatization.\n",
    "\n",
    "Wordnet's 'lemmas()' function gives us access to the base lemma associated any word in a synset.  This is our base command for finding the synonyms for a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('firm.n.01.firm'),\n",
       " Lemma('firm.n.01.house'),\n",
       " Lemma('firm.n.01.business_firm')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = Word('house')\n",
    "mysynsets = w1.get_synsets(pos=NOUN)\n",
    "mylemmas=mysynsets[1].lemmas()\n",
    "mylemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information tells us that the second synset for house -- 'firm.m.01' -- contains the words  'firm,' 'house,', and 'business firm,' each of which can be used as synonyms for each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can navigate *mylemmas* like a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('firm.n.01.firm')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylemmas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('firm.n.01.house')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylemmas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lemma('firm.n.01.business_firm')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylemmas[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *.lemmas()*, the words are labeled according to the name of the synset ('firm.n.01') and the name of the lemma ('firm,' 'house', or 'business firm').  \n",
    "\n",
    "If we just want to get to the root words, we use **.name()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'firm'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylemmas[0].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the lemmas from a synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's use the 'append' function and the 'lemmas' function to create a vocabulary list stripped of the Wordnet apparatus.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house', 'firm', 'house', 'business_firm', 'house', 'house', 'house', 'house', 'house', 'sign_of_the_zodiac', 'star_sign', 'sign', 'mansion', 'house', 'planetary_house', 'house', 'family', 'household', 'house', 'home', 'menage', 'theater', 'theatre', 'house', 'house']\n"
     ]
    }
   ],
   "source": [
    "new_vocab = [] # start with an empty list \n",
    "\n",
    "for syn in mysynsets: # move through each synset in my list of synsets\n",
    "    for lemma in syn.lemmas(): # move through each lemma in the synset\n",
    "        lemmaname = lemma.name() # get the root word attached to the lemma\n",
    "        new_vocab.append(str(lemmaname)) # save that root word in the list new_vocab\n",
    "        \n",
    "print(new_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have all the synonyms for \"house\" from the categories we saw above -- some of which refer to business firms, other of which refer to dwellings, signs of the zodiac, families, or theaters. Notice that there is repetition, because the root word 'house' is also stored as a lemma under the synset for the family \"house\" and the theater \"house\" etc.  \n",
    "\n",
    "We could eliminate repetitions from this list and we would have a master controlled vocabulary for looking for synonyms for the word 'house\" in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Finer Senses of Meaning: Looking Up Hyponyms \n",
    "\n",
    "One of the most exciting features of a wordnet is that we don't have to stop here, with our short list of synonyms.  We might be interested in words for particular *kinds* of houses -- for instance, cabins, or bungalows.  \n",
    "\n",
    "Searching for this more complete list is more likely to give us good results in text mining. That way, if someone refers to a treehouse or a hut, we'll still know that they're talking about houses. In fact, we'll be able to examine our data for *how* people talk about their houses.  \n",
    "\n",
    "The name of the linguistic feature when a word is particularized from general to specific is a *hyponym*.\n",
    "\n",
    "Wordnet allows us to detect the hyponyms for any given word.  Using our new tools for navigating synsets, we can keep drilling down within each of these catergories to get an even finer-grain list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .hyponyms() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know the many different types of houses in the dictionary, we can use wordnet's .hyponyms() command to navigate these lists, and we can generate another controlled vocabulary from them.\n",
    "\n",
    ".hyponyms() is applied to one synset at a time. It takes no object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('beach_house.n.01'),\n",
       " Synset('boarding_house.n.01'),\n",
       " Synset('bungalow.n.01'),\n",
       " Synset('cabin.n.02'),\n",
       " Synset('chalet.n.01'),\n",
       " Synset('chapterhouse.n.02'),\n",
       " Synset('country_house.n.01'),\n",
       " Synset('detached_house.n.01'),\n",
       " Synset('dollhouse.n.01'),\n",
       " Synset('duplex_house.n.01'),\n",
       " Synset('farmhouse.n.01'),\n",
       " Synset('gatehouse.n.01'),\n",
       " Synset('guesthouse.n.01'),\n",
       " Synset('hacienda.n.02'),\n",
       " Synset('lodge.n.04'),\n",
       " Synset('lodging_house.n.01'),\n",
       " Synset('maisonette.n.02'),\n",
       " Synset('mansion.n.02'),\n",
       " Synset('ranch_house.n.01'),\n",
       " Synset('residence.n.02'),\n",
       " Synset('row_house.n.01'),\n",
       " Synset('safe_house.n.01'),\n",
       " Synset('saltbox.n.01'),\n",
       " Synset('sod_house.n.01'),\n",
       " Synset('solar_house.n.01'),\n",
       " Synset('tract_house.n.01'),\n",
       " Synset('villa.n.02')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysynlist = wn.synset('house.n.01')\n",
    "hyposynlist = mysynlist.hyponyms()\n",
    "hyposynlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use .lemmas() and .name() to call the words associated with these folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach_house\n",
      "boarding_house\n",
      "boardinghouse\n",
      "bungalow\n",
      "cottage\n",
      "cabin\n",
      "chalet\n",
      "chapterhouse\n",
      "fraternity_house\n",
      "frat_house\n",
      "country_house\n",
      "detached_house\n",
      "single_dwelling\n",
      "dollhouse\n",
      "doll's_house\n",
      "duplex_house\n",
      "duplex\n",
      "semidetached_house\n",
      "farmhouse\n",
      "gatehouse\n",
      "guesthouse\n",
      "hacienda\n",
      "lodge\n",
      "hunting_lodge\n",
      "lodging_house\n",
      "rooming_house\n",
      "maisonette\n",
      "maisonnette\n",
      "mansion\n",
      "mansion_house\n",
      "manse\n",
      "hall\n",
      "residence\n",
      "ranch_house\n",
      "residence\n",
      "row_house\n",
      "town_house\n",
      "safe_house\n",
      "saltbox\n",
      "sod_house\n",
      "soddy\n",
      "adobe_house\n",
      "solar_house\n",
      "tract_house\n",
      "villa\n"
     ]
    }
   ],
   "source": [
    "for syn in hyposynlist:\n",
    "    for l in syn.lemmas():\n",
    "        print(l.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we've gotten a lot of data -- and this was just ONE of the dozen different synsets for  the word 'house.' This is okay, because we probably don't want to know the synsets for 'house' as in 'business firm' or 'sign of the zodiac' if we're trying to understand dwellings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice calling up the lemmas for a synset again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "park\n",
      "parkland\n",
      "park\n",
      "commons\n",
      "common\n",
      "green\n",
      "ballpark\n",
      "park\n",
      "Park\n",
      "Mungo_Park\n",
      "parking_lot\n",
      "car_park\n",
      "park\n",
      "parking_area\n",
      "park\n",
      "park\n",
      "park\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('park').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crime\n",
      "offense\n",
      "criminal_offense\n",
      "criminal_offence\n",
      "offence\n",
      "law-breaking\n",
      "crime\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('crime').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n",
      "miss\n",
      "missy\n",
      "young_lady\n",
      "young_woman\n",
      "fille\n",
      "female_child\n",
      "girl\n",
      "little_girl\n",
      "daughter\n",
      "girl\n",
      "girlfriend\n",
      "girl\n",
      "lady_friend\n",
      "girl\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('girl').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice calling up all the lemmas for the hyponyms of the same words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national_park\n",
      "safari_park\n",
      "amusement_park\n",
      "funfair\n",
      "pleasure_ground\n",
      "village_green\n",
      "used-car_lot\n",
      "angle-park\n",
      "double-park\n",
      "parallel-park\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('park').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for lemma in s.lemmas():\n",
    "            print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack\n",
      "attempt\n",
      "barratry\n",
      "capital_offense\n",
      "cybercrime\n",
      "felony\n",
      "forgery\n",
      "fraud\n",
      "Had_crime\n",
      "hijack\n",
      "highjack\n",
      "mayhem\n",
      "misdemeanor\n",
      "misdemeanour\n",
      "infraction\n",
      "violation\n",
      "infringement\n",
      "perpetration\n",
      "commission\n",
      "committal\n",
      "statutory_offense\n",
      "statutory_offence\n",
      "regulatory_offense\n",
      "regulatory_offence\n",
      "Tazir_crime\n",
      "thuggery\n",
      "treason\n",
      "high_treason\n",
      "lese_majesty\n",
      "vice_crime\n",
      "victimless_crime\n",
      "war_crime\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('crime').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for lemma in s.lemmas():\n",
    "            print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby\n",
      "babe\n",
      "sister\n",
      "belle\n",
      "bimbo\n",
      "chachka\n",
      "tsatske\n",
      "tshatshke\n",
      "tchotchke\n",
      "tchotchkeleh\n",
      "chit\n",
      "colleen\n",
      "dame\n",
      "doll\n",
      "wench\n",
      "skirt\n",
      "chick\n",
      "bird\n",
      "flapper\n",
      "gal\n",
      "gamine\n",
      "Gibson_girl\n",
      "lass\n",
      "lassie\n",
      "young_girl\n",
      "jeune_fille\n",
      "maid\n",
      "maiden\n",
      "May_queen\n",
      "queen_of_the_May\n",
      "mill-girl\n",
      "party_girl\n",
      "peri\n",
      "ring_girl\n",
      "rosebud\n",
      "sex_kitten\n",
      "sexpot\n",
      "sex_bomb\n",
      "shop_girl\n",
      "soubrette\n",
      "sweater_girl\n",
      "tomboy\n",
      "romp\n",
      "hoyden\n",
      "valley_girl\n",
      "working_girl\n",
      "Campfire_Girl\n",
      "farm_girl\n",
      "flower_girl\n",
      "moppet\n",
      "schoolgirl\n",
      "Scout\n",
      "mother's_daughter\n"
     ]
    }
   ],
   "source": [
    "for synset in Word('girl').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for lemma in s.lemmas():\n",
    "            print(lemma.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling down into even more particular hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyponyms don't just go one level deep.  Each of the individual synsets in the list **hyposynlist** may have hyponyms into which it can be particularized.  \n",
    "\n",
    "Let's look at the synset  Synset('country_house.n.01'), which is hyposynlist[6].  Does it have any hyponyms underneath it?  How many kinds of country houses are there, according to Wordnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chateau.n.01'),\n",
       " Synset('dacha.n.01'),\n",
       " Synset('shooting_lodge.n.01'),\n",
       " Synset('summer_house.n.01'),\n",
       " Synset('villa.n.03'),\n",
       " Synset('villa.n.04')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finerhyposynlist = hyposynlist[6].hyponyms()\n",
    "finerhyposynlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the words from both lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet knows that 'Country Houses' contains chateaus, dachas, shooting lodges, summer houses, and villas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get all the subcategories of different words for dwelling -- by moving through all the words in hyposynlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('bed_and_breakfast.n.01'), Synset('log_cabin.n.01'), Synset('chateau.n.01'), Synset('dacha.n.01'), Synset('shooting_lodge.n.01'), Synset('summer_house.n.01'), Synset('villa.n.03'), Synset('villa.n.04'), Synset('lodge.n.03'), Synset('flophouse.n.01'), Synset('manor.n.01'), Synset('palace.n.01'), Synset('stately_home.n.01'), Synset('court.n.09'), Synset('deanery.n.01'), Synset('manse.n.02'), Synset('palace.n.04'), Synset('parsonage.n.01'), Synset('religious_residence.n.01'), Synset('brownstone.n.02'), Synset('terraced_house.n.01')]\n"
     ]
    }
   ],
   "source": [
    "finer_syns = [] # create an empty list\n",
    " \n",
    "for syn in hyposynlist: # loop through all the synsets\n",
    "    myhyponyms = syn.hyponyms()\n",
    "    for h in myhyponyms:\n",
    "        finer_syns.append(h)\n",
    "  \n",
    "print(finer_syns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wordnet knows that there are bed and breakfasts, log cabins, palaces, stately homes, parsonages, and deaneries, to name a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice some more. Let's drill down into some more categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lass\n",
      "lassie\n",
      "young_girl\n",
      "jeune_fille\n",
      "maid\n",
      "maiden\n",
      "Scout\n"
     ]
    }
   ],
   "source": [
    "mywords = []\n",
    "\n",
    "for synset in Word('girl').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for syn in s.hyponyms():\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in mywords:\n",
    "                    mywords.append(lemma.name())\n",
    "                    print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack\n",
      "attempt\n",
      "felony\n",
      "fraud\n",
      "hijack\n",
      "highjack\n",
      "misdemeanor\n",
      "misdemeanour\n",
      "infraction\n",
      "violation\n",
      "infringement\n",
      "statutory_offense\n",
      "statutory_offence\n",
      "regulatory_offense\n",
      "regulatory_offence\n",
      "vice_crime\n"
     ]
    }
   ],
   "source": [
    "mywords = []\n",
    "\n",
    "for synset in Word('crime').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for syn in s.hyponyms():\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in mywords:\n",
    "                    mywords.append(lemma.name())\n",
    "                    print(lemma.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower_garden\n",
      "grove\n",
      "woodlet\n",
      "orchard\n",
      "plantation\n",
      "kitchen_garden\n",
      "vegetable_garden\n",
      "vegetable_patch\n"
     ]
    }
   ],
   "source": [
    "mywords = []\n",
    "\n",
    "for synset in Word('garden').synsets:\n",
    "    for s in synset.hyponyms():\n",
    "        for syn in s.hyponyms():\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in mywords:\n",
    "                    mywords.append(lemma.name())\n",
    "                    print(lemma.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep Drilling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning just to the list of countryhouses, let's see far we can take 'houses' into particulars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chateau.n.01'),\n",
       " Synset('dacha.n.01'),\n",
       " Synset('shooting_lodge.n.01'),\n",
       " Synset('summer_house.n.01'),\n",
       " Synset('villa.n.03'),\n",
       " Synset('villa.n.04')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finerhyposynlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's look at all the words by calling the .lemmas() and .name() for each synset we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chateau\n",
      "dacha\n",
      "shooting_lodge\n",
      "shooting_box\n",
      "summer_house\n",
      "villa\n",
      "villa\n"
     ]
    }
   ],
   "source": [
    "for syn in finerhyposynlist:\n",
    "    for l in syn.lemmas():\n",
    "        print(l.name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use .hyponyms() again to ask if any of the synsets we generated last time have smaller particular divisions of language.\n",
    "\n",
    "Are there particular kinds of villas, shooting lodges, etc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('villa.n.03')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villa = finerhyposynlist[4]\n",
    "villa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villa = finerhyposynlist[4]\n",
    "finerfinerhyposynlist = villa.hyponyms()\n",
    "finerfinerhyposynlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "villa = finerhyposynlist[5]\n",
    "finerfinerhyposynlist = villa.hyponyms()\n",
    "finerfinerhyposynlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shootinglodge = finerhyposynlist[2]\n",
    "finerfinerhyposynlist = villa.hyponyms()\n",
    "finerfinerhyposynlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No.  There are no subdivisions of the word 'villa' on record. However, we can look at the synonyms listed for villa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shooting_lodge', 'shooting_box']\n"
     ]
    }
   ],
   "source": [
    "shootinglodgewords = [] # start with an empty list \n",
    "\n",
    "for lemma in shootinglodge.lemmas(): # move through each lemma in the synset\n",
    "        lemmaname = lemma.name() # get the root word attached to the lemma\n",
    "        shootinglodgewords.append(str(lemmaname)) # save that root word in the list new_vocab\n",
    "        \n",
    "print(shootinglodgewords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two phrases here for referring to shooting lodges: shooting lodge and shooting box."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How far do you have to go to create a solid analysis?  That's a measure of personal taste. However, you should know that you can keep using the command .hyponyms() to inspect more and more particular meanings of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a For Loop to Get all the hyponym words for 'house' as dwelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have lists with at least to levels of detail -- hyposynlist and finer_syns.  \n",
    "\n",
    "Hyposynlist represents the subcategories of 'house' as dwelling.\n",
    "\n",
    "Finer_syns represents the subcategoreis of each folder in hyposynlist.\n",
    "\n",
    "Let's get all the words from both variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach_house',\n",
       " 'boarding_house',\n",
       " 'boardinghouse',\n",
       " 'bungalow',\n",
       " 'cottage',\n",
       " 'cabin',\n",
       " 'chalet',\n",
       " 'chapterhouse',\n",
       " 'fraternity_house',\n",
       " 'frat_house',\n",
       " 'country_house',\n",
       " 'detached_house',\n",
       " 'single_dwelling',\n",
       " 'dollhouse',\n",
       " \"doll's_house\",\n",
       " 'duplex_house',\n",
       " 'duplex',\n",
       " 'semidetached_house',\n",
       " 'farmhouse',\n",
       " 'gatehouse',\n",
       " 'guesthouse',\n",
       " 'hacienda',\n",
       " 'lodge',\n",
       " 'hunting_lodge',\n",
       " 'lodging_house',\n",
       " 'rooming_house',\n",
       " 'maisonette',\n",
       " 'maisonnette',\n",
       " 'mansion',\n",
       " 'mansion_house',\n",
       " 'manse',\n",
       " 'hall',\n",
       " 'residence',\n",
       " 'ranch_house',\n",
       " 'row_house',\n",
       " 'town_house',\n",
       " 'safe_house',\n",
       " 'saltbox',\n",
       " 'sod_house',\n",
       " 'soddy',\n",
       " 'adobe_house',\n",
       " 'solar_house',\n",
       " 'tract_house',\n",
       " 'villa',\n",
       " 'bed_and_breakfast',\n",
       " 'bed-and-breakfast',\n",
       " 'log_cabin',\n",
       " 'chateau',\n",
       " 'dacha',\n",
       " 'shooting_lodge',\n",
       " 'shooting_box',\n",
       " 'summer_house',\n",
       " 'flophouse',\n",
       " 'dosshouse',\n",
       " 'manor',\n",
       " 'manor_house',\n",
       " 'palace',\n",
       " 'castle',\n",
       " 'stately_home',\n",
       " 'court',\n",
       " 'deanery',\n",
       " 'parsonage',\n",
       " 'vicarage',\n",
       " 'rectory',\n",
       " 'religious_residence',\n",
       " 'cloister',\n",
       " 'brownstone',\n",
       " 'terraced_house']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housinglemmas = [] # create an empty list\n",
    "\n",
    "for syn in hyposynlist:\n",
    "    for l in syn.lemmas():\n",
    "        if l.name() not in housinglemmas: # check for uniqueness\n",
    "            housinglemmas.append(l.name())\n",
    "\n",
    "for syn in finer_syns:\n",
    "    for l in syn.lemmas():\n",
    "         if l.name() not in housinglemmas: # check for uniqueness\n",
    "            housinglemmas.append(l.name())\n",
    "\n",
    "housinglemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! So many words for housing! -- and we could keep drilling down if we wanted to.\n",
    "\n",
    "As an analyst, you will often want to generate a rich list of synonyms and hyponyms like this one.  You will have to be the judge of when enough is enough. You will also have to navigate WordNet on your own to grab a rich sense of semantically connected words with precise meaning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a certain point, there are diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcazar', 'glebe_house', 'convent', 'monastery', 'priory']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housinglemmas2 = [] # create an empty list\n",
    "\n",
    "still_finer_syns = [] # create an empty list\n",
    " \n",
    "for syn in finer_syns: # loop through all the synsets\n",
    "    myhyponyms = syn.hyponyms()\n",
    "    for h in myhyponyms:\n",
    "        still_finer_syns.append(h)\n",
    "              \n",
    "for syn in still_finer_syns:\n",
    "    for l in syn.lemmas():\n",
    "         if l.name() not in housinglemmas2: # check for uniqueness\n",
    "            housinglemmas2.append(l.name())\n",
    "\n",
    "housinglemmas2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **Cleaning Up a  Controlled Vocabulary**\n",
    "Controlled vocabulary have to be used with care -- and with critical thinking.  What's in the controlled vocabulary matters.  \"Applesauce\" is listed in the thesaurus as a synonym for nonsense, but it also means a sauce made from cooked apples.  The term is *ambiguous*.  We could search for it, but we'd want to treat the term with particular care -- otherwise we might just find debates about apples. Therefore we should eliminate \"applesauce\" from our controlled vocabulary before searching\n",
    "\n",
    "Returning to the words in the variable *housinglemmas* above -- what do you think of our results? Are all of them precise as words for describing housing? Or are some of the indeterminate in meaning?  \n",
    "\n",
    "Here's what I see:\n",
    "\n",
    "   * 'hall' and 'court' can have other meanings -- if we're using these words to mine for text, we probably want to be careful about those words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach_house',\n",
       " 'boarding_house',\n",
       " 'boardinghouse',\n",
       " 'bungalow',\n",
       " 'cottage',\n",
       " 'cabin',\n",
       " 'chalet',\n",
       " 'chapterhouse',\n",
       " 'fraternity_house',\n",
       " 'frat_house',\n",
       " 'country_house',\n",
       " 'detached_house',\n",
       " 'single_dwelling',\n",
       " 'dollhouse',\n",
       " \"doll's_house\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housinglemmas2 = []\n",
    "\n",
    "for word in housinglemmas:\n",
    "    if word not in ['hall', 'court']:\n",
    "        housinglemmas2.append(word)\n",
    "\n",
    "housinglemmas2[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housinglemmas2 now has everything except 'hall' and 'court.' This is more appropriate for use with text mining, because we're more liable to get meaningful results with a more specific list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an analyst, you will have to make critical decisions about which of these words to use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data for use with raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare our list of words for matching with historic texts, we need to make sure that there aren't any characters that will interfere with the matchcing process.\n",
    "\n",
    "Hyphens and underscores are a problem for us.  Boardinghouse may be written \"boarding house\" or \"boardinghouse\" in a historical text, but not \"boarding_house.\"  What should we do?\n",
    "\n",
    "The easiest way to deal with this problem is to apply a cleaning script to BOTH the list of controlled vocabulary AND the historical text where we remove hyphens and underscores, replacing them all with spaces.  Then we can search for the word \"boardinghouse\" and the bigram \"boarding house\" in the raw text, and we will get all occurrences, no matter how they were punctuated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove hyphens and underscores from both the historical text and the controlled vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script below can be used to clean both the historical text and the controlled vocabulary, replacing hyphens and underscores with spaces in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beach house',\n",
       " 'boarding house',\n",
       " 'boardinghouse',\n",
       " 'bungalow',\n",
       " 'cottage',\n",
       " 'cabin',\n",
       " 'chalet',\n",
       " 'chapterhouse',\n",
       " 'fraternity house',\n",
       " 'frat house']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanwords = []\n",
    "\n",
    "for word in housinglemmas2:\n",
    "    v = word.replace('-', ' ')\n",
    "    v = v.replace('_', ' ') \n",
    "    cleanwords.append(str(v))\n",
    "    \n",
    "cleanwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's intensively look into words for crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore what it looks like to really dive deep into Wordnet, using Wordnet to generate a list of words for 'crime.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " 'offense',\n",
       " 'criminal_offense',\n",
       " 'criminal_offence',\n",
       " 'offence',\n",
       " 'law-breaking',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'aggravated_assault',\n",
       " 'battery',\n",
       " 'assault_and_battery',\n",
       " 'resisting_arrest',\n",
       " 'mugging',\n",
       " 'barratry',\n",
       " 'capital_offense',\n",
       " 'cybercrime',\n",
       " 'felony',\n",
       " 'commercial_bribery',\n",
       " 'housebreaking',\n",
       " 'break-in',\n",
       " 'breaking_and_entering',\n",
       " 'home_invasion',\n",
       " 'abduction',\n",
       " 'kidnapping',\n",
       " 'snatch',\n",
       " 'blackmail',\n",
       " 'protection',\n",
       " 'tribute',\n",
       " 'shakedown',\n",
       " 'biopiracy',\n",
       " 'breach_of_trust_with_fraudulent_intent',\n",
       " 'embezzlement',\n",
       " 'peculation',\n",
       " 'defalcation',\n",
       " 'misapplication',\n",
       " 'misappropriation',\n",
       " 'plunderage',\n",
       " 'raid',\n",
       " 'grand_larceny',\n",
       " 'grand_theft',\n",
       " 'petit_larceny',\n",
       " 'petty_larceny',\n",
       " 'petty',\n",
       " 'pilferage',\n",
       " 'robbery',\n",
       " 'armed_robbery',\n",
       " 'heist',\n",
       " 'holdup',\n",
       " 'stickup',\n",
       " 'caper',\n",
       " 'job',\n",
       " 'dacoity',\n",
       " 'dakoity',\n",
       " 'rip-off',\n",
       " 'highjacking',\n",
       " 'hijacking',\n",
       " 'piracy',\n",
       " 'buccaneering',\n",
       " 'highway_robbery',\n",
       " 'rolling',\n",
       " 'rustling',\n",
       " 'shoplifting',\n",
       " 'shrinkage',\n",
       " 'skimming',\n",
       " 'forgery',\n",
       " 'fraud',\n",
       " 'fraud_in_law',\n",
       " 'bunco',\n",
       " 'bunco_game',\n",
       " 'bunko',\n",
       " 'bunko_game',\n",
       " 'con',\n",
       " 'confidence_trick',\n",
       " 'confidence_game',\n",
       " 'con_game',\n",
       " 'gyp',\n",
       " 'hustle',\n",
       " 'sting',\n",
       " 'flimflam',\n",
       " 'sting_operation',\n",
       " 'holdout',\n",
       " 'pyramiding',\n",
       " 'scam',\n",
       " 'cozenage',\n",
       " 'shell_game',\n",
       " 'thimblerig',\n",
       " 'swiz',\n",
       " 'Had_crime',\n",
       " 'hijack',\n",
       " 'highjack',\n",
       " 'mayhem',\n",
       " 'misdemeanor',\n",
       " 'misdemeanour',\n",
       " 'infraction',\n",
       " 'violation',\n",
       " 'infringement',\n",
       " 'perpetration',\n",
       " 'commission',\n",
       " 'committal',\n",
       " 'statutory_offense',\n",
       " 'statutory_offence',\n",
       " 'regulatory_offense',\n",
       " 'regulatory_offence',\n",
       " 'molestation',\n",
       " 'rape',\n",
       " 'assault',\n",
       " 'ravishment',\n",
       " 'date_rape',\n",
       " 'statutory_rape',\n",
       " 'carnal_abuse',\n",
       " 'Tazir_crime',\n",
       " 'thuggery',\n",
       " 'treason',\n",
       " 'high_treason',\n",
       " 'lese_majesty',\n",
       " 'vice_crime',\n",
       " 'victimless_crime',\n",
       " 'war_crime']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from textblob import Word\n",
    "\n",
    "controlled_vocab = []\n",
    "        \n",
    "# get hyponyms of the hyponyms\n",
    "for synset in Word('crime').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name() not in controlled_vocab:\n",
    "            controlled_vocab.append(lemma.name())\n",
    "    for s in synset.hyponyms():\n",
    "        for lemma in s.lemmas():\n",
    "            if lemma.name() not in controlled_vocab:\n",
    "                controlled_vocab.append(lemma.name())\n",
    "        for syn in s.hyponyms():\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in controlled_vocab:\n",
    "                    controlled_vocab.append(lemma.name())        \n",
    "            for ss in syn.hyponyms():\n",
    "                for lemma in ss.lemmas():\n",
    "                    if lemma.name() not in controlled_vocab:\n",
    "                        controlled_vocab.append(lemma.name())\n",
    "                for sss in ss.hyponyms():\n",
    "                    for lemma in sss.lemmas():\n",
    "                        if lemma.name() not in controlled_vocab:\n",
    "                            controlled_vocab.append(lemma.name())\n",
    "                    for ssss in sss.hyponyms():\n",
    "                        for lemma in ssss.lemmas():\n",
    "                            if lemma.name() not in controlled_vocab:\n",
    "                                controlled_vocab.append(lemma.name())\n",
    "\n",
    "     \n",
    "controlled_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't use the .hypernyms() command above, but it's useful. \n",
    "\n",
    "    .hypernym()\n",
    "\n",
    "does the opposite of .hyponyms() -- it grabs the larger category, like 'cutlery' for 'fork,' or 'utensil' for 'cutlery.'  So if we take some hypernyms of 'crime' and then add all of their hyponyms, we get a very wide sweep of words for 'offense' or 'law-breaking.'  \n",
    "\n",
    "If we use hypernyms() to search a few categories up, we can make our list of words even wider.  \n",
    "   * First we gather the higher-level categories for 'crime' with .hypernyms\n",
    "   * Then we feed all of those words ('offense,' 'law-breaking,' etc.) back to .hyponyms() to get a complete set of evildoings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " 'offense',\n",
       " 'criminal_offense',\n",
       " 'criminal_offence',\n",
       " 'offence',\n",
       " 'law-breaking',\n",
       " 'transgression',\n",
       " 'evildoing']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper = []\n",
    "hypersyns = []\n",
    "\n",
    "for synset in Word('crime').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name() not in hyper:\n",
    "            hyper.append(lemma.name())\n",
    "    for s in synset.hypernyms():\n",
    "        for lemma in s.lemmas():\n",
    "            if lemma.name() not in hyper:\n",
    "                hyper.append(lemma.name())\n",
    "        for hh in s.hypernyms():\n",
    "            hypersyns.append(hh)\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in hyper:\n",
    "                    hyper.append(lemma.name())      \n",
    "       \n",
    "hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " 'offense',\n",
       " 'criminal_offense',\n",
       " 'criminal_offence',\n",
       " 'offence',\n",
       " 'law-breaking',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'aggravated_assault',\n",
       " 'battery',\n",
       " 'assault_and_battery',\n",
       " 'resisting_arrest',\n",
       " 'mugging',\n",
       " 'barratry',\n",
       " 'capital_offense',\n",
       " 'cybercrime',\n",
       " 'felony',\n",
       " 'commercial_bribery',\n",
       " 'housebreaking',\n",
       " 'break-in',\n",
       " 'breaking_and_entering',\n",
       " 'home_invasion',\n",
       " 'abduction',\n",
       " 'kidnapping',\n",
       " 'snatch',\n",
       " 'blackmail',\n",
       " 'protection',\n",
       " 'tribute',\n",
       " 'shakedown',\n",
       " 'biopiracy',\n",
       " 'breach_of_trust_with_fraudulent_intent',\n",
       " 'embezzlement',\n",
       " 'peculation',\n",
       " 'defalcation',\n",
       " 'misapplication',\n",
       " 'misappropriation',\n",
       " 'plunderage',\n",
       " 'raid',\n",
       " 'grand_larceny',\n",
       " 'grand_theft',\n",
       " 'petit_larceny',\n",
       " 'petty_larceny',\n",
       " 'petty',\n",
       " 'pilferage',\n",
       " 'robbery',\n",
       " 'armed_robbery',\n",
       " 'heist',\n",
       " 'holdup',\n",
       " 'stickup',\n",
       " 'caper',\n",
       " 'job',\n",
       " 'dacoity',\n",
       " 'dakoity',\n",
       " 'rip-off',\n",
       " 'highjacking',\n",
       " 'hijacking',\n",
       " 'piracy',\n",
       " 'buccaneering',\n",
       " 'highway_robbery',\n",
       " 'rolling',\n",
       " 'rustling',\n",
       " 'shoplifting',\n",
       " 'shrinkage',\n",
       " 'skimming',\n",
       " 'forgery',\n",
       " 'fraud',\n",
       " 'fraud_in_law',\n",
       " 'bunco',\n",
       " 'bunco_game',\n",
       " 'bunko',\n",
       " 'bunko_game',\n",
       " 'con',\n",
       " 'confidence_trick',\n",
       " 'confidence_game',\n",
       " 'con_game',\n",
       " 'gyp',\n",
       " 'hustle',\n",
       " 'sting',\n",
       " 'flimflam',\n",
       " 'sting_operation',\n",
       " 'holdout',\n",
       " 'pyramiding',\n",
       " 'scam',\n",
       " 'cozenage',\n",
       " 'shell_game',\n",
       " 'thimblerig',\n",
       " 'swiz',\n",
       " 'Had_crime',\n",
       " 'hijack',\n",
       " 'highjack',\n",
       " 'mayhem',\n",
       " 'misdemeanor',\n",
       " 'misdemeanour',\n",
       " 'infraction',\n",
       " 'violation',\n",
       " 'infringement',\n",
       " 'perpetration',\n",
       " 'commission',\n",
       " 'committal',\n",
       " 'statutory_offense',\n",
       " 'statutory_offence',\n",
       " 'regulatory_offense',\n",
       " 'regulatory_offence',\n",
       " 'molestation',\n",
       " 'rape',\n",
       " 'assault',\n",
       " 'ravishment',\n",
       " 'date_rape',\n",
       " 'statutory_rape',\n",
       " 'carnal_abuse',\n",
       " 'Tazir_crime',\n",
       " 'thuggery',\n",
       " 'treason',\n",
       " 'high_treason',\n",
       " 'lese_majesty',\n",
       " 'vice_crime',\n",
       " 'victimless_crime',\n",
       " 'war_crime',\n",
       " 'brutalization',\n",
       " 'brutalisation',\n",
       " 'champerty',\n",
       " 'dereliction',\n",
       " 'nonfeasance',\n",
       " 'dishonesty',\n",
       " 'knavery',\n",
       " 'charlatanism',\n",
       " 'quackery',\n",
       " 'falsification',\n",
       " 'falsehood',\n",
       " 'frame-up',\n",
       " 'setup',\n",
       " 'sophistication',\n",
       " 'treachery',\n",
       " 'betrayal',\n",
       " 'perfidy',\n",
       " 'double_cross',\n",
       " 'double-crossing',\n",
       " 'sellout',\n",
       " 'trick',\n",
       " 'misrepresentation',\n",
       " 'deception',\n",
       " 'deceit',\n",
       " 'dissembling',\n",
       " 'dissimulation',\n",
       " 'bluff',\n",
       " 'four_flush',\n",
       " 'cheat',\n",
       " 'cheating',\n",
       " 'delusion',\n",
       " 'illusion',\n",
       " 'head_game',\n",
       " 'duplicity',\n",
       " 'double-dealing',\n",
       " 'fakery',\n",
       " 'imposture',\n",
       " 'impersonation',\n",
       " 'indirection',\n",
       " 'obscurantism',\n",
       " 'pretense',\n",
       " 'pretence',\n",
       " 'pretending',\n",
       " 'simulation',\n",
       " 'feigning',\n",
       " 'take-in',\n",
       " 'trickery',\n",
       " 'chicanery',\n",
       " 'chicane',\n",
       " 'guile',\n",
       " 'wile',\n",
       " 'shenanigan',\n",
       " 'distortion',\n",
       " 'overrefinement',\n",
       " 'straining',\n",
       " 'torture',\n",
       " 'twisting',\n",
       " 'equivocation',\n",
       " 'tergiversation',\n",
       " 'lying',\n",
       " 'prevarication',\n",
       " 'fabrication',\n",
       " 'fibbing',\n",
       " 'paltering',\n",
       " 'infliction',\n",
       " 'injury',\n",
       " 'disservice',\n",
       " 'ill_service',\n",
       " 'ill_turn',\n",
       " 'spoil',\n",
       " 'spoiling',\n",
       " 'spoilage',\n",
       " 'wrong',\n",
       " 'legal_injury',\n",
       " 'damage',\n",
       " 'injustice',\n",
       " 'unfairness',\n",
       " 'iniquity',\n",
       " 'shabbiness',\n",
       " 'maintenance',\n",
       " 'criminal_maintenance',\n",
       " 'malfeasance',\n",
       " 'malpractice',\n",
       " 'malversation',\n",
       " 'misbehavior',\n",
       " 'misbehaviour',\n",
       " 'misdeed',\n",
       " 'abnormality',\n",
       " 'irregularity',\n",
       " 'deviation',\n",
       " 'deviance',\n",
       " 'delinquency',\n",
       " 'juvenile_delinquency',\n",
       " 'familiarity',\n",
       " 'impropriety',\n",
       " 'indecorum',\n",
       " 'liberty',\n",
       " 'indecency',\n",
       " 'obscenity',\n",
       " 'indiscretion',\n",
       " 'peccadillo',\n",
       " 'infantilism',\n",
       " 'mischief',\n",
       " 'mischief-making',\n",
       " 'mischievousness',\n",
       " 'deviltry',\n",
       " 'devilry',\n",
       " 'devilment',\n",
       " 'rascality',\n",
       " 'roguery',\n",
       " 'roguishness',\n",
       " 'hell',\n",
       " 'blaze',\n",
       " 'monkey_business',\n",
       " 'vandalism',\n",
       " 'hooliganism',\n",
       " 'malicious_mischief',\n",
       " 'ruffianism',\n",
       " 'misfeasance',\n",
       " 'perversion',\n",
       " 'tort',\n",
       " 'civil_wrong',\n",
       " 'alienation_of_affection',\n",
       " 'invasion_of_privacy',\n",
       " 'trespass',\n",
       " 'continuing_trespass',\n",
       " 'trespass_de_bonis_asportatis',\n",
       " 'trespass_on_the_case',\n",
       " 'trespass_quare_clausum_fregit',\n",
       " 'trespass_viet_armis',\n",
       " 'transgression',\n",
       " 'evildoing',\n",
       " 'abomination',\n",
       " 'depravity',\n",
       " 'turpitude',\n",
       " 'evil',\n",
       " 'immorality',\n",
       " 'wickedness',\n",
       " 'foul_play',\n",
       " 'irreverence',\n",
       " 'sexual_immorality',\n",
       " 'inside_job',\n",
       " 'sin',\n",
       " 'sinning',\n",
       " 'actual_sin',\n",
       " 'fall',\n",
       " 'mortal_sin',\n",
       " 'deadly_sin',\n",
       " 'original_sin',\n",
       " 'venial_sin',\n",
       " 'terrorization',\n",
       " 'terrorisation',\n",
       " 'vice',\n",
       " 'gambling',\n",
       " 'gaming',\n",
       " 'play',\n",
       " 'intemperance',\n",
       " 'intemperateness',\n",
       " 'villainy',\n",
       " 'encroachment',\n",
       " 'intrusion',\n",
       " 'usurpation',\n",
       " 'inroad',\n",
       " 'copyright_infringement',\n",
       " 'infringement_of_copyright',\n",
       " 'plagiarism',\n",
       " 'plagiarization',\n",
       " 'plagiarisation',\n",
       " 'foul',\n",
       " 'foul_ball',\n",
       " 'personal_foul',\n",
       " 'technical_foul',\n",
       " 'technical',\n",
       " 'patent_infringement']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    for synset in hypersyns:\n",
    "        for ss in synset.hyponyms():\n",
    "                for lemma in ss.lemmas():\n",
    "                    if lemma.name() not in controlled_vocab:\n",
    "                        controlled_vocab.append(lemma.name())\n",
    "                for sss in ss.hyponyms():\n",
    "                    for lemma in sss.lemmas():\n",
    "                        if lemma.name() not in controlled_vocab:\n",
    "                            controlled_vocab.append(lemma.name())\n",
    "                    for ssss in sss.hyponyms():\n",
    "                        for lemma in ssss.lemmas():\n",
    "                            if lemma.name() not in controlled_vocab:\n",
    "                                controlled_vocab.append(lemma.name())\n",
    "controlled_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've ignored 'murder' somehow in this list of crime, so let's add hyponyms and near matches for 'murder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " 'offense',\n",
       " 'criminal_offense',\n",
       " 'criminal_offence',\n",
       " 'offence',\n",
       " 'law-breaking',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'aggravated_assault',\n",
       " 'battery']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get hyponyms of the hyponyms\n",
    "for synset in Word('murder').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name() not in controlled_vocab:\n",
    "            controlled_vocab.append(lemma.name())\n",
    "    for s in synset.hyponyms():\n",
    "        for lemma in s.lemmas():\n",
    "            if lemma.name() not in controlled_vocab:\n",
    "                controlled_vocab.append(lemma.name())\n",
    "        for syn in s.hyponyms():\n",
    "            for lemma in s.lemmas():\n",
    "                if lemma.name() not in controlled_vocab:\n",
    "                    controlled_vocab.append(lemma.name())        \n",
    "            for ss in syn.hyponyms():\n",
    "                for lemma in ss.lemmas():\n",
    "                    if lemma.name() not in controlled_vocab:\n",
    "                        controlled_vocab.append(lemma.name())\n",
    "                for sss in ss.hyponyms():\n",
    "                    for lemma in sss.lemmas():\n",
    "                        if lemma.name() not in controlled_vocab:\n",
    "                            controlled_vocab.append(lemma.name())\n",
    "                    for ssss in sss.hyponyms():\n",
    "                        for lemma in ssss.lemmas():\n",
    "                            if lemma.name() not in controlled_vocab:\n",
    "                                controlled_vocab.append(lemma.name())\n",
    "\n",
    "\n",
    "for synset in Word('murder').synsets:\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name() not in controlled_vocab:\n",
    "            controlled_vocab.append(lemma.name())\n",
    "    for s in synset.hypernyms():\n",
    "        for lemma in s.lemmas():\n",
    "            if lemma.name() not in controlled_vocab:\n",
    "                controlled_vocab.append(lemma.name())\n",
    "            \n",
    "controlled_vocab[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(controlled_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crime',\n",
       " 'offense',\n",
       " 'criminal offense',\n",
       " 'criminal offence',\n",
       " 'offence',\n",
       " 'law breaking',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'aggravated assault',\n",
       " 'battery']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_controlled_vocab = []\n",
    "\n",
    "for word in controlled_vocab:\n",
    "    v = word.replace('-', ' ')\n",
    "    v = v.replace('_', ' ') \n",
    "    clean_controlled_vocab.append(str(v))\n",
    "    \n",
    "clean_controlled_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vocab = pd.DataFrame(data={\"word\": clean_controlled_vocab})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>criminal offense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>criminal offence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word\n",
       "0             crime\n",
       "1           offense\n",
       "2  criminal offense\n",
       "3  criminal offence\n",
       "4           offence"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the data for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/jguldi/digital-history\n"
     ]
    }
   ],
   "source": [
    "cd ~/digital-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.to_csv('crime_vocab.csv', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "1) Read the wordnet documentation.  How do you use wordnet to find antonyms? Call up some antonyms for common words.\n",
    "\n",
    "   * https://www.nltk.org/howto/wordnet.html\n",
    "\n",
    "2) Find all the words for 'happy' in Jane Austen.\n",
    "\n",
    "3) Think about ambiguity in the list of words for crime.  Decide on a list of words to use as stopwords for that list -- words that have too many meanings for them to be useful.  Stopword the crime vocab list. Re-save it.\n",
    "\n",
    "Upload a screenshot of your code and results to Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
