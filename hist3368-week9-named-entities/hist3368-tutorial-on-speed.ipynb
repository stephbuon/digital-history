{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist 3368\n",
    "## Tutorial on Speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say you want to use Spacy, a resource-intensive software package, to extract named entities from Congress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, spacy\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting an error? \n",
    "\n",
    "* Please note that to use spaCy on M2 you must go to My Interactive Sessions/JupyterLab and add **source /hpc/applications/python_environments/spacy/bin/activate** to the **“Custom environment settings”** field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to load the speeches of Congress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/group/history/hist_3368-jguldi\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "congress = pd.read_csv(\"congress1967-2010.csv\")\n",
    "#congress = pd.read_csv(\"eighties_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/jguldi/digital-history\n"
     ]
    }
   ],
   "source": [
    "cd ~/digital-history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice that the Code is slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply our event recognizer to just a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'congress_1968' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d2ec25e1f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mner_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LAW'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspeech\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcongress_1968\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'speech'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'congress_1968' is not defined"
     ]
    }
   ],
   "source": [
    "sample = [ner_finder(speech, 'LAW') for speech in congress_1968['speech'][:20]]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the code hangs for a minute. Spacy uses a lot of 'memory' -- or computing power.  Coders have tricks to speed things up.  Let's talk about that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tracking Speed with time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Many coders like to keep track of how fast different approaches are so that they can choose the speediest approach when they move from small data to big data. Let's do that.  We'll import the *time* module and call\n",
    "\n",
    "    time.time() \n",
    "    \n",
    "to get the time in milliseconds.  Then we run the same line of code, and call time.time() again afterwards, and subtract start time from finish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use datetime.time() to take the time before and after the operation to see how quick or slow each operation is.\n",
    "\n",
    "Here's the same code you just ran again, with timing instructions around it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "sample = [ner_finder(speech, 'LAW') for speech in congress_1968['speech'][:-20]]\n",
    "\n",
    "finish = time.time()\n",
    "\n",
    "print(sample)\n",
    "print()\n",
    "\n",
    "finish-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's try a speedier approach.  Let's use our parallelized ner_finder to search for mentions of laws in just one year. \n",
    "\n",
    "Again, we'll run the sample code on a tiny sample.  Again, we'll keep track of how long it takes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Speeding things up with .apply()\n",
    "\n",
    "To speed things up, we can try calling upon \"parallel\" processing, which causes every node within a computer system to run the same command simultaneously.  \n",
    "\n",
    "We'll use a 'lambda' function, which allows us to take the function following \"lambda x\" and efficiently \"apply\" it to every row in the dataframe. Lambda functions run in parallel.\n",
    "\n",
    "Note these two elements of the grammar.\n",
    "\n",
    "    .apply()\n",
    "    lambda x: [function to be applied]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tutorial about using .apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/smPLY_5gVv4\" title=\"YouTube video player\"\"></iframe>')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's some code using .apply() with ner_finder() to search for all the laws mentioned in the Dallas Minutes.\n",
    "\n",
    "Note that we are also using *time.time()* to take the time in milliseconds before and after running the function, so that we can compare how fast the .apply() method is to similar code using list comprehension above.\n",
    "\n",
    "**This may still take a minute.** But apply is potentially much, much faster than if you had run the same command wihtout parallel processing.  \n",
    "\n",
    "*Note: You will see a pink warning label. It isn't an error, and the data is still running.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "sample2 = dallas_minutes['Text'][:5].apply(lambda x: ner_finder(x, 'LAW'))\n",
    "\n",
    "finish = time.time()\n",
    "\n",
    "print(sample2)\n",
    "print()\n",
    "\n",
    "finish-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winner is... the .apply() method in parallel -- faster by a hair! (*NOTE: Your mileage may vary*)\n",
    "\n",
    "Let's run it on a slightly larger sample of text -- the whole year 2019.  \n",
    "\n",
    "***We chose the faster method on purpose, but NER is a slow process. This process clocks at 30 m on my session. Get a cup of tea.***\n",
    "\n",
    "*You can also limit the amount of text you're working with by using square brackets, e.g. dallas_minutes_year1['Text'][:100]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "\n",
    "dallas_minutes_year1['Laws'] = dallas_minutes_year1['Text'].apply(lambda x: ner_finder(x, 'LAW'))\n",
    "\n",
    "finish = time.time()\n",
    "print(finish-start)\n",
    "\n",
    "\n",
    "dallas_minutes_year1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the code for applying nlp to the entire archive of Dallas City Council minutes, not just one year.  \n",
    "#dallas_minutes['Laws'] = dallas_minutes['Text'].apply(lambda x: ner_finder(x, 'LAW'))\n",
    "#dallas_minutes                                                                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
