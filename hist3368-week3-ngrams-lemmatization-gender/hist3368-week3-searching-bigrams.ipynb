{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week3-ngrams-lemmatization-gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Mini Notebook: Searching Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often in this work we will be interested not only in individual words but in multiple word phrases.  Sometimes multiple word phrases are repeated often, and they hold potent meaning:\n",
    "    \n",
    "   * true love\n",
    "   * dining room\n",
    "   * bitter justice\n",
    "\n",
    "Counting two word phrases can also illuminate hidden bias in large groups of documents. For example, one study proved that plot summaries of twentieth-century American movies tended to assign different verbs to the pronouns \"he\" and \"she\":\n",
    "\n",
    "   * he beats\n",
    "   * he instructs\n",
    "   * he challenges\n",
    "   * he orders\n",
    "   * he owns\n",
    "   * she cries\n",
    "   * she rejects\n",
    "   * she accepts\n",
    "   * she forgives\n",
    "   * she begs\n",
    "   \n",
    "see http://varianceexplained.org/r/tidytext-gender-plots/\n",
    "\n",
    "Clearly, these two-word phrases suggest some bias in the ways that women and men are portrayed on the American screen.\n",
    "\n",
    "In this notebook, we will learn how to search for multiple-word phrases.   We will use the **TextBlob** software package and the command **.ngram()** to find these phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download some Jane Austen Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps repeat the instructions for downloading and cleaning text from earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, numpy, re, matplotlib# , num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/group/history/hist_3368-jguldi\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download some data\n",
    "\n",
    "with open('senseandsensibility.txt', 'r') as myfile:\n",
    "    sas_data = myfile.read().split('\\n\\n\"I suppose you know, ma\\'am, that Mr. Ferrars is married\"\\n\\nIt _was_ Edward\\n\\n\"Everything in such respectable condition\"\\n\\n ')[1].split('THE END')[0].strip()\n",
    "\n",
    "with open('emma.txt', 'r') as myfile:\n",
    "    emma_data = myfile.read().split('CHAPTER I')[1].split('FINIS')[0].strip()\n",
    "\n",
    "with open('prideandprejudice.txt', 'r') as myfile:\n",
    "    pap_data = myfile.read().split('CHAPTER I')[1].split('End of the Project Gutenberg EBook of Pride and Prejudice, by Jane Austen')[0].strip()\n",
    "\n",
    "# combine into a list\n",
    "data = [sas_data, emma_data, pap_data]\n",
    "\n",
    "# remove whitespace characters\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\n', ' ')\n",
    "\n",
    "# split into words\n",
    "import pandas\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "\n",
    "# lowercase and strip punctuation\n",
    "import re\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # data[i] is the current novel\n",
    "    data[i] = data[i].lower() # force to lowercase\n",
    "    data[i] = re.sub('[\\\",.;:?([)\\]_*]', '', data[i]) # remove punctuation and special characters with regular expression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of novels called **data**, which has been stripped of punctuation & lowercased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*IMPORTANTLY* please note that we did not stopword the data this time.  When we look for grammatical relationships -- like verbs that follow nouns, or meaningful two-word phrases -- many stopwords are important.  \n",
    "\n",
    "The analyst has to choose which cleaning steps to use for each analysis in question.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                 chapter i   the family of dashwood had long been settled in sussex their estate was large and their residence was at norland park in the centre of their property where for many generations they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance the late owner of this estate was a single man who lived to a very advanced age and who for many years of his life had a constant companion and housekeeper in his s'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words and N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to look for multi-word phrases instead of individual words.  For example, if we're researching the living spaces of Jane Austen's England, we definitely want to know whether she refers to \"dining rooms\" or \"bed-rooms\" (which our punctuation clean-up might have turned into separate words, depending on what we did)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the software package **textblob** and the command TextBlob().  **TextBlob()** takes an object which is a string of text.\n",
    "\n",
    "   TextBlob(novel)\n",
    "\n",
    "We will use the command **.ngrams()** which takes the object \"n = _,\" where _ is set as the number of words in a phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we tell TextBlob to look at the first 100 characters of Sense and Sensibility for 2-word phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['chapter', 'i']),\n",
       " WordList(['i', 'the']),\n",
       " WordList(['the', 'family']),\n",
       " WordList(['family', 'of']),\n",
       " WordList(['of', 'dashwood']),\n",
       " WordList(['dashwood', 'had']),\n",
       " WordList(['had', 'long']),\n",
       " WordList(['long', 'been']),\n",
       " WordList(['been', 'settled']),\n",
       " WordList(['settled', 'in']),\n",
       " WordList(['in', 'sussex'])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "bigrams = TextBlob(data[0][:100]).ngrams(n=2)\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now the bigrams are in the proprietary \"WordList\" format.  \n",
    "\n",
    "We can convert them into a normal list by:\n",
    "   * calling each part of the list using square brackets (**bigram[0]**, **bigram[1]**)\n",
    "   * pasting them together using '+' with a space (' ') in the middle \n",
    "\n",
    "Here's a loop to clean them up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'i the',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in',\n",
       " 'in sussex']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramlist = []\n",
    "for bigram in bigrams:\n",
    "    bigram2 = bigram[0] + ' ' + bigram[1]\n",
    "    bigramlist.append(bigram2)\n",
    "bigramlist[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try that on all the novels, using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'i the',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramlist = []\n",
    "\n",
    "for novel in data:\n",
    "    bigrams = TextBlob(novel).ngrams(n=2)\n",
    "    for bigram in bigrams:\n",
    "        bigram2 = bigram[0] + ' ' + bigram[1]\n",
    "        bigramlist.append(bigram2)\n",
    "\n",
    "bigramlist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the bigrams in one list, we can also count the overall top bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the most common bigrams with **value_counts()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to be            448\n",
       "of the           444\n",
       "in the           369\n",
       "of her           291\n",
       "it was           290\n",
       "                ... \n",
       "miss dashwood     70\n",
       "is a              70\n",
       "out of            69\n",
       "you have          69\n",
       "to him            69\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts = pd.Series.value_counts(bigramlist)\n",
    "bigramcounts[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwording a bigram list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, this is boring.  Now is a good time to apply stopwords.  \n",
    "\n",
    "Why now? Because we have already done the n-gram analysis, and all of our n-grams are grammatically meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a for loop to apply stopwords to the bigram list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mrs jennings    237\n",
       " dtype: int64, could not    167\n",
       " dtype: int64, colonel brandon    132\n",
       " dtype: int64, mrs dashwood    121\n",
       " dtype: int64, sir john    112\n",
       " dtype: int64, would not    101\n",
       " dtype: int64, would be    100\n",
       " dtype: int64, lady middleton    96\n",
       " dtype: int64, would have    86\n",
       " dtype: int64, must be    86\n",
       " dtype: int64, every thing    81\n",
       " dtype: int64, could be    77\n",
       " dtype: int64, mrs ferrars    76\n",
       " dtype: int64, marianne 's    74\n",
       " dtype: int64, miss dashwood    70\n",
       " dtype: int64, may be    62\n",
       " dtype: int64, elinor 's    62\n",
       " dtype: int64, said elinor    61\n",
       " dtype: int64, soon as    61\n",
       " dtype: int64, sister 's    54\n",
       " dtype: int64]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "cleanbigramcounts = []\n",
    "    \n",
    "for n in range(len(bigramcounts)):\n",
    "    bigram2 = bigramcounts.index[n].split()\n",
    "    if (bigram2[1] and bigram2[0]) not in stopwords:\n",
    "        cleanbigramcounts.append(bigramcounts[[n]]) # use double brackets to grab the whole row -- including the index\n",
    "\n",
    "cleanbigramcounts[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling diversion: splitting bigrams to check if they contain stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you examine the for-loop above, you might notice that there are some tricky calls going on in the above for loop. That's because bigramcounts is a seris object -- with an index and a number.  \n",
    "   * We have to call each bigram count index to get the bigram itself rather than the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in the    369\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts.index[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to split the bigram in two to get the individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'the']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts.index[i].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we can use the 'in' operator to check if one of those words is in the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'in' in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line does the same thing -- calling the first word in the two-word bigram phrase from the index of bigramcounts, line 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts.index[i].split()[1] in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a tiny demo forloop that cycles through each word of a two-word phrase and asks if it is in stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for word in (bigramcounts.index[i].split()):\n",
    "    print(word in stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below line uses the 'and' operator to do the same thing -- cycling through each word of a two-word phrase and asking if it is in stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram2 = bigramcounts.index[1].split()\n",
    "(bigram2[1] and bigram2[0]) in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could switch the 'and' to 'or' in the loop above to find the bigrams that contain one or fewer stopwords in the formula. Why don't you try that and see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering bigrams for a common word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we will want to look not at the entire set of bigrams but at bigrams that contain words that are meaningful for a certain kind of analysis, for instance verbs that follow 'she' and verbs that follow 'he.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only want the bigrams that include the word \"she\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she was      213\n",
       "she had      193\n",
       "that she     122\n",
       "as she       116\n",
       "she could    108\n",
       "and she       96\n",
       "she would     64\n",
       "said she      47\n",
       "she is        46\n",
       "which she     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "she_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if \"she\" in bigram: # notice the space after she.  It\n",
    "        she_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(she_bigrams)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the above code won't work for 'he,' because it will pick up other words that contain 'he,' including:\n",
    "   * 'she' \n",
    "   * 'mother' \n",
    "   * 'heart' \n",
    "   * 'her'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "of the        444\n",
       "in the        369\n",
       "of her        291\n",
       "to the        244\n",
       "to her        234\n",
       "she was       213\n",
       "she had       193\n",
       "on the        161\n",
       "and the       160\n",
       "at the        160\n",
       "her sister    145\n",
       "for the       138\n",
       "her own       131\n",
       "he was        126\n",
       "that she      122\n",
       "in her        120\n",
       "her mother    118\n",
       "by the        117\n",
       "as she        116\n",
       "that he       116\n",
       "he had        113\n",
       "they were     111\n",
       "from the      109\n",
       "she could     108\n",
       "all the       104\n",
       "the same      103\n",
       "of their       97\n",
       "and she        96\n",
       "and her        96\n",
       "with the       92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if \"he\" in bigram: # notice the space after she.  It\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(he_bigrams)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining our filter using Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to use \"regular expressions,\" which are ways of coding the details of language.  You can communicate to the computer about such needs as detecting the beginning or end of a word by using two backslashes (an \"escape\" to tell the computer not to take the next letter literally) and \"b\" for \"boundary.\"  If you tell the computer to find a \"boundary\" in this way, it will look for both spaces and for the end of strings.\n",
    "\n",
    "Notice how I use two \"\\\\\\b\"'s below to tell the computer to look for the word \"he\" but not \"her\" or \"the.\" Python use the 're' package to detect regular expressions, and the .compile() and .match() commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(\"\\\\bhe\\\\b\") #  notice the .compile() and the \"escapes\"+b to signify \"word boundary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he was        126\n",
       "he had        113\n",
       "he is          75\n",
       "he has         49\n",
       "he did         37\n",
       "he could       36\n",
       "he would       28\n",
       "he said        23\n",
       "he should      23\n",
       "he replied     22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if pattern.match(bigram): # notice the use of .match()\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(he_bigrams)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Write a for-loop that looks for bigrams, trigrams, up to nine-grams in Jane Austen, by switching out '_' in the the 'n = _' parameters of the .ngrams() command.\n",
    "* Add a line of .value_counts() to the for-loop.  Using the **len()** command, count how many multi-word phrases there are for each iteration, i.e.: how many 9-word phrases are there, total? how many 8-word phrases? how many 7-word phrases? etc. \n",
    "* Adjust the for-loop to save the results of **len()** in a list.  HINT: You may need to greate a new dummy variable for this count before the for loop.\n",
    "* What are the longest phrases that are repeated more than 3 times across Austen's corpus? \n",
    "* Add to your for-loop a step to stopword each word in your analysis of phrases to make your results more meaningful.  What are the longest 3-word phrases in Jane Austen that don't include stopwords? HINT: Study the section labeled 'data digression' to split up your bigrams and test them individually.\n",
    "\n",
    "Upload a screenshot of your code and the answer to Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
