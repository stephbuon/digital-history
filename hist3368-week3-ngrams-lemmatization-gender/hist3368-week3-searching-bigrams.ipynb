{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week3-ngrams-lemmatization-gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Mini Notebook: Searching Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often in this work we will be interested not only in individual words but in multiple word phrases.  Sometimes multiple word phrases are repeated often, and they hold potent meaning:\n",
    "    \n",
    "   * true love\n",
    "   * dining room\n",
    "   * law and order\n",
    "\n",
    "Counting two word phrases can also illuminate hidden bias in large groups of documents. For example, one study proved that plot summaries of twentieth-century American movies tended to assign different verbs to the pronouns \"he\" and \"she\":\n",
    "\n",
    "   * he beats\n",
    "   * he instructs\n",
    "   * he challenges\n",
    "   * he orders\n",
    "   * he owns\n",
    "   \n",
    " \n",
    "   * she cries\n",
    "   * she rejects\n",
    "   * she accepts\n",
    "   * she forgives\n",
    "   * she begs\n",
    "   \n",
    "see http://varianceexplained.org/r/tidytext-gender-plots/\n",
    "\n",
    "Clearly, these two-word phrases suggest some bias in the ways that women and men are portrayed on the American screen.\n",
    "\n",
    "The practice of finding multiple-word phrases is called finding **\"ngrams\"**.  A two-word phrase is also called a **\"bigram\"**.  A three-word phrase is called a **\"trigram\"**, and so on.  \n",
    "\n",
    "In general, repeated many-word phrases often hold telling clues about the values of a text.\n",
    "\n",
    "In this notebook, we will learn how to search for multiple-word phrases.   We will use the **TextBlob** software package and the command **.ngram()** to find these phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download some Jane Austen Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps repeat the instructions for downloading and cleaning text from earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, numpy, re, matplotlib# , num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/group/history/hist_3368-jguldi\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download some data\n",
    "\n",
    "with open('senseandsensibility.txt', 'r') as myfile:\n",
    "    sas_data = myfile.read().split('\\n\\n\"I suppose you know, ma\\'am, that Mr. Ferrars is married\"\\n\\nIt _was_ Edward\\n\\n\"Everything in such respectable condition\"\\n\\n ')[1].split('THE END')[0].strip()\n",
    "\n",
    "with open('emma.txt', 'r') as myfile:\n",
    "    emma_data = myfile.read().split('CHAPTER I')[1].split('FINIS')[0].strip()\n",
    "\n",
    "with open('prideandprejudice.txt', 'r') as myfile:\n",
    "    pap_data = myfile.read().split('CHAPTER I')[1].split('End of the Project Gutenberg EBook of Pride and Prejudice, by Jane Austen')[0].strip()\n",
    "\n",
    "# combine into a list\n",
    "data = [sas_data, emma_data, pap_data]\n",
    "\n",
    "# remove whitespace characters\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\n', ' ')\n",
    "\n",
    "# split into words\n",
    "import pandas\n",
    "\n",
    "for novel in data:\n",
    "    words = novel.split()\n",
    "\n",
    "# lowercase and strip punctuation\n",
    "import re\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # data[i] is the current novel\n",
    "    data[i] = data[i].lower() # force to lowercase\n",
    "    data[i] = re.sub('[\\\",.;:?([)\\]_*]', '', data[i]) # remove punctuation and special characters with regular expression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of novels called **data**, which has been stripped of punctuation & lowercased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***IMPORTANTLY*** please note that we did not stopword the data this time.  When we look for grammatical relationships -- like verbs that follow nouns, which we will capture in today's analysis, or meaningful two-word phrases -- stopwords are important.  Stopwords are part of the order of the sentence.  If we stopworded the paragraph below, we would produce a list of two-word phrases that are not accurate for the flow of Austen's language.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chapter i   the family of dashwood had long been settled in sussex their estate was large and their residence was at norland park in the centre of their property where for many generations they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance the late owner of this estate was a single man who lived to a very advanced age and who for many years of his life had a constant companion and housekeeper in his s'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:500].strip() # .strip() just removes the extra whitespace from the title page and allow the text to display properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we did stopwords first and then counted n-grams, we wouldn't be getting accurate results. Instead, we'll find the n-grams and then remove n-grams with stopwords in them.\n",
    "\n",
    "As this course moves forward, we'll discuss less and less the steps for cleaning that we have chosen and the order.  We'll leave it to you to figure out why certain steps go in a certain order. \n",
    "\n",
    "You should get into the habit of asking yourself which cleaning steps have been executed, in which order, and what that means for the results. \n",
    "\n",
    "In text mining, the analyst has to choose which cleaning steps to use for each analysis in question.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Words and N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to look for multi-word phrases instead of individual words.  For example, if we're researching the living spaces of Jane Austen's England, we definitely want to know whether she refers to \"dining rooms\" or \"bed-rooms\" (which our punctuation clean-up might have turned into separate words, depending on what we did)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the software package **textblob** and the command TextBlob().  **TextBlob()** takes an object which is a string of text.\n",
    "\n",
    "   TextBlob(novel)\n",
    "\n",
    "We will use the command **.ngrams()** which takes the object \"n = _,\" where _ is set as the number of words in a phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we tell TextBlob to look at the first 100 characters of Sense and Sensibility for 2-word phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "bigrams = TextBlob(data[0][:100]).ngrams(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that right now the bigrams are in the proprietary **\"WordList\"** format.  Wordlist is part of the proprietary software associated with the package TextBlob. It functions much like a **normal list**.\n",
    "\n",
    "We can convert them into a **normal list** by:\n",
    "   * calling each part of the list using square brackets (**bigram[0]**, **bigram[1]**)\n",
    "   * pasting them together using '+' with a space (' ') in the middle \n",
    "\n",
    "Here's a loop to clean them up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'i the',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in',\n",
       " 'in sussex']"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramlist = []\n",
    "for bigram in bigrams:\n",
    "    bigram2 = bigram[0] + ' ' + bigram[1]\n",
    "    bigramlist.append(bigram2)\n",
    "bigramlist[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what's happening. If you read through the first word only of the above pairs, it reads just like the first words of the chapter: \"Chapter i: The Family of Dashwood had long been settled in Sussex.\"  But the computer has identified all the two-word pairs in that sentence: \"the family,\" \"family of,\" \"of Dashwood.\"  \n",
    "\n",
    "That is *exactly* what bigrams are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try the cleaning step we just tried, applied to all the novels, using a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'i the',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramlist = []\n",
    "\n",
    "for novel in data:\n",
    "    bigrams = TextBlob(novel).ngrams(n=2)\n",
    "    for bigram in bigrams:\n",
    "        bigram2 = bigram[0] + ' ' + bigram[1]\n",
    "        bigramlist.append(bigram2)\n",
    "\n",
    "bigramlist[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the bigrams in one list, we can also count the overall top bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the most common bigrams with **value_counts()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to be            448\n",
       "of the           444\n",
       "in the           369\n",
       "of her           291\n",
       "it was           290\n",
       "                ... \n",
       "miss dashwood     70\n",
       "is a              70\n",
       "out of            69\n",
       "you have          69\n",
       "to him            69\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramcounts = pd.Series.value_counts(bigramlist)\n",
    "bigramcounts[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it!  Also, our results are boring.  Now is a good time to apply stopwords.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwording a bigram list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why now? Because we have already done the n-gram analysis, and all of our n-grams are grammatically meaningful.\n",
    "\n",
    "*As a general rule, you must apply grammatical analysis -- like counting n-grams -- before removing words*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to stopword a bigram list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwording a bigram list is a little more tricky than stopwording a single word list, because each bigram is composed of two words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "\"to\" in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"be\" in stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"to be\" in stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we break up \"to be\" into two words, stopwording works again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to', 'be']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"to be\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for word in  \"to be\".split():\n",
    "    print(word in stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of condensing that information is to tweak the for loop above to the formula\n",
    "\n",
    "     item in list1 for item in list2 \n",
    "\n",
    "-- which means exactly the same as the loop above.\n",
    "\n",
    "Then we can use the conditional \"all\" to see if both statements are true (both 'to' and 'be' are in stopwords) -- or whether \"any\" statement is true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(word in stopwords for word in \"to be\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(word in stopwords for word in \"to be\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a for loop to apply stopwords to the bigram list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter i',\n",
       " 'the family',\n",
       " 'family of',\n",
       " 'of dashwood',\n",
       " 'dashwood had',\n",
       " 'had long',\n",
       " 'long been',\n",
       " 'been settled',\n",
       " 'settled in',\n",
       " 'in sussex',\n",
       " 'sussex their',\n",
       " 'their estate',\n",
       " 'estate was',\n",
       " 'was large',\n",
       " 'large and',\n",
       " 'their residence',\n",
       " 'residence was',\n",
       " 'at norland',\n",
       " 'norland park',\n",
       " 'park in']"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanbigramlist = []\n",
    "    \n",
    "for bigram in bigramlist:\n",
    "    bigram2 = bigram.split()\n",
    "    if any(word not in stopwords for word in bigram2): # if all the words in the bigram are non-stopwords, then:\n",
    "        bigram3 = bigram2[0] + ' ' + bigram2[1] # glue the split words back into a phrase with a space in the middle\n",
    "        cleanbigramlist.append(bigram3) # use double brackets to grab the whole row -- including the index\n",
    "\n",
    "cleanbigramlist[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the top stopworded bigrams across Jane Austen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mrs jennings       237\n",
       "could not          167\n",
       "her sister         145\n",
       "colonel brandon    132\n",
       "mrs dashwood       121\n",
       "her mother         118\n",
       "sir john           112\n",
       "she could          108\n",
       "would not          101\n",
       "to see             101\n",
       "would be           100\n",
       "lady middleton      96\n",
       "the world           92\n",
       "the house           88\n",
       "would have          86\n",
       "must be             86\n",
       "every thing         81\n",
       "could be            77\n",
       "it would            77\n",
       "am sure             77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.value_counts(cleanbigramlist)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question: how would the results of this table look different if you used \"all\" instead of \"any\" in the loop above?  Try swapping them out and see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering bigrams for a common word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we will want to look not at the entire set of bigrams but at bigrams that contain words that are meaningful for a certain kind of analysis, for instance verbs that follow 'she' and verbs that follow 'he.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we only want the bigrams that include the word \"she\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a naive way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "she was      213\n",
       "she had      193\n",
       "that she     122\n",
       "as she       116\n",
       "she could    108\n",
       "and she       96\n",
       "she would     64\n",
       "said she      47\n",
       "she is        46\n",
       "which she     45\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "she_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if \"she\" in bigram: # notice the space after she.  It\n",
    "        she_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(she_bigrams)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the above code won't work for 'he,' because it will pick up other words that contain 'he,' including:\n",
    "   * 'she' \n",
    "   * 'mother' \n",
    "   * 'heart' \n",
    "   * 'her'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "of the        444\n",
       "in the        369\n",
       "of her        291\n",
       "to the        244\n",
       "to her        234\n",
       "she was       213\n",
       "she had       193\n",
       "on the        161\n",
       "and the       160\n",
       "at the        160\n",
       "her sister    145\n",
       "for the       138\n",
       "her own       131\n",
       "he was        126\n",
       "that she      122\n",
       "in her        120\n",
       "her mother    118\n",
       "by the        117\n",
       "as she        116\n",
       "that he       116\n",
       "he had        113\n",
       "they were     111\n",
       "from the      109\n",
       "she could     108\n",
       "all the       104\n",
       "the same      103\n",
       "of their       97\n",
       "and she        96\n",
       "and her        96\n",
       "with the       92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if \"he\" in bigram: # notice the space after she.  It\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(he_bigrams)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining our filter using Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to use \"regular expressions,\" which are ways of coding the details of language.  We will use the **re** package and the command **.compile()** to make a \"regular expression\" that helps Python to search for an *exact word* like 'he' rather than the string 'he' as it appears in words like 'her' and 'heart.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.compile()** takes one object -- a properly formatted \"Regular Expression.\"\n",
    "\n",
    "The **re.compile()** command allows you to communicate with Python about such needs as detecting the beginning or end of a word.\n",
    "\n",
    "In fact, telling Python about the beginning and end of words is the major reason you'll want to use Regular Expressions in this class. We'll search for words this way all the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(\"\\\\bhe\\\\b\") #  notice the .compile() and the \"escapes\"+b to signify \"word boundary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the rules you need to know:\n",
    "\n",
    "   * codes in Regular Expressions begin with two backslashes. This punctuation tells the computer not to take the next letter literally: **\"\\\\\\\\\"**.  This is called an \"escape\"\n",
    "   * with \"b\" for \"boundary,\" --  **\"\\\\\\b\"** -- the regular exprerssion tells the computer to search for a word \"boundary.\"\n",
    "   * If you place \"\\\\\\b\" before and after a word, then send it to re.compile(), that tells Python to search for the word wherever it exists as a freestanding word in a string of text, e.g. \" he \" or \"he.\" or \"He \", but not \"her,\" \"heart\", or \"she.\"\n",
    "\n",
    "If you tell the computer to find a \"boundary\" in this way, it will look for both spaces and for the end of strings.\n",
    "\n",
    "#### Search for a regular expression in the bigram list\n",
    "\n",
    "Notice how I use two \"\\\\\\b\"'s below to tell the computer to look for the word \"he\" but not \"her\" or \"the.\" \n",
    "\n",
    "Notice the use of the command **.match()**.  \n",
    "\n",
    "   * .match attaches to 'pattern' -- which is the variable we defined up above as the regular expression for freestanding 'he'. \n",
    "       * 'Pattern' here is just a variable name; it could be called anything.\n",
    "   * .match takes one object: the list where Python is searching for the pattern. \n",
    "       * In the case below, Python is searching for the pattern \"he\" (as a freestanding word) in each \"bigram\" in \"bigramlist.\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he was        126\n",
       "he had        113\n",
       "he is          75\n",
       "he has         49\n",
       "he did         37\n",
       "he could       36\n",
       "he would       28\n",
       "he said        23\n",
       "he should      23\n",
       "he replied     22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in bigramlist:\n",
    "    if pattern.match(bigram): # notice the use of .match()\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(he_bigrams)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our filter is now refined enough to identify unique words, we can try it on the stopworded *cleanbigramlist* data we made above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "he could        36\n",
       "he would        28\n",
       "he said         23\n",
       "he replied      22\n",
       "he might        19\n",
       "he must         18\n",
       "he came         12\n",
       "he looked       11\n",
       "he never         9\n",
       "he really        8\n",
       "he left          8\n",
       "he may           8\n",
       "he stopped       8\n",
       "he added         7\n",
       "he married       7\n",
       "he seemed        6\n",
       "he continued     6\n",
       "he felt          6\n",
       "he told          6\n",
       "he went          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_bigrams = []\n",
    "\n",
    "for bigram in cleanbigramlist:\n",
    "    if pattern.match(bigram): # notice the use of .match()\n",
    "        he_bigrams.append(bigram)\n",
    "        \n",
    "pd.Series.value_counts(he_bigrams)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use regular expressions to search for \"she\" as a freestanding word in the stopworded list *cleanbigramlist*.  \n",
    "  * Paste the he list and she list side by side in a Word Document. \n",
    "    \n",
    "  * Write a paragraph of at least three sentences comparing the two lists\n",
    "    \n",
    "    \n",
    "2) Write a for-loop that looks for bigrams, trigrams, up to nine-grams in Jane Austen, by switching out '_' in the the 'n = _' parameters of the .ngrams() command.\n",
    "    \n",
    "  * Add a line of .value_counts() to the for-loop.  Count how many multi-word phrases there are for each iteration, i.e.: how many 9-word phrases are there, total? how many 8-word phrases? how many 7-word phrases? etc. \n",
    "    \n",
    "  * Adjust the for-loop to save the results of each count in a list.  HINT: You may need to greate a new dummy variable for this count before the for loop.\n",
    "    \n",
    "  * What are the longest phrases that are repeated more than 3 times across Austen's corpus? Paste at least 5 into a table in Word.  \n",
    "  \n",
    "  * Write a paragraph of at least three sentences discussing the phrases.\n",
    "    \n",
    "3) Use stopwording.  What are the longest 3-word phrases in Jane Austen that don't include stopwords? HINT: inside the for loop, create a section to split up your bigrams and test them individually.\n",
    "\n",
    "  * Create a table.  Output the results to Word.  Write a paragraph of at least three sentences discussing the phrases.  \n",
    "      \n",
    " \n",
    "\n",
    "Upload a screenshot of your code and the answer to Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
