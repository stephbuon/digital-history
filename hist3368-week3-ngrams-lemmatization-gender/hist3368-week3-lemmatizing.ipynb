{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week3-ngrams-lemmatization-gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Mini Notebook: Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to introduce you to another cleaning step, called 'stemming' or 'lemmatization.'  Previously, we learned to clean text by lowercasing text, removing punctuation, and removing stopwords. \n",
    "\n",
    "When scholars practice wordcount, they often want to make singulars and plurals the same, so that the following words could be counted the same:\n",
    "\n",
    "    * giraffe\n",
    "    * giraffes\n",
    "    \n",
    "The easy way to fix this prblem is called \"stemming.\" In stemming, we tell the computer to look for common endings -- like 's,' 'ed,' and 'ing' -- and remove them.\n",
    "\n",
    "However, that process won't work for irregular words in English, for instance the following words:\n",
    "\n",
    "    * wolf / wolves\n",
    "    * woman / women\n",
    "\n",
    "Fortunately, linguists have compiled lists of irregular words and their 'root lemma,' which is to say the 'wolf' in 'wolves.'  The process of 'lemmatization' is looking for irregular words and replacing them with their lemmas.  \n",
    "\n",
    "We will use the **worddnet** command from the **nltk** package -- which was designed by linguists -- to lemmatize text correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download some Jane Austen Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install some software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, numpy, re, matplotlib# , num2words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Troubleshooting -- if you have trouble, remember to install all new software according to the following formula (remove the hashtag to run the line:).\n",
    "\n",
    " You only need to run the install command once for each software package and your account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/group/history/hist_3368-jguldi\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/group/history/hist_3368-jguldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download some data\n",
    "\n",
    "with open('senseandsensibility.txt', 'r') as myfile:\n",
    "    sas_data = myfile.read().split('\\n\\n\"I suppose you know, ma\\'am, that Mr. Ferrars is married\"\\n\\nIt _was_ Edward\\n\\n\"Everything in such respectable condition\"\\n\\n ')[1].split('THE END')[0].strip()\n",
    "\n",
    "with open('emma.txt', 'r') as myfile:\n",
    "    emma_data = myfile.read().split('CHAPTER I')[1].split('FINIS')[0].strip()\n",
    "\n",
    "with open('prideandprejudice.txt', 'r') as myfile:\n",
    "    pap_data = myfile.read().split('CHAPTER I')[1].split('End of the Project Gutenberg EBook of Pride and Prejudice, by Jane Austen')[0].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that your data matches what you think it should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *\\n\\n\\n\\n\\nCHAPTER I\\n\\n\\nThe family of Dashwood had long been settled in Sussex. Their estate\\nwas large, and their residence was at Norland Park, in the centre of\\ntheir property, where, for many generations, they had lived in so\\nrespectable a manner as to engage the general good opinion of their\\nsurrounding acquaintance. The late owner of this estate was a single\\nman, who lived to a very advanced age, and who for many years of his\\nlife, had a constant companion and housekeeper in his sister. But her\\ndeath, which happened ten years before his own, produced a great\\nalteration in his home; for to supply her loss, he invited and\\nreceived into his house the family of his nephew Mr. Henry Dashwood,\\nthe legal inheritor of the Norland estate, and the person to whom he\\nintended to bequeath it. In the society of his nephew and niece, and\\ntheir children, the old Gentleman's days were comfortably spent. His\\nattachment to them all increased. The constant attention of Mr. and\\nMrs. Henry Dashwood to his wishes, which proceeded not merely from\\ninterest, but from goodness of heart, gave him every degree of solid\\ncomfort which his age could receive; and the cheerfulness of the\\nchildren added a relish to his existence.\\n\\nBy a former marriage, Mr. Henry Dashwood had one son: by his present\\nlady, three daughters. The son, a steady respectable young man, was\\namply provided for by the fortune of his mother, which had been large,\\nand half of which devolved on him on his coming of age. By his own\\nmarriage, likewise, which happened soon afterwards, he added to his\\nwealth. To him therefore the succession to the Norland estate was not\\nso really important as to his sisters; for their fortune, independent\\nof what might arise to them from their father's inheriting that\\nproperty, could be but small. Their mother had nothing, and their\\nfather only seven thousand pounds in his own disposal; for the\\nremaining moiety of his first wife's fortune was also secured to her\\nchild, an\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing only first 2000 characters.\n",
    "sas_data[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good!\n",
    "\n",
    "Isn't it getting tired, retyping the same command for each novel? Let's throw them all into one list -- which we'll call *data* --  so we can loop through them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [sas_data, emma_data, pap_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we can call the first item in a list with square brackets.  Here is how you will call Sense and Sensibility:\n",
    "\n",
    "    data[0]\n",
    "    \n",
    "If you only want to see the first 2000 characters of Sense and Sensibility, you call it this way:\n",
    "\n",
    "    data[0][:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *\\n\\n\\n\\n\\nCHAPTER I\\n\\n\\nThe family of Dashwood had long been settled in Sussex. Their estate\\nwas large, and their residence was at Norland Park, in the centre of\\ntheir property, where, for many generations, they had lived in so\\nrespectable a manner as to engage the general good opinion of their\\nsurrounding acquaintance. The late owner of this estate was a single\\nman, who lived to a very advanced age, and who for many years of his\\nlife, had a constant companion and housekeeper in his sister. But her\\ndeath, which happened ten years before his own, produced a great\\nalteration in his home; for to supply her loss, he invited and\\nreceived into his house the family of his nephew Mr. Henry Dashwood,\\nthe legal inheritor of the Norland estate, and the person to whom he\\nintended to bequeath it. In the society of his nephew and niece, and\\ntheir children, the old Gentleman's days were comfortably spent. His\\nattachment to them all increased. The constant attention of Mr. and\\nMrs. Henry Dashwood to his wishes, which proceeded not merely from\\ninterest, but from goodness of heart, gave him every degree of solid\\ncomfort which his age could receive; and the cheerfulness of the\\nchildren added a relish to his existence.\\n\\nBy a former marriage, Mr. Henry Dashwood had one son: by his present\\nlady, three daughters. The son, a steady respectable young man, was\\namply provided for by the fortune of his mother, which had been large,\\nand half of which devolved on him on his coming of age. By his own\\nmarriage, likewise, which happened soon afterwards, he added to his\\nwealth. To him therefore the succession to the Norland estate was not\\nso really important as to his sisters; for their fortune, independent\\nof what might arise to them from their father's inheriting that\\nproperty, could be but small. Their mother had nothing, and their\\nfather only seven thousand pounds in his own disposal; for the\\nremaining moiety of his first wife's fortune was also secured to her\\nchild, an\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still appear to be some errors where spaces have been replaced by \"\\n\".  \n",
    "\n",
    "The characters '\\n' are a 'regular expression', or computer speak for 'white space goes here.'  You'll also see literal '\\n''s in the text above -- an artifact of how the text was formatted. \n",
    "\n",
    "Let's get rid of those next, using *.replace*. We'll replace them with a normal space, or ' '."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"*       *       *       *       *     CHAPTER I   The family of Dashwood had long been settled in Sussex. Their estate was large, and their residence was at Norland Park, in the centre of their property, where, for many generations, they had lived in so respectable a manner as to engage the general good opinion of their surrounding acquaintance. The late owner of this estate was a single man, who lived to a very advanced age, and who for many years of his life, had a constant companion and housekeeper in his sister. But her death, which happened ten years before his own, produced a great alteration in his home; for to supply her loss, he invited and received into his house the family of his nephew Mr. Henry Dashwood, the legal inheritor of the Norland estate, and the person to whom he intended to bequeath it. In the society of his nephew and niece, and their children, the old Gentleman's days were comfortably spent. His attachment to them all increased. The constant attention of Mr. and Mrs. Henry Dashwood to his wishes, which proceeded not merely from interest, but from goodness of heart, gave him every degree of solid comfort which his age could receive; and the cheerfulness of the children added a relish to his existence.  By a former marriage, Mr. Henry Dashwood had one son: by his present lady, three daughters. The son, a steady respectable young man, was amply provided for by the fortune of his mother, which had been large, and half of which devolved on him on his coming of age. By his own marriage, likewise, which happened soon afterwards, he added to his wealth. To him therefore the succession to the Norland estate was not so really important as to his sisters; for their fortune, independent of what might arise to them from their father's inheriting that property, could be but small. Their mother had nothing, and their father only seven thousand pounds in his own disposal; for the remaining moiety of his first wife's fortune was also secured to her child, an\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace('\\n', ' ') \n",
    "data[0][:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect each individual novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*       *       *       *       *     CHAPTER I   The family of Dashwood had long been settled in Sussex. Their estate was large, and their residence was at Norland Park, in the centre of their proper\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to unite some of the best blessings of existence; and had lived nearly twenty-one years in the world w\n",
      "\n",
      ".   It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.  However little known the feelings or views of such a man may be on his first\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for novel in data:\n",
    "    \n",
    "    print(novel[:200].strip()) # the .strip() command removes whitespace that might prevent this from displaying properly\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Novels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's lowercase the text and get rid of punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase and strip punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # data[i] is the current novel\n",
    "    data[i] = data[i].lower() # force to lowercase\n",
    "    data[i] = re.sub('[\\\",.;:?([)\\]_*]', '', data[i]) # remove punctuation and special characters with regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's split the text of each novel into individual words using *.split().\n",
    "\n",
    "Then we will filter out the stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter out stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " 'family',\n",
       " 'dashwood',\n",
       " 'long',\n",
       " 'settled',\n",
       " 'sussex',\n",
       " 'estate',\n",
       " 'large',\n",
       " 'residence',\n",
       " 'norland',\n",
       " 'park',\n",
       " 'centre',\n",
       " 'property',\n",
       " 'many',\n",
       " 'generations',\n",
       " 'lived',\n",
       " 'respectable',\n",
       " 'manner',\n",
       " 'engage',\n",
       " 'general']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "cleandata = [] # create an empty list of clean novels\n",
    "\n",
    "for novel in data:\n",
    "    cleanwords = [] # create a dummy list of cleanwords\n",
    "    words = novel.split() # split the words of the original novel up into a list of individual words.\n",
    "    for word in words:\n",
    "        if word not in stopwords:\n",
    "            cleanwords.append(word)\n",
    "    cleandata.append(cleanwords)\n",
    "\n",
    "cleandata[0][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is another cleaning process. It makes it possible to count as similar words that have the same root, for example, \"manner\" and \"manners.\"\n",
    "\n",
    "Stemming refers to the computational process of normalizing singular and plural, past and present tense by removing the most common suffices in English, for instance \"ed\" or \"ing\".\n",
    "\n",
    "We will use a standard **NLTK** package function, **PorterStemmer()**, to do the stemming. \n",
    "\n",
    "**PorterStemmer.stem()** takes one object, the word that needs to be stemmed.  \n",
    "\n",
    "Note that below we are nicknaming PorterStemmer \"st\" for short. So the command will be **st.stem()** with the word to be stemmed as the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'long'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('longs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daughter'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('daughters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try applying stemming to *cleandata* with a for loop and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " 'famili',\n",
       " 'dashwood',\n",
       " 'long',\n",
       " 'settl',\n",
       " 'sussex',\n",
       " 'estat',\n",
       " 'larg',\n",
       " 'resid',\n",
       " 'norland',\n",
       " 'park',\n",
       " 'centr',\n",
       " 'properti',\n",
       " 'mani',\n",
       " 'gener',\n",
       " 'live',\n",
       " 'respect',\n",
       " 'manner',\n",
       " 'engag',\n",
       " 'gener']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_list = [] # create an empty list that we will fill in with stemmed words\n",
    "\n",
    "for novel in cleandata: # move through each novel in the list *cleandata*\n",
    "    for word in novel: # move through each word in the novel\n",
    "        stemmed = st.stem(word) # stem that word\n",
    "        stemmed_list.append(stemmed) # save the stemmed word to the new list, stemmed_list\n",
    "        \n",
    "stemmed_list[:20] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, with stemming:\n",
    "\n",
    "   * \"settled\" becomes \"settl,\" which means that \"settling\" and \"settler\" will be counted together.\n",
    "   * \"residence\" becomes \"resid,\" which means it will be counted with \"resident\" and \"residing.\"\n",
    "\n",
    "Those counts will work well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What's not so great about Stemming?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is a quick-and-dirty method. But it gives us strange results that we might not want to publish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'women'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'famili'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.stem('families')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But there are some questionable adjustments that we might disagree with.\n",
    "\n",
    "   * \"was\" has become \"wa.\" this won't help us to count \"was\" with \"is\" or \"to be,\" which are other forms of the same verb.\n",
    "   * \"large\" becomes \"larg\" (which means that \"large\" will be counted with \"largely\" and potentially \"largo,\" which would be innacurate)\n",
    "   * \"families\" becomes \"famili,\" which means it wouldn't be counted accurately as the same word as \"family.\"\n",
    "   \n",
    "\n",
    "Stemming, therefore, isn't what we want to use for cleaning text. It would give us inaccurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's turn towards a more robust process.  In 'lemmatization,' the computer has been given a list of irregular words. It looks for them, and reduces every word to its \"lemma,\" or root.\n",
    "\n",
    "This process is extremely memory intensive, but the results are far more accurate.  \n",
    "\n",
    "We will be using lemmatization, not stemming, to clean texts in this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install the wordnet command from the nltk.corpus package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-35-e00bed121b72>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-e00bed121b72>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    nltk.download(‘wordnet’)\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download(‘wordnet’) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command for \"lemmatize\" is **wn.morphy().** \n",
    "\n",
    "The .morphy() command takes one object: the word that needs to be lemmatized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.morphy('families')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn.morphy('women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wn.morphy('aardwolves')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a loop to lemmatize every word in Jane Austen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_list = []\n",
    "\n",
    "for novel in cleandata:\n",
    "    for word in novel:\n",
    "        lemma = wn.morphy(word)\n",
    "        if not lemma:\n",
    "            # word is not a valid english word so skip it\n",
    "            continue\n",
    "        lemma_list.append(lemma)\n",
    "\n",
    "lemma_list[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is often a more useful approach than stemming because it leverages an understanding of the word itself to convert the word back to its root word. \n",
    "\n",
    "Lemmatizing fixes some of the problems we saw with stemming:\n",
    "\n",
    "   * \"settled\" becomes \"settle\"\n",
    "   * \"been\" has become \"be\"\n",
    "   * \"large\" is \"large\"\n",
    "\n",
    "This is an improvement over stemming in many respects.\n",
    "\n",
    "**However**\n",
    "\n",
    "We still need to note some important oddities, which we should be aware of before we publish an interpretation based on lemmatization:\n",
    "\n",
    "   * Words such as \"was\" is still replaced by \"wa,\" which is an issue if we care about the word \"to be.\"  \n",
    "   * We would also see, if we looked further, that the word \"that\" has been replaced by \"None\"\n",
    "\n",
    "In fact, there are ways that we can improve this process and correct these errors -- as we shall see in a few weeks when we use the full repertoire of tools to detect the grammatical significance of each word in context.  \n",
    "\n",
    "For now, quick lemmatization gets us better results than stemming.  It produces a few errors that we would not want to publish. \n",
    "\n",
    "### The Analyst's Role\n",
    "\n",
    "The analyst's role is to understand the strengths and weaknesses of every approach they use in text mining.\n",
    "\n",
    "If we use the technique above to find lemmas, we should be aware of these potential difficulties so that we can eliminate any noise generated by oddities.  \n",
    "\n",
    "For instance, you would not want to publish a graph showing \"wa\" or \"None.\"  Those are merely data errors.  Nor would you want to write about them in a paragraph.\n",
    "\n",
    "Occasionally, the assignments for these notebooks will ask you to think about why one approach is better than another. \n",
    "\n",
    "The purpose of thinking about how we clean is to produce better results -- word counts that don't have data-generated errors, graphs that don't have results that you can't explain, and interpretive paragraphs that make sense.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting with stemming and lemmatization\n",
    "\n",
    "Understanding the difference between stemming and lemmatization is important because the choice of technique affects the result of counting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the counts generated by working with *stemmed_list* and *lemma_list*, the two lists of cleaned words that we generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stemmed_count = pd.Series.value_counts(stemmed_list)\n",
    "stemmed_count[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_count = pd.Series.value_counts(lemma_list)\n",
    "lemma_count[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summing up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's all the code we learned in the notebook today, applied to the novel _Sense and Sensibility_.\n",
    "\n",
    "You should be able to understand what each line of code does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk, numpy, re, matplotlib# , num2words\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('wordnet') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Here are the top lemmatized words\n",
      "say       550\n",
      "mrs       531\n",
      "every     373\n",
      "know      364\n",
      "one       318\n",
      "much      286\n",
      "make      282\n",
      "must      282\n",
      "sister    259\n",
      "time      238\n",
      "dtype: int64\n",
      "\n",
      "### Here are the top word stems\n",
      "mr         710\n",
      "elinor     614\n",
      "could      575\n",
      "would      512\n",
      "mariann    486\n",
      "said       380\n",
      "everi      373\n",
      "one        318\n",
      "much       286\n",
      "must       282\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# choose just one novel from the data\n",
    "novel = data[0] \n",
    "\n",
    "# remove whitespace, lowercase, and \n",
    "novel.replace('\\n', ' ') # remove whitespace\n",
    "novel = novel.lower() # force to lowercase\n",
    "novel = re.sub('[\\\",.;:?([)\\]_*]', '', novel) # remove punctuation and special characters with regular expression\n",
    "\n",
    "# split the novel into words, lemmatize each word, and remove stopwords\n",
    "lemmas = [] # create a dummy list of lemmas\n",
    "stems = [] # create a dummy list of stems\n",
    "words = novel.split() # split the words of the original novel up into a list of individual words.\n",
    "for word in words:\n",
    "        if word not in stopwords: # filter out stopwords\n",
    "            lemma = wn.morphy(word) # lemmatize each non-stopword\n",
    "            stem = st.stem(word) # stem that word\n",
    "            lemmas.append(lemma) # save the lemma for use later\n",
    "            stems.append(stem) # save the stem for use later\n",
    "\n",
    "# analyze your work\n",
    "print(\"### Here are the top lemmatized words\")\n",
    "print(pd.Series.value_counts(lemmas)[:10]) # count all the clean results & show only the top results\n",
    "print(\"\")\n",
    "\n",
    "print(\"### Here are the top word stems\")\n",
    "print(pd.Series.value_counts(stems)[:10]) # count all the clean results & show only the top results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) For lemma_count and stemmed_count, expand the number of words you're looking at to 200 instead of 20.  Hint: you might have to use a for loop with 'print' to get the computer to display so many results.\n",
    "\n",
    "   * What differences do you notice between the two methods of shortening words? \n",
    "   * What oddities should we be aware of that might affect the outcome of a wordcount analysis?\n",
    "\n",
    "2) Lemmatize the text of Benjamin Bowsey's trial from last week.  \n",
    "\n",
    "   * Generate list of top lemmatized words from the Bowsey trial.\n",
    "   * Inspect the list of lemmas.  Remove any oddities or data errors from the lemma list before you visualize it.\n",
    "   * Create a new word cloud with the clean lemmas.  Save it.\n",
    "   * Compare the new word cloud with last week's wordcloud.  Tell us about 5 differences between the two charts.\n",
    "\n",
    "3) Make three bar plots, one for each of the three Austen novels. \n",
    "\n",
    "   * Show the top twenty lemmas, stopworded and stripped of punctuation, from each novel. \n",
    "   * Entitle and label your bar plots appropiately. Label them with names (figure 1, etc.)\n",
    "   * Write a paragraph of at least three sentences about what you observe to be the differences and similarities between the novels based on word count of top lemmas. Reference the figures by name in your paragraph.  \n",
    "\n",
    "Put your answers and the two wordclouds into a word document and upload it to Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
