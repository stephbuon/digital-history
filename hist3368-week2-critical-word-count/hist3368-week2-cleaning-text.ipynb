{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For citation information, please see the \"Source Information\" section listed in the associated README file: https://github.com/stephbuon/digital-history/tree/master/hist3368-week1-intro-to-jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hist 3368 - Week 2 - Cleaning Text\n",
    "\n",
    "* lightly amended from Alison Parrish, Lauren Klein, and the Programming Historian William J. Turkel and Adam Crymble, \"Counting Word Frequencies with Python,\" The Programming Historian 1 (2012), https://doi.org/10.46430/phen0003.*\n",
    "\n",
    "Very often, when working with text, we'll want to \"clean\" up the results of how the computer first reads them.  What does this mean?  When a computer reads human texts, the following situations frequently occur:\n",
    "\n",
    "    * The computer thinks that a piece of punctuation like a comma or semicolon is literally part of the word.\n",
    "    * The computer wants to count singular words (like 'tree') as a different word from the same word in the plural ('trees)\n",
    "    \n",
    "We might add one further difficulty:\n",
    "\n",
    "    * The computer's counts of important words, by default, are meaningless. In almost every human text, the most frequently appearing words are \"the,\" \"and,\" \"of,\" and \"in.\" If asked to count the most frequent words, a human might simply choose to ignore those words.\n",
    "\n",
    "Thus the computer, by default, counts words quite differently from the way you or I might, if instructed to count words.\n",
    "\n",
    "To teach the computer how to count words usefully, we need to \"clean\" the text:\n",
    "\n",
    "    * We will remove punctuation. This is called \"stripping punctuation\"\n",
    "    * We will create a list of \"stopwords,\" generated from either a default list or from counting the most frequent words in a list.  \n",
    "    \n",
    "There is also one more major cleaning step that we will teach later, next week:\n",
    "\n",
    "    * We will normalize plural words (\"trees\") and past-tense words (\"yielded\") by removing the suffixes \"s\" and \"ed\". This is known as \"stemming\" or \"lemmatizing\" depending on the technique.\n",
    "\n",
    "In this lesson, we will examine basic strategies for cleaning text that will be a part of our work for the rest of the semester.\n",
    "\n",
    "Throughout the semester, you will return to these cleaning functions again and again. Why? Because no default cleaning cocktail works all the time. Counting words, you may frequently find that some stray piece of punctuation escaped your cleaning, or that the most frequent words counted are meaningless for your analysis.  \n",
    "\n",
    "Again and again, you will need to choose new stop words. You will clean new punctuation marks.  You will adjust the text. Learning the basic commands for cleaning text will be useful to you for the rest of the semester and indeed whenever you choose to text mine in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Learn About Cleaning with Sample Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's generate a sample text.  We'll use two functions we learned about previously -- .split() and pd.Series.value_counts -- to generate a raw word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampletext = \"Once upon a time, in a kingdom far, far away, there lived a young woman.  In other times, there had been other women, but this young woman was special.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplewords = sampletext.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a           3\n",
       "young       2\n",
       "other       2\n",
       "there       2\n",
       "times,      1\n",
       "far         1\n",
       "away,       1\n",
       "kingdom     1\n",
       "far,        1\n",
       "special.    1\n",
       "been        1\n",
       "time,       1\n",
       "woman.      1\n",
       "lived       1\n",
       "women,      1\n",
       "woman       1\n",
       "in          1\n",
       "Once        1\n",
       "this        1\n",
       "In          1\n",
       "was         1\n",
       "had         1\n",
       "upon        1\n",
       "but         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "samplecount = pd.Series.value_counts(samplewords)\n",
    "samplecount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there are some properties of this word count that wouldn't correspond to how a human would have counted the words. \n",
    "\n",
    "    * \"Far\" and \"far,\" are counted as separate words\n",
    "    * \"woman.\", \"women,\" and \"woman\" are counted as separate words.\n",
    "    * \"In\" (with a capital I) and \"in\" (lowercase) are counted separately.\n",
    "    \n",
    "Let's explore some commands that will tell Python to count these words in a more intuitive way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first command to teach Python to treat text more intuitively is called \"lowercasing.\"  Lowercasing normalized capitals and lowercase letters.\n",
    "\n",
    "In Python, we execute lowercasing with the function *.lower().\n",
    "\n",
    "We will apply .lower() to the original text, sampletext. \n",
    "\n",
    "Then we will use .split() and .value_counts() as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a           3\n",
       "young       2\n",
       "other       2\n",
       "in          2\n",
       "there       2\n",
       "times,      1\n",
       "far         1\n",
       "away,       1\n",
       "kingdom     1\n",
       "once        1\n",
       "been        1\n",
       "time,       1\n",
       "woman.      1\n",
       "far,        1\n",
       "lived       1\n",
       "women,      1\n",
       "was         1\n",
       "this        1\n",
       "woman       1\n",
       "special.    1\n",
       "had         1\n",
       "upon        1\n",
       "but         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampletextlowered = sampletext.lower()\n",
    "samplewordslowered = sampletextlowered.split()\n",
    "samplecountlowered = pd.Series.value_counts(samplewordslowered)\n",
    "samplecountlowered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the count of \"in\" is now 2 instead of 1.  Notice that there are no longer capitalized words in the count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stripping punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the function .strip() to remove certain characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pull a list of punctuation from the cloud by importing the \"string\" package and inspecting the object string.punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the command .replace() to work on removing punctuation.  \n",
    "\n",
    "   * Replace only works on one item of punctuation at a time, so we need a \"for\" loop to cycle through each punctuation mark in string.punctuation\n",
    "   * Replace takes two arguments: first, the string to find; second, what to replace it with.  \n",
    "        * We will replace any given punctuation item with an empty string: \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once upon a time in a kingdom far far away there lived a young woman  in other times there had been other women but this young woman was special\n"
     ]
    }
   ],
   "source": [
    "nopunctuationtext = sampletextlowered\n",
    "for c in string.punctuation:\n",
    "    nopunctuationtext = nopunctuationtext.replace(c, \"\")\n",
    "    \n",
    "print(nopunctuationtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Great! Now we .split() and .value_counts() as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a          3\n",
       "other      2\n",
       "far        2\n",
       "woman      2\n",
       "in         2\n",
       "young      2\n",
       "there      2\n",
       "kingdom    1\n",
       "once       1\n",
       "time       1\n",
       "been       1\n",
       "this       1\n",
       "times      1\n",
       "lived      1\n",
       "was        1\n",
       "away       1\n",
       "special    1\n",
       "women      1\n",
       "had        1\n",
       "upon       1\n",
       "but        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nopunctuationwords = nopunctuationtext.split()\n",
    "nopunctuationcounts = pd.Series.value_counts(nopunctuationwords)\n",
    "nopunctuationcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"far,\" (with a comma) and \"far\" (without a comma) are now counted together.  There are two of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very frequently, human analysts don't care about *absolute* most frequent words in a text.  That is because, statistically, those most frequent words are also boring: words such as \"the\", \"an,\" and \"in.\"\n",
    "\n",
    "Coders who work with text frequently often compile generic stopwords lists for the English language.  We can reach into the cloud and download one from the software package \"nltk\" with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can always expand this list, depending on what we're studying in a text, by using .append() to add new words to this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['won', \"won't\", 'wouldn', \"wouldn't\", 'boringword']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords2 = stopwords.words('english')\n",
    "stopwords2.append(\"boringword\")\n",
    "\n",
    "stopwords2[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a for loop to cycle through the words in nopunctuationwords and keep only the ones that aren't stopwords.\n",
    "\n",
    "   * First, we create an empty list using square brackets. We're calling it *goodwords*.  Right now there's nothing in the list, but we'll be adding to it, one good word at a time.\n",
    "   \n",
    "            goodwords = []\n",
    "            \n",
    "       \n",
    "   * Next, we write a for loop to cycle through each item in the Series nopunctuationwords:\n",
    "   \n",
    "           for word in nopunctuationwords:\n",
    "           \n",
    "       \n",
    "   * Next, we write a conditional statement using \"if\", \"in\", and \"not\" to test the condition of whether each word is in the stopwordslist\n",
    "   \n",
    "           if word not in stopwords2:\n",
    "           \n",
    "           \n",
    "   * We add the words that meet the condition in the \"if\" statement by appending those words to our new list, *goodwords*\n",
    "   \n",
    "           goodwords.append(word)\n",
    "           \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upon',\n",
       " 'time',\n",
       " 'kingdom',\n",
       " 'far',\n",
       " 'far',\n",
       " 'away',\n",
       " 'lived',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'times',\n",
       " 'women',\n",
       " 'young',\n",
       " 'woman',\n",
       " 'special']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodwords = []\n",
    "\n",
    "for word in nopunctuationwords:\n",
    "    if word not in stopwords2:\n",
    "        goodwords.append(word)\n",
    "\n",
    "goodwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now count these words as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "far        2\n",
       "young      2\n",
       "woman      2\n",
       "special    1\n",
       "lived      1\n",
       "kingdom    1\n",
       "upon       1\n",
       "women      1\n",
       "time       1\n",
       "times      1\n",
       "away       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodwordcounts = pd.Series.value_counts(goodwords)\n",
    "goodwordcounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this list of counted words is *juicier* than the lists before.  It counts only the words that would be used to tell a story -- \"young,\" \"woman,\" \"special,\" \"kingdom,\" etc.  These words give the flavor of the two sentences above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's count with some real text from the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we are loading text from the internet.  Don't worry about the commands below; we will give you the code to load many texts from the internet in this class. \n",
    "\n",
    "Let's load some text and use square brackets -- [:2000] -- to look at the first 2000 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "browse - central criminal court\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "jump to contentjump to main navigationjump to section navigation\n",
      "\n",
      "\n",
      "the proceedings of the old bailey\n",
      "london's central criminal court, 1674 to 1913\n",
      "\n",
      "\n",
      "main navigationhomesearchabout the proceedingshistorical backgrounddatathe projectcontact\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " benjamin bowsey. breaking peace: riot. 28th june 1780reference numbert17800628-33verdictguiltysentencedeathrelated material associated recordsactionscite this textold bailey proceedings online (www.oldbaileyonline.org, version 8.0, 30 august 2021), june 1780, trial of                      benjamin                      bowsey                                                                               (t17800628-33).close | print-friendly version | report an errornavigation< previous text (trial account) | next text (trial account) >see original 324.                                                        benjamin                      bowsey                                                                                                          (a blackmoor                  ) was indicted for                                                          that he together with five hundred other persons and more, did, unlawfully, riotously, and tumultuously assemble on the 6th of june                      to the disturbance of the public peace and did begin to demolish and pull down the dwelling house of                                                                          richard                            akerman                                                                                                                                                            , against the form of the statute, &c.                                                rose                   jennings                                                                                       , esq. sworn. had you any occasion to be in this part of the town, on the 6th of june in the evening? - i dined with m\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.error, urllib.parse, bs4 as bs\n",
    "source = urllib.request.urlopen('http://www.oldbaileyonline.org/browse.jsp?id=t17800628-33&div=t17800628-33')\n",
    "soup = bs.BeautifulSoup(source, 'lxml')\n",
    "text = soup.get_text()\n",
    "print(text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Remove Custom Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you read the sample text we scraped from the internet, you'll see that there's an eighteenth-century court case. But there's also a lot of gobbledegook from the Internet -- URL's, section headers, etc.  We don't want to count these or read them.\n",
    "\n",
    "Fortunately, we can use the same procedure as we did for stripping punctuation and stopwording to get rid of the gobbledegook.  \n",
    "\n",
    "We'll begin by creating a custom stopwords list called \"extrawords.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can define a set of words that seem to come from the webpage that we don't want to use\n",
    "extrawords = [\"[]\", \"_gaq.push(['_setaccount'\", \"browse\", \"-\", \"central\", \"criminal\", \"court\", \"var\", \"_gaq\", \"=\", \"_gaq\", \"||\", \"[];\", \n",
    "              \"_gaq.push([\", \"_setaccount\", \"ua-19174022-1]\", \"_gaq.push([\", \"\\\"_gaq.push(['_setaccount'\\\"\",\n",
    "              \"_trackpageview\",\"(function()\", \"{\", \"var\", \"ga\", \"=\", \"document.createelement\",\n",
    "              \"'ua-19174022-1'\", \"_gaq.push(['_trackpageview'\",\n",
    "              \"script\", \"ga.type\", \"=\", \"text/javascript\", \"ga.async\", \"=\", \"true;\", \"ga.src\", \"=\", \"https:\",\n",
    "              \"==\", \"document.location.protocol\", \"?\", \"https://ssl\", \":\", \"http://www\", \"+\", \n",
    "              \".google-analytics.com/ga.js\", \"var\", \"s\", \"=\", \"document.getelementsbytagname\",\n",
    "              \"s.parentnode.insertbefore(ga\", \"s\", \"})();\", \"jump\", \"to\", \"contentjump\", \"to\", \"main\",\n",
    "              \"navigationjump\", \"section\", \"navigation\",  \"proceedings\", \n",
    "              '(www.oldbaileyonline.org', '8.0', '2020)', '1780',\n",
    "              \"'ua-19174022-1'])\", \"_gaq.push(['_trackpageview'])\", \"document.createelement('script')\", \n",
    "              \"'text/javascript'\", 'true', \"('https:'\", \"'https://ssl'\", '', \"'http://www')\",\n",
    "              \"'.google-analytics.com/ga.js'\", \"document.getelementsbytagname('script')[0]\", 's)', '})()',\n",
    "              \"bailey\",  \"1674\", \"to\", \"1913\", \"main\", \"navigationhomesearchabout\",\n",
    "              \"proceedingshistorical\", \"backgrounddatathe\", \"projectcontact\", \"benjamin\", \"bowsey\", \n",
    "              \"breaking\", \"peace:\", \"riot.\", \"28th\", \"june\", \"1780reference\", \n",
    "              \"numbert17800628-33verdictguiltysentencedeathrelated\", \"material\", \"associated\", \n",
    "              \"recordsactionscite\", \"this\", \"textold\", \"bailey\", \"proceedings\", \"online\", \n",
    "              '1674-1834', 'api', 'demonstrator', '<!--', 'google_ad_client', 'pub-6166712890256554', \n",
    "              '/*', '180x150', 'created', '21/11/08', '*/', 'google_ad_slot', '3829571269', 'google_ad_width',\n",
    "              '180', 'google_ad_height', '150', '//-->', '<!--', 'google_ad_client', 'pub-6166712890256554', '/*',\n",
    "              '180x150', 'created', '21/11/08', '*/', 'google_ad_slot', '1983343858', 'google_ad_width', '180', \n",
    "              'google_ad_height', '150', '//-->', '<!--', 'google_ad_client', 'pub-6166712890256554', '/*', \n",
    "              '180x150', 'created', '21/11/08', '*/', 'google_ad_slot', '9176171409', 'google_ad_width', '180', \n",
    "              'google_ad_height', '150', '//-->', 'footer', 'march', '2018', '©', '2003-2018',  \n",
    "              'www.oldbaileyonline.org', '2020', 't17800628-33).close', \"'324'\",\n",
    "              \"_gaq.push(['_setaccount\", \"_gaq.push(['_trackpageview\", \"document.createelement('script\", \"document.getelementsbytagname('script')[0\",\n",
    "              \"_gaq.push(['_setaccount',\", \"ua-19174022-1']);\", \"_gaq.push(['_trackpageview']);\", \n",
    "              \"document.createelement('script');\", \"text/javascript';\", \"('https:\", \"http://www')\", \n",
    "              \".google-analytics.com/ga.js';\", \"document.getelementsbytagname('script')[0];\", 's.parentnode.insertbefore(ga,', 's);',\n",
    "               'web', 'site', 'sitemap', 'copyright', '&', 'citation', 'guide', 'visual', 'design', 'technical',\n",
    "              'design', 'xml', 'feedback', 'ua-19174022-1', \"'www.oldbaileyonline.org'\", \"'2020'\", \"'t17800628-33).close'\", \n",
    "              \"'ua-19174022-1']\", \"_gaq.push(['_trackpageview']\", 'function', \"document.createelement('script'\", \"'https:'\", \"'http://www'\", '}', \n",
    "              \"(www.oldbaileyonline.org,\", \"version\", \"8.0,\", \"08\", \"september\", \"2020),\", \"june\", \"1780,\", \n",
    "              '\"pub-6166712890256554\";', '180x150,', '\"3829571269\";', '180;', '150;', '\"pub-6166712890256554\";', '180x150,', \n",
    "              '\"1983343858\";', '180;', '150;', '\"pub-6166712890256554\";', '180x150,', '\"9176171409\";', '180;', '150;',\n",
    "              \"trial\", \"of\", \"benjamin\", \"bowsey\", \"(t17800628-33).close\", \"|\", \"print-friendly\", \"version\", \n",
    "              \"|\", \"report\", \"errornavigation<\", \"previous\", \"text\", \"(trial\", \"account)\", \"|\", \"next\", \"recordsactionscite\", \n",
    "              \"text\", \"(trial\", \"account)\", \">see\", \"original\", \"324.\", \"navigationjump\", \"contentjump\", \"browse\", \"navigationhomesearchabout\",\n",
    "             \"proceedingshistorical\", \"1780reference\", \"navigationjump\", \"navigationhomesearchabout\", \"navigationhomesearchabout\", \"proceedingshistorical\", \"backgrounddatathe\", \"projectcontact\",\n",
    "              \"backgrounddatathe\", \"(trial\", \"account)\", \"projectcontact\", \"(t17800628-33).close\", \"(www.oldbaileyonline.org,\", \"numbert17800628-33verdictguiltysentencedeathrelated\",\n",
    "             ]\n",
    "#print(extrawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "browse - central criminal court jump to contentjump to main navigationjump to section navigation the proceedings of the old bailey london's central criminal court, 1674 to 1913 main navigationhomesearchabout the proceedingshistorical backgrounddatathe projectcontact benjamin bowsey. breaking peace: riot. 28th june 1780reference material associated recordsactionscite this textold bailey proceedings online (www.oldbaileyonline.org, version 8.0, 30 august 2021), june 1780, trial of benjamin bowsey (t17800628-33).close | print-friendly version | report an errornavigation< previous text (trial account) | next text (trial account) >see original 324. benjamin bowsey (a blackmoor ) was indicted for that he together with five hundred other persons and more, did, unlawfully, riotously, and tumultuously assemble on the 6th of june to the disturbance of the public peace and did begin to demolish and pull down the dwelling house of richard akerman , against the form of the statute, &c. rose jennings , esq. sworn. had you any occasion to be in this part of the town, on the 6th of june in the evening? - i dined with my brother who lives opposite mr. akerman's house. they attacked mr. akerman's house precisely at seven o'clock; they were preceded by a man better dressed than the rest, who went up to mr. akerman's door; he rapped three times, and i believe pulled the bell as often. mr. akerman had barrocadoed his house. when the man found that no one came, he went down the steps, made his obeisance to the mob, and pointed to the door, and then retired. have you any recollection how that man who you say had a better appearance than the rest was dressed? - i think he had on a dark brown coat and a round ha, but i cannot be particular as to that; the mob immediately following in that formidable manner made such an impression upon me, that i did not take notice. the mob approached about thirty in number, three a-breast, some with paving mattocks, others with iron crows and chissels; and\n"
     ]
    }
   ],
   "source": [
    "# we can get rid of the extrawords using a loop\n",
    "\n",
    "for e in extrawords:\n",
    "    cleaned = text.replace(e, \"\")\n",
    "\n",
    "cleaned =  ' '.join(cleaned.split()) # this command -- which we didn't touch on -- removes extra whitespace.\n",
    "\n",
    "print(cleaned[:2000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning, the text looks much better, doesn't it?  \n",
    "\n",
    "   * There are still a smattering of misplaced matter the beginning of the passage, left over from the webpage heading. \n",
    "   * But by and large, you can just read the text like a transcript of the trial at this point, word for word. \n",
    "   * Later this week we'll ask you to do just that.  Bear in mind that you can read the whole thing right now with the command 'print(cleaned)' (without the square brackets limiting the viewing box to the first 2000 characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase, remove punctuation, and stopword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use the tools we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'browse  central criminal court jump to contentjump to main navigationjump to section navigation the proceedings of the old bailey londons central criminal court 1674 to 1913 main navigationhomesearchabout the proceedingshistorical backgrounddatathe projectcontact benjamin bowsey breaking peace riot 28th june 1780reference material associated recordsactionscite this textold bailey proceedings online wwwoldbaileyonlineorg version 80 30 august 2021 june 1780 trial of benjamin bowsey t1780062833close  printfriendly version  report an errornavigation previous text trial account  next text trial account see original 324 benjamin bowsey a blackmoor  was indicted for that he together with five hundred other persons and more did unlawfully riotously and tumultuously assemble on the 6th of june to the disturbance of the public peace and did begin to demolish and pull down the dwelling house of richard akerman  against the form of the statute c rose jennings  esq sworn had you any occasion to be in this part of the town on the 6th of june in the evening  i dined with my brother who lives opposite mr akermans house they attacked mr akermans house precisely at seven oclock they were preceded by a man better dressed than the rest who went up to mr akermans door he rapped three times and i believe pulled the bell as often mr akerman had barrocadoed his house when the man found that no one came he went down the steps made his obeisance to the mob and pointed to the door and then retired have you any recollection how that man who you say had a better appearance than the rest was dressed  i think he had on a dark brown coat and a round ha but i cannot be particular as to that the mob immediately following in that formidable manner made such an impression upon me that i did not take notice the mob approached about thirty in number three abreast some with paving mattocks others with iron crows and chissels and then followed an innumerable company with bludgeons they seemed to be the sp'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove punctuation\n",
    "for c in string.punctuation:\n",
    "    cleaned = cleaned.replace(c, \"\")\n",
    "\n",
    "cleaned[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['browse',\n",
       " 'central',\n",
       " 'criminal',\n",
       " 'court',\n",
       " 'jump',\n",
       " 'to',\n",
       " 'contentjump',\n",
       " 'to',\n",
       " 'main',\n",
       " 'navigationjump',\n",
       " 'to',\n",
       " 'section',\n",
       " 'navigation',\n",
       " 'the',\n",
       " 'proceedings',\n",
       " 'of',\n",
       " 'the',\n",
       " 'old',\n",
       " 'bailey',\n",
       " 'londons']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase and split into words\n",
    "cleanlowercasewords = cleaned.lower().split()\n",
    "cleanlowercasewords[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['browse',\n",
       " 'central',\n",
       " 'criminal',\n",
       " 'court',\n",
       " 'jump',\n",
       " 'contentjump',\n",
       " 'main',\n",
       " 'navigationjump',\n",
       " 'section',\n",
       " 'navigation',\n",
       " 'proceedings',\n",
       " 'old',\n",
       " 'bailey',\n",
       " 'londons',\n",
       " 'central',\n",
       " 'criminal',\n",
       " 'court',\n",
       " '1674',\n",
       " '1913',\n",
       " 'main']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the standard stopwords list\n",
    "stopworded = []\n",
    "\n",
    "for word in cleanlowercasewords:\n",
    "    if word not in stopwords2:\n",
    "        stopworded.append(word)\n",
    "\n",
    "stopworded[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house       23\n",
       "yes         20\n",
       "mr          19\n",
       "prisoner    18\n",
       "man         16\n",
       "mob         14\n",
       "black       13\n",
       "night       12\n",
       "saw         11\n",
       "see         10\n",
       "akermans    10\n",
       "know         9\n",
       "fire         9\n",
       "june         9\n",
       "face         9\n",
       "sworn        9\n",
       "went         9\n",
       "believe      8\n",
       "thing        8\n",
       "room         8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted = pd.Series.value_counts(stopworded)\n",
    "counted[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General advice about cleaning\n",
    "\n",
    "It's important to check the text as you work. At many times throughout the course of a text-mining project,  good practice requires \"inspecting\" the data set to see how well a particular operation worked.  In this case, we're checking our work cleaning.\n",
    "\n",
    "Do we like the resulting list of top words? \n",
    "\n",
    "   * To my eye, many of the resulting words are boring.  They just look like regular features of eighteenth-century trials.  I think I'd get more out of this list if I removed \"yes\" and \"mr\" from the list.\n",
    "   \n",
    "Part of doing a good job cleaning is asking yourself if you like the results, and trying again if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding a stopwords list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add two more words to our stopwords list and run the count again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords3 = stopwords2\n",
    "stopwords3.append(\"mr\")\n",
    "stopwords3.append(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "house       23\n",
       "prisoner    18\n",
       "man         16\n",
       "mob         14\n",
       "black       13\n",
       "night       12\n",
       "saw         11\n",
       "akermans    10\n",
       "see         10\n",
       "face         9\n",
       "fire         9\n",
       "june         9\n",
       "know         9\n",
       "sworn        9\n",
       "went         9\n",
       "time         8\n",
       "room         8\n",
       "believe      8\n",
       "thing        8\n",
       "lodging      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopworded = []\n",
    "\n",
    "for word in cleanlowercasewords:\n",
    "    if word not in stopwords3:\n",
    "        stopworded.append(word)\n",
    "\n",
    "counted = pd.Series.value_counts(stopworded)\n",
    "counted[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What did we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's ask some basic questions about what we just did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words did we originally download from the internet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2874"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many words were eliminated after after we cleaned them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1676"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split()) - len(stopworded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
